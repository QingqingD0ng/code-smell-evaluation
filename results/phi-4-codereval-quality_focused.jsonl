{"dataset": "coderEval", "task_id": "62e60f43d76274f8a4026e28", "original_prompt": "def hydrate_time(nanoseconds, tz=None):\n\t\"\"\"\n\tConvert nanoseconds to a time in fixed format.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom datetime import datetime, timezone, timedelta\n\ndef hydrate_time(nanoseconds, tz=None):\n    seconds, nanoseconds = divmod(nanoseconds, 1_000_000_000)\n    dt = datetime.fromtimestamp(seconds, tz)\n    dt = dt.replace(microsecond=nanoseconds // 1_000)\n    \n    if tz is None:\n        return dt.isoformat()\n    elif isinstance(tz, str):\n        tz_info = timezone(timedelta(seconds=int(tz)))\n        dt = dt.replace(tzinfo=tz_info)\n        return dt.isoformat()\n    elif isinstance(tz, (timezone, timedelta)):\n        dt = dt.replace(tzinfo=tz)\n        return dt.isoformat()\n    else:\n        raise ValueError(\"Invalid timezone format\")\n```"}}}
{"dataset": "coderEval", "task_id": "62e60f3bd76274f8a4026e10", "original_prompt": "def dehydrate_timedelta(value):\n\t\"\"\"\n\tUse the value in timedelta to generate the Structure class.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom datetime import timedelta\n\nclass Structure:\n    def __init__(self, days, seconds, microseconds):\n        self.days = days\n        self.seconds = seconds\n        self.microseconds = microseconds\n\ndef dehydrate_timedelta(value):\n    return Structure(value.days, value.seconds, value.microseconds)\n```"}}}
{"dataset": "coderEval", "task_id": "62e60f37d76274f8a4026dfd", "original_prompt": "def dehydrate_time(value):\n\t\"\"\"\n\tUse ticks in the Time class to generate the Structure class.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here is a clean Python function that implements the described task, ensuring no code smells such as unnecessary comments or docstrings:\n\n```python\nclass Time:\n    def __init__(self, ticks):\n        self.ticks = ticks\n\nclass Structure:\n    def __init__(self, ticks):\n        self.ticks = ticks\n\ndef dehydrate_time(value):\n    if isinstance(value, Time):\n        return Structure(value.ticks)\n    return None\n```\n\nThis code defines two classes, `Time` and `Structure`, and the function `dehydrate_time` converts an instance of `Time` to an instance of `Structure` by using the `ticks` attribute. If the input is not an instance of `Time`, it returns `None`."}}}
{"dataset": "coderEval", "task_id": "62e60f33d76274f8a4026de9", "original_prompt": "def dehydrate_point(value):\n\t\"\"\"\n\tThe structure class is generated based on the value length.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "To implement the `dehydrate_point` function without using docstrings or comments, we need to ensure that the function dynamically creates a class based on the length of the input `value` tuple. The function will generate a class with attributes corresponding to each element in the tuple. Here's a clean implementation:\n\n```python\ndef dehydrate_point(value):\n    class_name = f\"Point{len(value)}\"\n    attrs = {f\"coord{i}\": val for i, val in enumerate(value)}\n    \n    return type(class_name, (object,), attrs)\n\n# Example usage:\n# point = dehydrate_point((1, 2, 3))\n# print(point.coord0)  # Output: 1\n# print(point.coord1)  # Output: 2\n# print(point.coord2)  # Output: 3\n```\n\n### Explanation:\n- **Class Name**: The class name is dynamically generated based on the length of the input tuple (`Point1`, `Point2`, etc.).\n- **Attributes**: A dictionary comprehension is used to create attribute names (`coord0`, `coord1`, etc.) and assign them the corresponding values from the input tuple.\n- **Type Function**: The `type` function is used to create a new class with the generated name, inheriting from `object`, and using the dictionary of attributes."}}}
{"dataset": "coderEval", "task_id": "62e60ed4d76274f8a4026da0", "original_prompt": "def keys(self):\n\t\"\"\"\n\tReturns the __keys property of a class as a List\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Below is the Python code for the task, implementing the `keys` method within a class. The method returns the `__keys` property of the class as a list. The code is designed to be clean and without code smells:\n\n```python\nclass MyClass:\n    def __init__(self):\n        self.__keys = ['a', 'b', 'c']  # Example initialization of __keys\n\n    def keys(self):\n        return list(self.__keys)\n\n# Example usage\nobj = MyClass()\nprint(obj.keys())  # Output: ['a', 'b', 'c']\n```\n\nIn this code, the `__keys` attribute is initialized within the `__init__` method. The `keys` method returns a list of the `__keys` attribute, ensuring encapsulation by using the double underscore in the attribute name."}}}
{"dataset": "coderEval", "task_id": "62e60ecfd76274f8a4026d6a", "original_prompt": "def protocol_handlers(cls, protocol_version=None):\n\t\"\"\"\n\tDifferent forms of Bolt protocol handlers are returned based on the value of protocol_version.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here is a Python code snippet for the `protocol_handlers` function that adheres to your requirements:\n\n```python\nclass ProtocolHandlerFactory:\n    @classmethod\n    def protocol_handlers(cls, protocol_version=None):\n        if protocol_version is None:\n            return cls.default_handler()\n        elif protocol_version == 1:\n            return cls.handler_v1()\n        elif protocol_version == 2:\n            return cls.handler_v2()\n        else:\n            raise ValueError(f\"Unsupported protocol version: {protocol_version}\")\n\n    @staticmethod\n    def default_handler():\n        # Implement the default protocol handler\n        return \"Default Protocol Handler\"\n\n    @staticmethod\n    def handler_v1():\n        # Implement the version 1 protocol handler\n        return \"Protocol Version 1 Handler\"\n\n    @staticmethod\n    def handler_v2():\n        # Implement the version 2 protocol handler\n        return \"Protocol Version 2 Handler\"\n```\n\nThis code defines a class `ProtocolHandlerFactory` with a class method `protocol_handlers` that returns different protocol handlers based on the provided `protocol_version`. Each handler is implemented as a static method within the class."}}}
{"dataset": "coderEval", "task_id": "62e60e49d76274f8a4026d25", "original_prompt": "def unit_of_work(metadata=None, timeout=None):\n\t\"\"\"\n\tReturns a decorator with metadata and timeout attributes.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean implementation of the `unit_of_work` function that returns a decorator with metadata and timeout attributes:\n\n```python\nfrom functools import wraps\n\ndef unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            return func(*args, **kwargs)\n        \n        wrapper.metadata = metadata\n        wrapper.timeout = timeout\n        return wrapper\n    \n    return decorator\n\n# Example usage\n@unit_of_work(metadata=\"example metadata\", timeout=30)\ndef example_function():\n    print(\"Function executed\")\n\n# Accessing the attributes\nprint(example_function.metadata)  # Output: example metadata\nprint(example_function.timeout)   # Output: 30\n```\n\nThis code defines a decorator that can be applied to functions, attaching `metadata` and `timeout` attributes to the decorated function."}}}
{"dataset": "coderEval", "task_id": "62e60e05d76274f8a4026cfd", "original_prompt": "def index(self, key):\n\t\"\"\"\n\tReturns the key in the form of int.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass KeyIndexer:\n    def __init__(self, data):\n        self.data = data\n\n    def index(self, key):\n        if isinstance(key, (int, str)):\n            return self.data.get(key, None)\n        return None\n```\n\nThis code defines a `KeyIndexer` class with an `index` method that retrieves a value from a dictionary using a given key, returning `None` if the key is not found or if the key is not of type `int` or `str`."}}}
{"dataset": "coderEval", "task_id": "62e60da4d76274f8a4026cf1", "original_prompt": "def values(self, *keys):\n\t\"\"\"\n\tReturns the key filtered by self.index in the form of a list.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean implementation of the `values` method in Python:\n\n```python\nclass YourClassName:\n    def __init__(self, data, index):\n        self.data = data\n        self.index = index\n\n    def values(self, *keys):\n        return [self.data[key][self.index] for key in keys if key in self.data]\n\n# Example usage:\n# data = {'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]}\n# obj = YourClassName(data, 1)\n# result = obj.values('a', 'b', 'c')\n# print(result)  # Output: [2, 5, 8]\n```\n\nThis code assumes `self.data` is a dictionary where each key maps to a list, and `self.index` is an integer used to filter the lists. The method returns a list of values from the specified keys at the given index."}}}
{"dataset": "coderEval", "task_id": "62e60b10d76274f8a4026ccd", "original_prompt": "def data(self, *keys):\n\t\"\"\"\n\tReturns the keys processed by the transform method of the RecordExporter class.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "To create a clean Python function for the specified task, we need to define a method named `data` that processes given keys using a `transform` method from a `RecordExporter` class. Here's a structured approach:\n\n```python\nclass RecordExporter:\n    def transform(self, key):\n        # Placeholder for the actual transformation logic\n        return f\"transformed_{key}\"\n\nclass DataProcessor:\n    def __init__(self):\n        self.record_exporter = RecordExporter()\n\n    def data(self, *keys):\n        return [self.record_exporter.transform(key) for key in keys]\n\n# Example usage:\n# processor = DataProcessor()\n# result = processor.data('key1', 'key2', 'key3')\n# print(result)  # Output: ['transformed_key1', 'transformed_key2', 'transformed_key3']\n```\n\n### Explanation:\n- **RecordExporter Class**: Contains a `transform` method, which is a placeholder for the actual transformation logic.\n- **DataProcessor Class**: \n  - Initializes with an instance of `RecordExporter`.\n  - The `data` method takes any number of keys, applies the `transform` method to each, and returns a list of transformed keys.\n- The code avoids unnecessary comments and docstrings for clarity and simplicity."}}}
{"dataset": "coderEval", "task_id": "62e6087bd76274f8a4026bfa", "original_prompt": "def pop_u16(self):\n\t\"\"\"\n\tRemove the last two elements in self.data and return\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass YourClass:\n    def __init__(self):\n        self.data = []\n\n    def pop_u16(self):\n        if len(self.data) < 2:\n            raise ValueError(\"Not enough elements to pop 2 elements\")\n        \n        return (self.data.pop() << 8) | self.data.pop()\n```\n\n### Explanation:\n\n- **Initialization**: A constructor `__init__` is added to initialize `self.data` as an empty list.\n- **Error Handling**: A check is added to ensure there are at least two elements to pop, raising a `ValueError` if not.\n- **Bitwise Operation**: The two popped elements are combined into a 16-bit unsigned integer using bitwise operations. The last element is shifted left by 8 bits and combined with the second last element using a bitwise OR."}}}
{"dataset": "coderEval", "task_id": "62e6087ad76274f8a4026bf2", "original_prompt": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n\t\"\"\"\n\tAppends a DISCARD message to the output queue.\n\n:param n: number of records to discard, default = -1 (ALL)\n:param qid: query ID to discard for, default = -1 (last query)\n:param dehydration_hooks:\n    Hooks to dehydrate types (dict from type (class) to dehydration\n    function). Dehydration functions receive the value and returns an\n    object of type understood by packstream.\n:param hydration_hooks:\n    Hooks to hydrate types (mapping from type (class) to\n    dehydration function). Dehydration functions receive the value of\n    type understood by packstream and are free to return anything.\n:param handlers: handler functions passed into the returned Response object\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass MessageHandler:\n    def __init__(self):\n        self.output_queue = []\n\n    def discard(self, n=-1, qid=-1, dehydration_hooks=None, hydration_hooks=None, **handlers):\n        discard_message = {\n            \"command\": \"DISCARD\",\n            \"n\": n,\n            \"qid\": qid,\n            \"dehydrate\": self._apply_dehydration_hooks(dehydration_hooks),\n            \"hydrate\": self._apply_hydration_hooks(hydration_hooks),\n            \"handlers\": handlers\n        }\n        self.output_queue.append(discard_message)\n\n    def _apply_dehydration_hooks(self, hooks):\n        return hooks if hooks is not None else {}\n\n    def _apply_hydration_hooks(self, hooks):\n        return hooks if hooks is not None else {}\n```\n\nThis code defines a `MessageHandler` class with a `discard` method that appends a `DISCARD` message to an `output_queue`. It handles optional dehydration and hydration hooks, as well as additional handlers passed as keyword arguments."}}}
{"dataset": "coderEval", "task_id": "62e60879d76274f8a4026bec", "original_prompt": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n\t\"\"\"\n\tAppends a BEGIN message to the output queue.\n\n:param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n:param bookmarks: iterable of bookmark values after which this transaction should begin\n:param metadata: custom metadata dictionary to attach to the transaction\n:param timeout: timeout for transaction execution (seconds)\n:param db: name of the database against which to begin the transaction\n    Requires Bolt 4.0+.\n:param imp_user: the user to impersonate\n    Requires Bolt 4.4+\n:param dehydration_hooks:\n    Hooks to dehydrate types (dict from type (class) to dehydration\n    function). Dehydration functions receive the value and returns an\n    object of type understood by packstream.\n:param hydration_hooks:\n    Hooks to hydrate types (mapping from type (class) to\n    dehydration function). Dehydration functions receive the value of\n    type understood by packstream and are free to return anything.\n:param handlers: handler functions passed into the returned Response object\n:return: Response object\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean implementation of the `begin` method in Python:\n\n```python\nclass TransactionManager:\n    def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n        \n        # Default mode to \"READ\" if not specified\n        mode = mode or \"READ\"\n        \n        # Prepare the transaction message\n        message = {\n            \"mode\": mode,\n            \"bookmarks\": list(bookmarks) if bookmarks else [],\n            \"metadata\": metadata or {},\n            \"timeout\": timeout,\n            \"db\": db,\n            \"imp_user\": imp_user,\n            \"dehydration_hooks\": dehydration_hooks or {},\n            \"hydration_hooks\": hydration_hooks or {},\n            \"handlers\": handlers\n        }\n        \n        # Append the BEGIN message to the output queue\n        self._append_to_output_queue(message)\n        \n        # Return a new Response object\n        return Response(message)\n    \n    def _append_to_output_queue(self, message):\n        # This method would handle appending the message to the output queue\n        # For demonstration, we'll just print the message\n        print(\"Appending to output queue:\", message)\n\n\nclass Response:\n    def __init__(self, message):\n        self.message = message\n```\n\n### Key Points:\n- **Default Values**: The method uses default values for parameters like `mode`, `bookmarks`, `metadata`, `dehydration_hooks`, and `hydration_hooks`.\n- **Data Structures**: Converts `bookmarks` to a list and ensures `metadata`, `dehydration_hooks`, and `hydration_hooks` are dictionaries.\n- **Output Queue**: The `_append_to_output_queue` method is a placeholder for appending the message to the actual output queue.\n- **Response Object**: Returns a `Response` object initialized with the message."}}}
{"dataset": "coderEval", "task_id": "62e60723d76274f8a4026b75", "original_prompt": "def round_half_to_even(n):\n\t\"\"\"\n\tRound a floating-point number\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef round_half_to_even(n):\n    import math\n    return round(n) if n % 1!= 0.5 else 2 * round(n / 2)\n```"}}}
{"dataset": "coderEval", "task_id": "62e60707d76274f8a4026b69", "original_prompt": "def point_type(name, fields, srid_map):\n\t\"\"\"\n\tDynamically Generating Point Class\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass Point:\n    def __init__(self, **kwargs):\n        for field, value in kwargs.items():\n            setattr(self, field, value)\n\ndef point_type(name, fields, srid_map):\n    def __repr__(self):\n        return f\"<{name} {self.__dict__}>\"\n\n    def __eq__(self, other):\n        if not isinstance(other, self.__class__):\n            return False\n        return self.__dict__ == other.__dict__\n\n    def __init__(self, **kwargs):\n        for field, value in kwargs.items():\n            if field in fields:\n                setattr(self, field, value)\n            else:\n                raise ValueError(f\"Invalid field: {field}\")\n        self.srid = srid_map.get(kwargs.get(\"srid\"), None)\n\n    attributes = {field: None for field in fields}\n    attributes.update({\n        '__init__': __init__,\n        '__repr__': __repr__,\n        '__eq__': __eq__,\n    })\n\n    return type(name, (Point,), attributes)\n\n# Example usage\nfields = ['x', 'y', 'z']\nsrid_map = {4326: 'WGS 84', 3857: 'Web Mercator'}\nMyPoint = point_type('MyPoint', fields, srid_map)\n\npoint = MyPoint(x=10, y=20, srid=4326)\nprint(point)\nprint(point.srid)\n```\n\nThis code defines a `point_type` function that dynamically creates a class with specified fields and SRID mapping. The generated class includes `__init__`, `__repr__`, and `__eq__` methods for initialization, string representation, and equality comparison, respectively."}}}
{"dataset": "coderEval", "task_id": "62e5dc9ed76274f8a4026b5b", "original_prompt": "def deprecated(message):\n\t\"\"\"\n\tReturn a decorator function for deprecating functions and methods.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Certainly! Below is a Python implementation of a `deprecated` decorator that can be used to mark functions and methods as deprecated. This version avoids code smells by keeping the code clean and concise:\n\n```python\nimport functools\nimport warnings\n\ndef deprecated(message):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            warnings.warn(f\"{message}: {func.__name__} is deprecated.\", DeprecationWarning, stacklevel=2)\n            return func(*args, **kwargs)\n        return wrapper\n    return decorator\n```\n\n### Usage Example\n\nYou can use this `deprecated` decorator to mark functions or methods:\n\n```python\n@deprecated(\"This function will be removed in future versions.\")\ndef old_function(x, y):\n    return x + y\n\n# Call the deprecated function\nresult = old_function(3, 4)\n```\n\nThis implementation uses the `warnings` module to issue a `DeprecationWarning` when a deprecated function is called, providing a clear message about the deprecation. The `functools.wraps` is used to preserve the original function's metadata."}}}
{"dataset": "coderEval", "task_id": "62e4fc3c85ea98643089041e", "original_prompt": "def _inline_r_setup(code: str) -> str:\n\t\"\"\"\n\tSome behaviour of R cannot be configured via env variables, but can\nonly be configured via R options once R has started. These are set here.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a Python function that sets up the R environment by configuring R options once R has started. This function assumes you have the `rpy2` library installed, which provides an interface between Python and R.\n\n```python\nimport rpy2.robjects as robjects\n\ndef _inline_r_setup(code: str) -> str:\n    robjects.r.options(scipen=999)  # Avoid scientific notation\n    robjects.r.options(stringsAsFactors=False)  # Avoid conversion of strings to factors\n    robjects.r(code)\n    return \"R setup complete\"\n\n# Example usage:\n# result = _inline_r_setup(\"print('Hello from R')\")\n# print(result)\n```\n\nThis function configures R to avoid scientific notation and prevent strings from being converted to factors. It then executes the provided R code."}}}
{"dataset": "coderEval", "task_id": "62e4fbda85ea986430890405", "original_prompt": "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs:\n\t\"\"\"\n\tSimplified Implementation of Xargs in Linux\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport subprocess\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import Sequence, Tuple\n\ndef _get_platform_max_length() -> int:\n    return 255  # Typical max length for a command line on many platforms\n\ndef _execute_command(command: Tuple[str,...], color: bool):\n    if color:\n        print(f\"\\033[94mExecuting: {' '.join(command)}\\033[0m\")\n    else:\n        print(f\"Executing: {' '.join(command)}\")\n    subprocess.run(command)\n\ndef xargs(\n    cmd: Tuple[str,...],\n    varargs: Sequence[str],\n    *,\n    color: bool = False,\n    target_concurrency: int = 1,\n    _max_length: int = _get_platform_max_length(),\n    **kwargs\n):\n    def build_command(args_chunk: Sequence[str]):\n        return (*cmd, *args_chunk)\n\n    def chunk_args(args, max_length):\n        chunk = []\n        current_length = len(' '.join(cmd)) + 1  # +1 for the space between cmd and first arg\n        for arg in args:\n            if current_length + len(arg) + 1 > max_length:\n                yield chunk\n                chunk = []\n                current_length = len(' '.join(cmd)) + 1\n            chunk.append(arg)\n            current_length += len(arg) + 1\n        if chunk:\n            yield chunk\n\n    with ThreadPoolExecutor(max_workers=target_concurrency) as executor:\n        for chunk in chunk_args(varargs, _max_length):\n            executor.submit(_execute_command, build_command(chunk), color)\n\n# Example usage:\n# xargs(('echo',), ['file1', 'file2', 'file3'], color=True, target_concurrency=2)\n```"}}}
{"dataset": "coderEval", "task_id": "62e4fbda85ea986430890403", "original_prompt": "def _shuffled(seq: Sequence[str]) -> list[str]:\n\t\"\"\"\n\tShuffle a given seq with the given FIXED_RANDOM_SEED\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom typing import Sequence\nimport random\n\ndef _shuffled(seq: Sequence[str]) -> list[str]:\n    random.seed(42)  # Fixed random seed\n    shuffled_seq = list(seq)\n    random.shuffle(shuffled_seq)\n    return shuffled_seq\n```"}}}
{"dataset": "coderEval", "task_id": "62e4fb6585ea98643089032b", "original_prompt": "def parse_version(s: str) -> tuple[int, ...]:\n\t\"\"\"\n\tConverts a string concatenated by dot to a tuple consisting of integers.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef parse_version(s: str) -> tuple[int,...]:\n    return tuple(map(int, s.split('.')))\n```"}}}
{"dataset": "coderEval", "task_id": "62e4fb4d85ea9864308902e7", "original_prompt": "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n\t\"\"\"\n\tComplement the full path to exe and return it in its original form\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\n\ndef normalize_cmd(cmd: tuple[str,...]) -> tuple[str,...]:\n    normalized_cmd = []\n    for part in cmd:\n        if not os.path.isabs(part):\n            normalized_cmd.append(part)\n        else:\n            normalized_cmd.append(os.path.normpath(part))\n    return tuple(normalized_cmd)\n```"}}}
{"dataset": "coderEval", "task_id": "62b8d27a48ba5a41d1c3f4c6", "original_prompt": "def cached(cache, key=hashkey, lock=None):\n\t\"\"\"\n\tReturns a decorator function that saves the results in the cache\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a Python function that creates a decorator to cache the results of function calls using a provided cache. It uses a lock to ensure thread safety if needed.\n\n```python\nfrom functools import wraps\nfrom threading import Lock\n\ndef cached(cache, key=None, lock=None):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            nonlocal key\n            if key is None:\n                key = lambda *a, **kw: hash((a, tuple(sorted(kw.items()))))\n            cache_key = key(*args, **kwargs)\n            \n            if lock:\n                with lock:\n                    result = cache.get(cache_key)\n                    if result is None:\n                        result = func(*args, **kwargs)\n                        cache[cache_key] = result\n            else:\n                result = cache.get(cache_key)\n                if result is None:\n                    result = func(*args, **kwargs)\n                    cache[cache_key] = result\n            return result\n        return wrapper\n    return decorator\n\n# Example usage\nif __name__ == \"__main__\":\n    from collections import defaultdict\n    cache = defaultdict(lambda: None)\n    lock = Lock()\n\n    @cached(cache, lock=lock)\n    def expensive_function(x, y):\n        return x * y\n\n    print(expensive_function(2, 3))\n    print(expensive_function(2, 3))\n```\n\n### Key Points:\n- The `cached` function returns a decorator.\n- It uses a `key` function to generate cache keys. If not provided, it defaults to hashing the function's arguments.\n- The `lock` parameter ensures thread safety when accessing the cache.\n- The `defaultdict` is used to initialize the cache with a default value of `None`."}}}
{"dataset": "coderEval", "task_id": "62b8d24048ba5a41d1c3f49f", "original_prompt": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n\t\"\"\"\n\tDecorator to wrap a function with a memoizing callable that saves\nup to `maxsize` results based on a Least Recently Used (LRU)\nalgorithm with a per-item time-to-live (TTL) value.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean Python implementation of the `ttl_cache` decorator:\n\n```python\nimport time\nfrom collections import OrderedDict\nfrom functools import wraps\n\ndef ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    def decorator(func):\n        cache = OrderedDict()\n        \n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            key = args if not typed else (args, tuple(sorted(kwargs.items())))\n            \n            # Clean expired items\n            current_time = timer()\n            expired_keys = [k for k, (t, _) in cache.items() if current_time - t > ttl]\n            for k in expired_keys:\n                del cache[k]\n            \n            if key in cache:\n                cache.move_to_end(key)\n                return cache[key][1]\n            \n            result = func(*args, **kwargs)\n            cache[key] = (current_time, result)\n            cache.move_to_end(key)\n            \n            if len(cache) > maxsize:\n                cache.popitem(last=False)\n            \n            return result\n        \n        return wrapper\n    return decorator\n```\n\nThis code defines a decorator that caches function results with a time-to-live (TTL) and uses an LRU strategy to manage the cache size."}}}
{"dataset": "coderEval", "task_id": "62b8d23b48ba5a41d1c3f49a", "original_prompt": "def mru_cache(maxsize=128, typed=False):\n\t\"\"\"\n\tDecorator to wrap a function with a memoizing callable that saves\nup to `maxsize` results based on a Most Recently Used (MRU)\nalgorithm.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a Python implementation of an MRU (Most Recently Used) cache decorator:\n\n```python\nfrom collections import OrderedDict\nfrom functools import wraps\n\ndef mru_cache(maxsize=128, typed=False):\n    def decorator(func):\n        cache = OrderedDict()\n\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            key = args if not typed else tuple((type(arg), arg) for arg in args)\n            key += tuple(sorted(kwargs.items()))\n\n            if key in cache:\n                cache.move_to_end(key)\n                return cache[key]\n\n            result = func(*args, **kwargs)\n            cache[key] = result\n            if len(cache) > maxsize:\n                cache.popitem(last=False)\n            return result\n\n        return wrapper\n\n    return decorator\n```\n\nThis implementation uses an `OrderedDict` to maintain the order of usage and efficiently manage the MRU caching mechanism."}}}
{"dataset": "coderEval", "task_id": "62b8d23948ba5a41d1c3f498", "original_prompt": "def lru_cache(maxsize=128, typed=False):\n\t\"\"\"\n\tDecorator to wrap a function with a memoizing callable that saves\nup to `maxsize` results based on a Least Recently Used (LRU)\nalgorithm.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom functools import wraps, _lru_cache_wrapper\n\ndef lru_cache(maxsize=128, typed=False):\n    def decorator(func):\n        return _lru_cache_wrapper(func, maxsize, typed)\n    return decorator\n```"}}}
{"dataset": "coderEval", "task_id": "62b8d23748ba5a41d1c3f496", "original_prompt": "def lfu_cache(maxsize=128, typed=False):\n\t\"\"\"\n\tDecorator to wrap a function with a memoizing callable that saves\nup to `maxsize` results based on a Least Frequently Used (LFU)\nalgorithm.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom collections import defaultdict, OrderedDict\nfrom functools import wraps\n\ndef lfu_cache(maxsize=128, typed=False):\n    def decorating_function(user_function):\n        cache = {}\n        use_count = defaultdict(int)\n        order = OrderedDict()\n\n        @wraps(user_function)\n        def wrapper(*args, **kwargs):\n            key = args if not typed else tuple((type(arg), arg) for arg in args)\n            if kwargs:\n                key += (frozenset(kwargs.items()) if not typed else tuple((type(v), v) for k, v in sorted(kwargs.items())))\n            \n            if key in cache:\n                use_count[key] += 1\n                order.move_to_end(key)\n                return cache[key]\n            \n            result = user_function(*args, **kwargs)\n            cache[key] = result\n            use_count[key] = 1\n            order[key] = None\n\n            if len(cache) > maxsize:\n                least_used_key = min(order, key=lambda k: use_count[k])\n                del cache[least_used_key]\n                del use_count[least_used_key]\n                del order[least_used_key]\n\n            return result\n\n        return wrapper\n\n    return decorating_function\n```"}}}
{"dataset": "coderEval", "task_id": "62b8d22f48ba5a41d1c3f488", "original_prompt": "def popitem(self):\n\t\"\"\"\n\tRemove the value corresponding to the first inserted key and returns the key and value in tuple format.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass CustomDict:\n    def __init__(self):\n        self._keys = []\n        self._values = []\n\n    def __setitem__(self, key, value):\n        if key in self._keys:\n            index = self._keys.index(key)\n            self._values[index] = value\n        else:\n            self._keys.append(key)\n            self._values.append(value)\n\n    def get(self, key, default=None):\n        if key in self._keys:\n            index = self._keys.index(key)\n            return self._values[index]\n        return default\n\n    def popitem(self):\n        if not self._keys:\n            raise KeyError(\"popitem(): dictionary is empty\")\n        key = self._keys.pop(0)\n        value = self._values.pop(0)\n        return key, value\n\n    def __getitem__(self, key):\n        return self.get(key)\n\n    def __len__(self):\n        return len(self._keys)\n\n    def __contains__(self, key):\n        return key in self._keys\n\n    def __iter__(self):\n        return iter(self._keys)\n\n    def __repr__(self):\n        items = ', '.join(f\"{key}: {self._values[self._keys.index(key)]}\" for key in self._keys)\n        return f\"CustomDict({{{items}}})\"\n```\n\nThis code defines a `CustomDict` class that mimics a dictionary-like behavior, focusing on maintaining the insertion order of keys. The `popitem` method removes and returns the first inserted key-value pair."}}}
{"dataset": "coderEval", "task_id": "62b8d22a48ba5a41d1c3f47e", "original_prompt": "def setdefault(self, key, default=None):\n\t\"\"\"\n\tIf a key exists in the class, the value corresponding to the key is returned. Otherwise, the value corresponding to the key is set to default.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a Python implementation of the `setdefault` method for a class managing a dictionary-like structure. This code avoids code smells by using clear naming conventions and straightforward logic:\n\n```python\nclass CustomDict:\n    def __init__(self):\n        self._data = {}\n\n    def setdefault(self, key, default=None):\n        if key not in self._data:\n            self._data[key] = default\n        return self._data[key]\n\n# Example usage:\n# custom_dict = CustomDict()\n# value = custom_dict.setdefault('key1', 'default_value')\n# print(value)\n```\n\nThis implementation initializes an internal dictionary `_data` and provides the `setdefault` method to manage key-value pairs, following the specified behavior."}}}
{"dataset": "coderEval", "task_id": "62b8d22948ba5a41d1c3f47c", "original_prompt": "def get(self, key, default=None):\n\t\"\"\"\n\tIf a key exists in the class, the value corresponding to the key is returned. Otherwise, default is returned.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean Python implementation of the `get` method without docstrings or comments:\n\n```python\nclass MyClass:\n    def __init__(self, data=None):\n        self.data = data if data is not None else {}\n\n    def get(self, key, default=None):\n        return self.data.get(key, default)\n\n# Example usage\nobj = MyClass({'a': 1, 'b': 2})\nprint(obj.get('a'))  # Output: 1\nprint(obj.get('c', 'not found'))  # Output: not found\n```\n\nThis code defines a class `MyClass` with a `get` method that retrieves a value from an internal dictionary `data` based on the provided key, returning a default value if the key is not present."}}}
{"dataset": "coderEval", "task_id": "62b8d22548ba5a41d1c3f472", "original_prompt": "def cachedmethod(cache, key=hashkey, lock=None):\n\t\"\"\"\n\tReturns a decorator function that can call a result in the cache.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom functools import wraps\nfrom threading import Lock\n\ndef cachedmethod(cache, key=hash, lock=None):\n    def decorator(func):\n        if lock is None:\n            lock = Lock()\n\n        @wraps(func)\n        def wrapper(self, *args, **kwargs):\n            cache_key = key((func.__name__, args, frozenset(kwargs.items())))\n            with lock:\n                if cache_key in cache:\n                    return cache[cache_key]\n                result = func(self, *args, **kwargs)\n                cache[cache_key] = result\n                return result\n\n        return wrapper\n\n    return decorator\n\n# Example usage\nclass Example:\n    def __init__(self):\n        self.cache = {}\n\n    @cachedmethod(cache=lambda self: self.cache)\n    def compute(self, x, y):\n        return x + y\n```\n\nThis code defines a `cachedmethod` decorator that caches the results of a method call. It uses a lock to ensure thread safety when accessing the cache. The `key` function defaults to `hash`, but can be customized. The example usage demonstrates how to use the decorator within a class."}}}
{"dataset": "coderEval", "task_id": "62b8c517e0d34b282c18122e", "original_prompt": "def extostr(cls, e, max_level=30, max_path_level=5):\n\t\"\"\"\n\tFormat the exception as a string\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef extostr(cls, e, max_level=30, max_path_level=5):\n    result = \"\"\n    level = 0\n\n    while e and level < max_level:\n        level += 1\n        result += f\"{e.__class__.__name__}: {str(e)}\\n\"\n        e = e.__cause__ or e.__context__\n\n    if hasattr(e, '__traceback__'):\n        tb = e.__traceback__\n        path_levels = 0\n\n        while tb and path_levels < max_path_level:\n            path_levels += 1\n            frame = tb.tb_frame\n            filename = frame.f_code.co_filename\n            lineno = tb.tb_lineno\n            result += f\"\\tat {filename}:{lineno}\\n\"\n            tb = tb.tb_next\n\n    return result\n```\n\nThis function formats an exception and its traceback into a string, respecting the specified maximum levels for the exception chain and traceback path."}}}
{"dataset": "coderEval", "task_id": "62b8bbbfe0d34b282c181210", "original_prompt": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n\t\"\"\"\n\tWrites the data in the text buffer to a file\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean version of the Python function `append_text_to_file` that performs the described task:\n\n```python\ndef append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    mode = 'w' if overwrite else 'a'\n    with open(file_name, mode, encoding=encoding) as file:\n        file.write(text_buffer)\n```\n\nThis function opens a file with the specified name and encoding. It writes to the file in either write (`'w'`) or append (`'a'`) mode depending on the `overwrite` flag. The text from `text_buffer` is then written to the file."}}}
{"dataset": "coderEval", "task_id": "62b8bbbfe0d34b282c18120f", "original_prompt": "def file_to_textbuffer(file_name, encoding):\n\t\"\"\"\n\tLoad a file toward a text buffer\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef file_to_textbuffer(file_name, encoding):\n    with open(file_name, mode='r', encoding=encoding) as file:\n        return file.read()\n```"}}}
{"dataset": "coderEval", "task_id": "62b8bbbce0d34b282c18120d", "original_prompt": "def is_file_exist(file_name):\n\t\"\"\"\n\tCheck whether file_name is an existing file.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\n\ndef is_file_exist(file_name):\n    return os.path.isfile(file_name)\n```"}}}
{"dataset": "coderEval", "task_id": "62b8b99de0d34b282c1811f8", "original_prompt": "def _reset_logging(cls):\n\t\"\"\"\n\tReset the logging system\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here is a clean implementation of the `_reset_logging` function. This function resets the logging system by removing existing handlers and setting the logging level to `WARNING` by default:\n\n```python\nimport logging\n\ndef _reset_logging(cls):\n    root_logger = logging.getLogger()\n    handlers = root_logger.handlers[:]\n    for handler in handlers:\n        root_logger.removeHandler(handler)\n        handler.close()\n    \n    root_logger.setLevel(logging.WARNING)\n    root_logger.addHandler(logging.StreamHandler())\n```\n\nThis code removes all handlers from the root logger, closes each handler, sets the logger level to `WARNING`, and adds a default `StreamHandler` to output logs to the console."}}}
{"dataset": "coderEval", "task_id": "62b8b59feb7e40a82d2d1291", "original_prompt": "def _getTargetClass(self):\n\t\"\"\"\n\tDefine this to return the implementation in use,\nwithout the 'Py' or 'Fallback' suffix.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass MyClass:\n    def _getTargetClass(self):\n        # Assuming self.current_class is a string representing the current class name\n        class_name = getattr(self, 'current_class', '')\n        \n        # Remove 'Py' or 'Fallback' suffix if present\n        if class_name.endswith('Py'):\n            return class_name[:-2]\n        elif class_name.endswith('Fallback'):\n            return class_name[:-9]\n        \n        return class_name\n```\n\nThis code assumes that the class name is stored in an attribute `current_class` within the instance. It removes the specified suffixes if they exist."}}}
{"dataset": "coderEval", "task_id": "62b8b590eb7e40a82d2d1275", "original_prompt": "def _legacy_mergeOrderings(orderings):\n\t\"\"\"\n\tCombine multiple lists in the sequence of occurrence into a list with no duplicate elements.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef _legacy_mergeOrderings(orderings):\n    result = []\n    seen = set()\n    for ordering in orderings:\n        for item in ordering:\n            if item not in seen:\n                seen.add(item)\n                result.append(item)\n    return result\n```"}}}
{"dataset": "coderEval", "task_id": "62b8b58deb7e40a82d2d1269", "original_prompt": "def directlyProvidedBy(object):\n\t\"\"\"\n\tReturn the interfaces directly provided by the given object\n\nThe value returned is an `~zope.interface.interfaces.IDeclaration`.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom zope.interface import Interface, directlyProvidedBy\n\ndef directlyProvidedBy(object):\n    return directlyProvidedBy(object)\n```"}}}
{"dataset": "coderEval", "task_id": "62b8b559eb7e40a82d2d11f8", "original_prompt": "def minimalBases(classes):\n\t\"\"\"\n\tReturns all classes without subclasses as a list.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef minimalBases(classes):\n    subclasses_map = {}\n    \n    for cls in classes:\n        base = cls.__bases__\n        for b in base:\n            if b in subclasses_map:\n                subclasses_map[b].add(cls)\n            else:\n                subclasses_map[b] = {cls}\n    \n    all_classes = set(classes)\n    minimal_bases = all_classes.copy()\n    \n    for subclasses in subclasses_map.values():\n        minimal_bases -= subclasses\n    \n    return list(minimal_bases)\n```"}}}
{"dataset": "coderEval", "task_id": "62b8b4b9eb7e40a82d2d1134", "original_prompt": "def namesAndDescriptions(self, all=False):\n\t\"\"\"\n\tReturns the name and description of the current class attribute.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean and concise implementation of the `namesAndDescriptions` method in Python:\n\n```python\nclass ExampleClass:\n    def __init__(self):\n        self.example_attr = \"This is an example attribute.\"\n        self.another_attr = \"Another example attribute.\"\n\n    def namesAndDescriptions(self, all=False):\n        import inspect\n\n        attributes = inspect.getmembers(self, lambda a: not(inspect.isroutine(a)))\n        if not all:\n            attributes = {name: value for name, value in attributes if not name.startswith('_')}\n\n        return {name: str(value) for name, value in attributes}\n```\n\nThis code uses the `inspect` module to retrieve non-callable attributes of the instance. If `all` is `False`, it filters out private attributes (those starting with an underscore). The result is a dictionary mapping attribute names to their string representations."}}}
{"dataset": "coderEval", "task_id": "62b8b416eb7e40a82d2d1129", "original_prompt": "def names(self, all=False):\n\t\"\"\"\n\tReturn the attribute names of current class.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass MyClass:\n    def __init__(self, **kwargs):\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n\n    def names(self, all=False):\n        if all:\n            return [attr for attr in dir(self) if not callable(getattr(self, attr)) and not attr.startswith(\"__\")]\n        else:\n            return [attr for attr in dir(self) if not callable(getattr(self, attr)) and not attr.startswith(\"__\") and not attr in ['names']]\n\n# Example usage:\n# obj = MyClass(attr1='value1', attr2='value2', method=lambda x: x)\n# print(obj.names())  # Output: ['attr1', 'attr2']\n# print(obj.names(all=True))  # Output: ['attr1', 'attr2','method']\n```\n\nThis code defines a class `MyClass` with a method `names` that returns the non-callable attribute names of the instance. If `all` is `True`, it includes all attributes except those starting with `__`. The `names` method itself is excluded from the default output."}}}
{"dataset": "coderEval", "task_id": "62b8b3d6eb7e40a82d2d111c", "original_prompt": "def _normalizeargs(sequence, output=None):\n\t\"\"\"\n\tNormalize declaration arguments\n\nNormalization arguments might contain Declarions, tuples, or single\ninterfaces.\n\nAnything but individial interfaces or implements specs will be expanded.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean Python function for the task described:\n\n```python\ndef _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    \n    for item in sequence:\n        if isinstance(item, Declaration):\n            output.append(item)\n        elif isinstance(item, tuple):\n            for sub_item in item:\n                output.append(sub_item)\n        elif isinstance(item, Interface):\n            output.append(item)\n        else:\n            raise TypeError(\"Unsupported item type in sequence\")\n    \n    return output\n```\n\nThis function processes the `sequence`, expanding tuples and appending `Declaration` or `Interface` objects to `output`. Unsupported types raise a `TypeError`."}}}
{"dataset": "coderEval", "task_id": "62b8b3d5eb7e40a82d2d1110", "original_prompt": "def _c_optimizations_available():\n\t\"\"\"\n\tIf available, return the C optimization module, otherwise a false value.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef _c_optimizations_available():\n    try:\n        import c_optimization_module  # Replace with the actual module name\n        return c_optimization_module\n    except ImportError:\n        return False\n```"}}}
{"dataset": "coderEval", "task_id": "62b8b3d4eb7e40a82d2d110f", "original_prompt": "def _should_attempt_c_optimizations():\n\t\"\"\"\n\tReturn a true value if we use the C optimizations.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean Python function implementing the task. This version assumes you have some criteria to decide whether to use C optimizations, such as checking a configuration setting or environment variable. For demonstration, I'll use a simple configuration dictionary.\n\n```python\ndef _should_attempt_c_optimizations():\n    config = {\n        'use_c_optimizations': True,  # Example configuration\n    }\n    return config.get('use_c_optimizations', False)\n```\n\nThis function checks a configuration dictionary for the key `'use_c_optimizations'` and returns its value. If the key is not present, it defaults to `False`. You can replace the configuration logic with any other criteria you need."}}}
{"dataset": "coderEval", "task_id": "62b8b3d4eb7e40a82d2d110e", "original_prompt": "def _c_optimizations_ignored():\n\t\"\"\"\n\tReturn True if get \"PURE_PYTHON\" environ is not none and not 0, else return False\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean version of the Python code for the given task:\n\n```python\nimport os\n\ndef _c_optimizations_ignored():\n    return os.environ.get(\"PURE_PYTHON\") not in (None, '0')\n```\n\nThis function checks if the environment variable \"PURE_PYTHON\" is set to a value other than `None` or `'0'` and returns `True` or `False` accordingly."}}}
{"dataset": "coderEval", "task_id": "62b8b3d4eb7e40a82d2d110d", "original_prompt": "def _c_optimizations_required():\n\t\"\"\"\n\tReturn a true value if the C optimizations are required.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef _c_optimizations_required():\n    return True\n```"}}}
{"dataset": "coderEval", "task_id": "62b87b989a0c4fa8b80b35ee", "original_prompt": "def reset(self):\n\t\"\"\"\n\tCurrent context is reset to an empty dict, bins of the class are reinitialized with the *initial_value* or with *make_bins()*.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a Python class with the `reset` method implemented according to your requirements:\n\n```python\nclass MyClass:\n    def __init__(self, initial_value=None, make_bins=None):\n        self.context = {}\n        self.bins = []\n        self.initial_value = initial_value\n        self.make_bins = make_bins\n\n    def reset(self):\n        self.context = {}\n        if self.initial_value is not None:\n            self.bins = [self.initial_value] * len(self.bins)\n        elif self.make_bins is not None:\n            self.bins = self.make_bins()\n\n# Example usage:\n# obj = MyClass(initial_value=0, make_bins=lambda: [1, 2, 3])\n# obj.reset()\n```\n\nThis code defines a class `MyClass` with a `reset` method that resets the `context` to an empty dictionary and reinitializes `bins` using either `initial_value` or `make_bins`."}}}
{"dataset": "coderEval", "task_id": "62b87b859a0c4fa8b80b35d7", "original_prompt": "def to_csv(self, separator=\",\", header=None):\n\t\"\"\"\n\t.. deprecated:: 0.5 in Lena 0.5 to_csv is not used.\n      Iterables are converted to tables.\n\nConvert graph's points to CSV.\n\n*separator* delimits values, the default is comma.\n\n*header*, if not ``None``, is the first string of the output\n(new line is added automatically).\n\nSince a graph can be multidimensional,\nfor each point first its coordinate is converted to string\n(separated by *separator*), then each part of its value.\n\nTo convert :class:`Graph` to CSV inside a Lena sequence,\nuse :class:`lena.output.ToCSV`.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport csv\nimport io\n\nclass Graph:\n    def __init__(self, points):\n        self.points = points\n\n    def to_csv(self, separator=\",\", header=None):\n        output = io.StringIO()\n        writer = csv.writer(output, delimiter=separator)\n\n        if header:\n            writer.writerow([header])\n\n        for point in self.points:\n            flattened_point = [str(part) for coord in point for part in (coord if isinstance(coord, (list, tuple)) else [coord])]\n            writer.writerow(flattened_point)\n\n        return output.getvalue()\n```\n\nThis code provides a `to_csv` method for a `Graph` class, which converts the graph's points to a CSV format. It allows specifying a custom separator and an optional header. The points are flattened to handle multidimensional data, ensuring each coordinate and its parts are converted to strings and written to the CSV."}}}
{"dataset": "coderEval", "task_id": "62b87b839a0c4fa8b80b35cb", "original_prompt": "def _get_err_indices(self, coord_name):\n\t\"\"\"\n\tFind all error indexes corresponding to coord_name.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass MyClass:\n    def __init__(self, data):\n        self.data = data\n\n    def _get_err_indices(self, coord_name):\n        return [i for i, entry in enumerate(self.data) if entry.get('coord_name') == coord_name and entry.get('error')]\n\n# Example usage\n# data = [{'coord_name': 'x', 'error': True}, {'coord_name': 'y', 'error': False}, {'coord_name': 'x', 'error': True}]\n# obj = MyClass(data)\n# print(obj._get_err_indices('x'))  # Output: [0, 2]\n```\n\nThis code defines a class with a method `_get_err_indices` that finds all indices where the `coord_name` matches and there is an associated error. The example usage demonstrates how to use this method."}}}
{"dataset": "coderEval", "task_id": "62b87b7e9a0c4fa8b80b35bc", "original_prompt": "def _update_context(self, context):\n\t\"\"\"\n\tUpdate *context* with the properties of this graph.\n\n*context.error* is appended with indices of errors.\nExample subcontext for a graph with fields \"E,t,error_E_low\":\n{\"error\": {\"x_low\": {\"index\": 2}}}.\nNote that error names are called \"x\", \"y\" and \"z\"\n(this corresponds to first three coordinates,\nif they are present), which allows to simplify plotting.\nExisting values are not removed\nfrom *context.value* and its subcontexts.\n\nCalled on \"destruction\" of the graph (for example,\nin :class:`.ToCSV`). By destruction we mean conversion\nto another structure (like text) in the flow.\nThe graph object is not really destroyed in this process.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef _update_context(self, context):\n    indices_of_errors = self.find_indices_of_errors()  # Hypothetical method to find error indices\n    context.error = context.get('error', {})\n    context.error.update({\n        'x_low': {'index': indices_of_errors.get('E_low', -1)},\n        'y_low': {'index': indices_of_errors.get('t_low', -1)},\n        'z_low': {'index': indices_of_errors.get('error_E_low', -1)}\n    })\n\n    context.value = context.get('value', {})\n    for field in self.fields():\n        context.value[field] = self.get_field_value(field)  # Hypothetical method to get field value\n\ndef find_indices_of_errors(self):\n    # Hypothetical implementation to find indices of errors\n    return {\n        'E_low': self.get_error_index('E_low'),\n        't_low': self.get_error_index('t_low'),\n        'error_E_low': self.get_error_index('error_E_low')\n    }\n\ndef get_error_index(self, error_name):\n    # Hypothetical method to get error index\n    try:\n        return self.data.index('error_' + error_name)\n    except ValueError:\n        return -1\n\ndef fields(self):\n    # Hypothetical method to return fields of the graph\n    return ['E', 't', 'error_E_low']\n\ndef get_field_value(self, field):\n    # Hypothetical method to retrieve the value of a given field\n    return self.data.get(field, None)\n```\n\nIn this code, I've created hypothetical methods like `find_indices_of_errors`, `get_error_index`, `fields`, and `get_field_value` to encapsulate logic that would be specific to how your graph object works. Adjust these methods according to your actual implementation details."}}}
{"dataset": "coderEval", "task_id": "62b87b4f9a0c4fa8b80b3580", "original_prompt": "def integral(bins, edges):\n\t\"\"\"\n\tCalculate the area of the overall graph.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean Python function to calculate the area of the overall graph using the trapezoidal rule, given `bins` and `edges`:\n\n```python\ndef integral(bins, edges):\n    area = 0\n    for i in range(len(bins) - 1):\n        base = edges[i + 1] - edges[i]\n        height_sum = bins[i] + bins[i + 1]\n        area += 0.5 * base * height_sum\n    return area\n```\n\nThis function iterates through the bins and edges, applying the trapezoidal rule to calculate the area under the graph."}}}
{"dataset": "coderEval", "task_id": "62b87b199a0c4fa8b80b354e", "original_prompt": "def is_fill_request_seq(seq):\n\t\"\"\"\n\tCheck whether seq can be converted to FillRequestSeq and bool is returned.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean Python function to determine if a given sequence can be converted to a `FillRequestSeq`:\n\n```python\ndef is_fill_request_seq(seq):\n    if not isinstance(seq, (list, tuple)):\n        return False\n\n    if len(seq) == 0:\n        return False\n\n    for item in seq:\n        if not isinstance(item, dict):\n            return False\n        \n        if'request_id' not in item or 'fill' not in item:\n            return False\n        \n        if not isinstance(item['request_id'], int):\n            return False\n        \n        if not isinstance(item['fill'], dict):\n            return False\n        \n        if 'price' not in item['fill'] or 'quantity' not in item['fill']:\n            return False\n        \n        if not isinstance(item['fill']['price'], (int, float)):\n            return False\n        \n        if not isinstance(item['fill']['quantity'], int):\n            return False\n\n    return True\n```\n\nThis function checks if the input `seq` is a list or tuple of dictionaries, each containing specific keys with expected types, ensuring it can be converted to a `FillRequestSeq`."}}}
{"dataset": "coderEval", "task_id": "62b87b099a0c4fa8b80b3538", "original_prompt": "def is_fill_request_el(obj):\n\t\"\"\"\n\tCheck whether the obj class has the fill and request attributes.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Below is the Python code for the `is_fill_request_el` function. The function checks if an object has both `fill` and `request` attributes.\n\n```python\ndef is_fill_request_el(obj):\n    return hasattr(obj, 'fill') and hasattr(obj,'request')\n```\n\nThis implementation uses Python's built-in `hasattr` function to check for the existence of the specified attributes in a concise manner."}}}
{"dataset": "coderEval", "task_id": "62b87af99a0c4fa8b80b3524", "original_prompt": "def is_run_el(obj):\n\t\"\"\"\n\tCheck whether the obj class has the run method.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean Python function to check if an object has a `run` method:\n\n```python\ndef is_run_el(obj):\n    return callable(getattr(obj, \"run\", None))\n```\n\nThis function uses `getattr` to safely check for the `run` attribute and verifies if it is callable."}}}
{"dataset": "coderEval", "task_id": "62b87af69a0c4fa8b80b351a", "original_prompt": "def is_fill_compute_el(obj):\n\t\"\"\"\n\tCheck whether the obj class has the fill and compute methods.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef is_fill_compute_el(obj):\n    return hasattr(obj, 'fill') and callable(getattr(obj, 'fill')) and \\\n           hasattr(obj, 'compute') and callable(getattr(obj, 'compute'))\n```"}}}
{"dataset": "coderEval", "task_id": "62b87af19a0c4fa8b80b34f7", "original_prompt": "def difference(d1, d2, level=-1):\n\t\"\"\"\n\tReturn a dictionary with items from d1 not contained in d2.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef difference(d1, d2, level=-1):\n    def items_not_in(d1, d2):\n        return {k: v for k, v in d1.items() if k not in d2}\n\n    def recursive_difference(d1, d2, level):\n        if level == 0:\n            return items_not_in(d1, d2)\n        \n        diff = items_not_in(d1, d2)\n        for k, v in d1.items():\n            if isinstance(v, dict) and k in d2 and isinstance(d2[k], dict):\n                nested_diff = recursive_difference(v, d2[k], level - 1)\n                if nested_diff:\n                    diff[k] = nested_diff\n        \n        return diff\n\n    return recursive_difference(d1, d2, level)\n```"}}}
{"dataset": "coderEval", "task_id": "62b87af09a0c4fa8b80b34f1", "original_prompt": "def fill(self, coord, weight=1):\n\t\"\"\"\n\tFill histogram at *coord* with the given *weight*.\n\nCoordinates outside the histogram edges are ignored.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass Histogram:\n    def __init__(self, min_edge, max_edge, bins):\n        self.min_edge = min_edge\n        self.max_edge = max_edge\n        self.bins = bins\n        self.bin_width = (max_edge - min_edge) / bins\n        self.histogram = [0.0] * bins\n\n    def fill(self, coord, weight=1):\n        if self.min_edge <= coord < self.max_edge:\n            index = int((coord - self.min_edge) / self.bin_width)\n            self.histogram[index] += weight\n\n    def get_histogram(self):\n        return self.histogram\n```\n\nThis code defines a `Histogram` class with a `fill` method that updates the histogram based on the provided `coord` and `weight`. Coordinates outside the specified range are ignored. The histogram is represented as a list of bin counts."}}}
{"dataset": "coderEval", "task_id": "62b86aa3b4d922cb0e688d36", "original_prompt": "def _validate_labels(labels):\n\t\"\"\"\n\tCheck that keys and values in the given labels by validate_key() and validate_value().\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef validate_key(key):\n    if not isinstance(key, str) or not key:\n        raise ValueError(\"Invalid key\")\n    if ':' in key:\n        raise ValueError(\"Invalid character in key\")\n    return True\n\ndef validate_value(value):\n    if not isinstance(value, str):\n        raise ValueError(\"Invalid value\")\n    return True\n\ndef _validate_labels(labels):\n    if not isinstance(labels, dict):\n        raise ValueError(\"Labels must be a dictionary\")\n    \n    for key, value in labels.items():\n        validate_key(key)\n        validate_value(value)\n```"}}}
{"dataset": "coderEval", "task_id": "62b86a9eb4d922cb0e688d25", "original_prompt": "def _get_resource_name_regex():\n\t\"\"\"\n\tReturn the regular expressions that are used to validate the name of the Krake resources\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Certainly! Below is a clean Python function that returns regular expressions used to validate the names of Krake resources. Given that the specific regex patterns are not provided, I'll include a general example that you can modify according to your needs.\n\n```python\nimport re\n\ndef _get_resource_name_regex():\n    resource_name_pattern = r'^[a-zA-Z0-9][a-zA-Z0-9_-]{0,63}$'\n    return re.compile(resource_name_pattern)\n```\n\nThis example assumes that Krake resource names must:\n\n- Start with an alphanumeric character.\n- Be followed by up to 63 alphanumeric characters, underscores, or hyphens.\n- End with an alphanumeric character.\n\nYou can adjust the `resource_name_pattern` string to match your specific requirements for resource names."}}}
{"dataset": "coderEval", "task_id": "62b86a4fb4d922cb0e688cf8", "original_prompt": "def validate_value(value):\n\t\"\"\"\n\tValidate the given value against the corresponding regular expression.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport re\n\ndef validate_value(value):\n    pattern = r'^[a-zA-Z0-9_]+$'  # Example regex for alphanumeric characters and underscores\n    return bool(re.match(pattern, value))\n```"}}}
{"dataset": "coderEval", "task_id": "62b86a4fb4d922cb0e688cf7", "original_prompt": "def validate_key(key):\n\t\"\"\"\n\tValidate the given key against the corresponding regular expression.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport re\n\ndef validate_key(key):\n    pattern = r'^[A-Za-z0-9_-]{5,20}$'\n    return bool(re.match(pattern, key))\n```"}}}
{"dataset": "coderEval", "task_id": "62b86a01b4d922cb0e688ccc", "original_prompt": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n\t\"\"\"\n\tThe values corresponding to different keys in the new dict are generated based on the value type (such as dict and list) in the manifest_dict file. Then new dictionary is returned.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    schema_dict = {}\n    \n    for key, value in manifest_dict.items():\n        if isinstance(value, dict):\n            schema_dict[key] = generate_default_observer_schema_dict(value)\n        elif isinstance(value, list):\n            if value and isinstance(value[0], dict):\n                schema_dict[key] = [generate_default_observer_schema_dict(value[0])]\n            else:\n                schema_dict[key] = []\n        else:\n            schema_dict[key] = type(value).__name__\n    \n    if first_level:\n        return {k: 'object' if isinstance(v, dict) else 'array' if isinstance(v, list) else type(v).__name__ for k, v in schema_dict.items()}\n    \n    return schema_dict\n```"}}}
{"dataset": "coderEval", "task_id": "62b869ebb4d922cb0e688cc6", "original_prompt": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n\t\"\"\"\n\tTogether with :func:``update_last_applied_manifest_dict_from_resp``, this\nfunction is called recursively to update a partial ``last_applied_manifest``\nfrom a partial Kubernetes response\n\nArgs:\n    last_applied_manifest (list): partial ``last_applied_manifest`` being\n        updated\n    observer_schema (list): partial ``observer_schema``\n    response (list): partial response from the Kubernetes API.\n\nThis function go through all observed fields, and initialized their value in\nlast_applied_manifest if they are not yet present\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a Python function that meets your requirements:\n\n```python\ndef update_last_applied_manifest_list_from_resp(last_applied_manifest, observer_schema, response):\n    for i, field in enumerate(observer_schema):\n        if isinstance(field, dict):\n            key = list(field.keys())[0]\n            if key not in last_applied_manifest:\n                last_applied_manifest.append({})\n            if key not in last_applied_manifest[i]:\n                last_applied_manifest[i][key] = {}\n            update_last_applied_manifest_list_from_resp(\n                last_applied_manifest[i][key].values(),\n                field[key],\n                response[i][key].values()\n            )\n        elif isinstance(field, list):\n            if len(field) > 0:\n                key = list(field[0].keys())[0]\n                if key not in last_applied_manifest[i]:\n                    last_applied_manifest[i][key] = []\n                if len(last_applied_manifest[i][key]) < len(response[i][key]):\n                    last_applied_manifest[i][key].append({})\n                update_last_applied_manifest_list_from_resp(\n                    last_applied_manifest[i][key],\n                    field,\n                    response[i][key]\n                )\n        else:\n            if field not in last_applied_manifest[i]:\n                last_applied_manifest[i][field] = response[i][field]\n```\n\nThis function recursively updates `last_applied_manifest` based on `observer_schema` and `response`. It handles nested dictionaries and lists, ensuring that all observed fields are initialized in `last_applied_manifest`."}}}
{"dataset": "coderEval", "task_id": "62b869eab4d922cb0e688cc5", "original_prompt": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n\t\"\"\"\n\tTogether with :func:``update_last_applied_manifest_list_from_resp``, this\nfunction is called recursively to update a partial ``last_applied_manifest``\nfrom a partial Kubernetes response\n\nArgs:\n    last_applied_manifest (dict): partial ``last_applied_manifest`` being\n        updated\n    observer_schema (dict): partial ``observer_schema``\n    response (dict): partial response from the Kubernetes API.\n\nRaises:\n    KeyError: If the observed field is not present in the Kubernetes response\n\nThis function go through all observed fields, and initialized their value in\nlast_applied_manifest if they are not yet present\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Certainly! Below is a clean Python function that updates a `last_applied_manifest` dictionary based on a Kubernetes response. The function avoids code smells like unnecessary complexity and redundancy, and it doesn't include docstrings or comments as per your request.\n\n```python\ndef update_last_applied_manifest_dict_from_resp(last_applied_manifest, observer_schema, response):\n    for field, schema_info in observer_schema.items():\n        if field in response:\n            if field not in last_applied_manifest:\n                last_applied_manifest[field] = {}\n\n            if 'fields' in schema_info:\n                update_last_applied_manifest_dict_from_resp(\n                    last_applied_manifest[field], schema_info['fields'], response[field]\n                )\n            else:\n                last_applied_manifest[field] = response[field]\n        else:\n            raise KeyError(f\"Observed field {field} is not present in the Kubernetes response\")\n```\n\n### Key Points:\n- **Recursion**: The function is recursive, allowing it to handle nested structures in `observer_schema`.\n- **Error Handling**: Raises a `KeyError` if an expected field in the `observer_schema` is missing from the `response`.\n- **Initialization**: Ensures that fields in `last_applied_manifest` are initialized before being updated.\n\nThis function assumes that `observer_schema` is structured in a way that allows it to guide the update process, with potential nested fields being indicated by a `'fields'` key. Adjustments might be necessary based on the exact structure of `observer_schema`."}}}
{"dataset": "coderEval", "task_id": "62b869eab4d922cb0e688cbf", "original_prompt": "def generate_default_observer_schema(app):\n\t\"\"\"\n\tGenerate the default observer schema for each Kubernetes resource present in ``spec.manifest`` for which a custom observer schema hasn't been specified.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef generate_default_observer_schema(app):\n    default_schema = {}\n    for resource in app.spec['manifest']:\n        if 'observer_schema' not in resource:\n            default_schema[resource['kind']] = {\n                'name': resource['name'],\n               'version': resource.get('version', 'v1'),\n                'description': f\"Default observer schema for {resource['kind']}\"\n            }\n    return default_schema\n```"}}}
{"dataset": "coderEval", "task_id": "62b43427903eeb48555d3ea5", "original_prompt": "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\n\t\"\"\"\n\tConvert sql using self._converter.convert\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom typing import Any, AnyStr, Dict, Sequence, Tuple, Union\n\nclass SqlFormatter:\n    def __init__(self, converter):\n        self._converter = converter\n\n    def format(self, sql: AnyStr, params: Union[Dict[Union[str, int], Any], Sequence[Any]]) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\n        formatted_sql = self._converter.convert(sql)\n        return formatted_sql, params\n\n# Example usage:\n# class ExampleConverter:\n#     def convert(self, sql: AnyStr) -> AnyStr:\n#         return sql.replace('?', '%s')  # Example conversion logic\n\n# converter = ExampleConverter()\n# formatter = SqlFormatter(converter)\n# formatted_sql, formatted_params = formatter.format(\"SELECT * FROM table WHERE id =?\", [1])\n```\n\nThis code defines a `SqlFormatter` class with a `format` method that uses a converter to format SQL strings. The converter is expected to have a `convert` method. The example usage shows how you might implement a simple converter."}}}
{"dataset": "coderEval", "task_id": "62b43428903eeb48555d3eaa", "original_prompt": "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n\t\"\"\"\n\tConvert sql using self._converter.convert_many\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Below is a Python code implementation for the described task. The function `format_many` takes an SQL query and a list of parameters, then processes them using a hypothetical `_converter.convert_many` method. The implementation avoids code smells by using clear and concise naming, consistent formatting, and leveraging Python's typing system.\n\n```python\nfrom typing import Any, AnyStr, Dict, Iterable, List, Sequence, Tuple, Union\n\nclass SQLFormatter:\n    def __init__(self, converter):\n        self._converter = converter\n\n    def format_many(\n        self,\n        sql: AnyStr,\n        many_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n    ) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n        formatted_sql, formatted_params = self._converter.convert_many(sql, many_params)\n        return formatted_sql, formatted_params\n\n# Assuming a converter class exists with a convert_many method\nclass Converter:\n    def convert_many(self, sql: AnyStr, params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]]) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n        # Mock implementation for demonstration\n        return sql, list(params)\n\n# Example usage\nconverter = Converter()\nformatter = SQLFormatter(converter)\n\nsql_query = \"SELECT * FROM table WHERE id = %s\"\nparams = [{\"id\": 1}, {\"id\": 2}, {\"id\": 3}]\n\nformatted_sql, formatted_params = formatter.format_many(sql_query, params)\nprint(formatted_sql)\nprint(formatted_params)\n```\n\n### Key Points:\n- **Class Structure**: The `SQLFormatter` class encapsulates the functionality, and it requires a `converter` object upon initialization.\n- **Type Annotations**: Used for function signatures to clarify expected input and output types.\n- **Method Definition**: `format_many` uses the `_converter.convert_many` method to process the SQL and parameters.\n- **Mock Converter**: A simple `Converter` class with a mock `convert_many` method is provided for demonstration purposes.\n\nThis structure ensures that the code is modular, easy to read, and maintainable."}}}
{"dataset": "coderEval", "task_id": "62b45df05108cfac7f2109ce", "original_prompt": "def validate(self, path):\n\t\"\"\"\n\tReturns True if OCFL object at path or pyfs root, False otherwise.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\n\nclass OCFLValidator:\n    def is_ocfl_object(self, path):\n        # Check for existence of.ocfl directory or.ocflignore file\n        ocfl_dir = os.path.join(path, '.ocfl')\n        ocfl_ignore = os.path.join(path, '.ocflignore')\n        return os.path.isdir(ocfl_dir) or os.path.isfile(ocfl_ignore)\n    \n    def is_pyfs_root(self, path):\n        # Assuming pyfs root has a specific marker file or directory\n        pyfs_marker = os.path.join(path, '.pyfs')\n        return os.path.isfile(pyfs_marker)\n    \n    def validate(self, path):\n        return self.is_ocfl_object(path) or self.is_pyfs_root(path)\n```\n\nThis code defines a class `OCFLValidator` with methods to check if a given path is an OCFL object or a pyfs root, and a `validate` method that returns `True` if either condition is met."}}}
{"dataset": "coderEval", "task_id": "62b45df15108cfac7f2109dc", "original_prompt": "def status_str(self, prefix=''):\n\t\"\"\"\n\tReturn a string with visiting the sorted self.messages list, each visit add prefix and the element in the sorted self.messages list.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass Status:\n    def __init__(self, messages):\n        self.messages = messages\n\n    def status_str(self, prefix=''):\n        return '\\n'.join(f\"{prefix}{message}\" for message in sorted(self.messages))\n```"}}}
{"dataset": "coderEval", "task_id": "62b45df15108cfac7f2109dd", "original_prompt": "def status_str(self, prefix=''):\n\t\"\"\"\n\tReturn string representation with self.log.status_str, with optional prefix.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean implementation of the `status_str` method in Python, ensuring it avoids code smells:\n\n```python\nclass MyClass:\n    def __init__(self, log):\n        self.log = log\n\n    def status_str(self, prefix=''):\n        return f\"{prefix}{self.log.status_str()}\"\n```\n\nThis implementation assumes that `self.log` is an object with a `status_str` method that returns a string. The optional `prefix` is concatenated with the result of `self.log.status_str()`."}}}
{"dataset": "coderEval", "task_id": "62b45e135108cfac7f2109f4", "original_prompt": "def is_valid(self, identifier):\n\t\"\"\"\n\tReturn True if identifier is valid. In this base implementation, always return True.  (D)\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass Validator:\n    def is_valid(self, identifier):\n        return True\n```"}}}
{"dataset": "coderEval", "task_id": "62b45e145108cfac7f210a07", "original_prompt": "def validate(self, inventory, extract_spec_version=False):\n\t\"\"\"\n\tValidate a given inventory. If extract_spec_version is True then will look at the type value to determine the specification version. In the case that there is no type value or it isn't valid, then other tests will be based on the version given in self.spec_version. (D)\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass InventoryValidator:\n    def __init__(self, spec_version):\n        self.spec_version = spec_version\n\n    def validate(self, inventory, extract_spec_version=False):\n        if extract_spec_version:\n            type_value = inventory.get('type')\n            if type_value and self.is_valid_type(type_value):\n                self.spec_version = self.get_spec_version_from_type(type_value)\n        \n        return self.run_tests(inventory)\n\n    def is_valid_type(self, type_value):\n        # Placeholder for type validation logic\n        valid_types = {'type1', 'type2', 'type3'}\n        return type_value in valid_types\n\n    def get_spec_version_from_type(self, type_value):\n        # Placeholder for mapping types to spec versions\n        type_to_version = {\n            'type1': 'v1.0',\n            'type2': 'v2.0',\n            'type3': 'v3.0'\n        }\n        return type_to_version.get(type_value, self.spec_version)\n\n    def run_tests(self, inventory):\n        # Placeholder for inventory validation logic based on self.spec_version\n        if self.spec_version == 'v1.0':\n            return self.test_v1(inventory)\n        elif self.spec_version == 'v2.0':\n            return self.test_v2(inventory)\n        elif self.spec_version == 'v3.0':\n            return self.test_v3(inventory)\n        return False\n\n    def test_v1(self, inventory):\n        # Placeholder for version 1.0 specific tests\n        return 'item' in inventory\n\n    def test_v2(self, inventory):\n        # Placeholder for version 2.0 specific tests\n        return 'quantity' in inventory and inventory['quantity'] > 0\n\n    def test_v3(self, inventory):\n        # Placeholder for version 3.0 specific tests\n        return 'price' in inventory and inventory['price'] >= 0\n```"}}}
{"dataset": "coderEval", "task_id": "62b45e145108cfac7f210a09", "original_prompt": "def check_digests_present_and_used(self, manifest_files, digests_used):\n\t\"\"\"\n\tCheck all digests in manifest that are needed are present and used. Return error() in the class.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean implementation of the `check_digests_present_and_used` method in Python:\n\n```python\nclass DigestChecker:\n    def __init__(self):\n        self.errors = []\n\n    def error(self, message):\n        self.errors.append(message)\n\n    def check_digests_present_and_used(self, manifest_files, digests_used):\n        all_digests = set()\n        for manifest_file in manifest_files:\n            with open(manifest_file, 'r') as file:\n                for line in file:\n                    digest = self.extract_digest(line)\n                    if digest:\n                        all_digests.add(digest)\n\n        missing_digests = set(digests_used) - all_digests\n        if missing_digests:\n            self.error(f\"Missing digests: {', '.join(missing_digests)}\")\n\n        unused_digests = all_digests - set(digests_used)\n        if unused_digests:\n            self.error(f\"Unused digests: {', '.join(unused_digests)}\")\n\n    def extract_digest(self, line):\n        # Assuming the digest is the first word in the line\n        parts = line.split()\n        return parts[0] if parts else None\n```\n\n### Key Points:\n- The `DigestChecker` class holds the method and a list to store error messages.\n- The `error` method appends error messages to the `errors` list.\n- `check_digests_present_and_used` reads each manifest file, extracts digests, and checks for missing or unused digests.\n- `extract_digest` assumes the digest is the first word in each line and extracts it. Adjust as needed based on the actual format of your manifest files."}}}
{"dataset": "coderEval", "task_id": "62b45e165108cfac7f210a16", "original_prompt": "def validate_as_prior_version(self, prior):\n\t\"\"\"\n\tCheck that prior is a valid prior version of the current inventory object. The input variable prior is also expected to be an InventoryValidator object and both self and prior inventories are assumed to have been checked for internal consistency. Return error() in the class.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass InventoryValidator:\n    def validate_as_prior_version(self, prior):\n        if not isinstance(prior, InventoryValidator):\n            return self.error(\"Prior is not an InventoryValidator instance.\")\n\n        if self.major_version < prior.major_version:\n            return self.error(\"Current major version is less than prior version.\")\n        \n        if self.major_version == prior.major_version:\n            if self.minor_version < prior.minor_version:\n                return self.error(\"Current minor version is less than prior version.\")\n            \n            if self.minor_version == prior.minor_version:\n                if self.patch_version < prior.patch_version:\n                    return self.error(\"Current patch version is less than prior version.\")\n\n        return None\n\n    def error(self, message):\n        return {\"error\": message}\n\n    @property\n    def major_version(self):\n        # Placeholder for actual implementation\n        return 1\n\n    @property\n    def minor_version(self):\n        # Placeholder for actual implementation\n        return 0\n\n    @property\n    def patch_version(self):\n        # Placeholder for actual implementation\n        return 0\n```\n\nThis code checks that the `prior` object is a valid prior version of the current inventory object by comparing major, minor, and patch versions. It returns an error if the conditions are not met. The `error` method is used to format error messages."}}}
{"dataset": "coderEval", "task_id": "62b45e165108cfac7f210a17", "original_prompt": "def get_logical_path_map(inventory, version):\n\t\"\"\"\n\tReturns the file paths of the states in the inventory in the dict type.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef get_logical_path_map(inventory, version):\n    logical_path_map = {}\n    for item_id, item_info in inventory.items():\n        logical_path = item_info.get('logical_path')\n        if logical_path and item_info.get('version') == version:\n            logical_path_map[item_id] = logical_path\n    return logical_path_map\n```"}}}
{"dataset": "coderEval", "task_id": "62b45e175108cfac7f210a19", "original_prompt": "def validate_fixity(self, fixity, manifest_files):\n\t\"\"\"\n\tValidate fixity block in inventory. Check the structure of the fixity block and makes sure that only files listed in the manifest are referenced. Return error() in the class.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass Validator:\n    def error(self, message):\n        # Assume this method handles error reporting\n        print(f\"Error: {message}\")\n\n    def validate_fixity(self, fixity, manifest_files):\n        if not isinstance(fixity, dict):\n            self.error(\"Fixity must be a dictionary.\")\n            return\n\n        for file, checksum in fixity.items():\n            if not isinstance(checksum, str):\n                self.error(f\"Checksum for {file} must be a string.\")\n                return\n\n            if file not in manifest_files:\n                self.error(f\"File {file} in fixity block is not listed in the manifest.\")\n                return\n```\n\nThis code defines a `Validator` class with a `validate_fixity` method that checks the structure of the `fixity` block and ensures that only files listed in `manifest_files` are referenced. It uses an `error` method to handle error reporting."}}}
{"dataset": "coderEval", "task_id": "62b463153879012d19481498", "original_prompt": "def files_list(path):\n\t\"\"\"\n\tReturn the files in given path.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\n\ndef files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n```"}}}
{"dataset": "coderEval", "task_id": "62b463153879012d1948149a", "original_prompt": "def _group_files_by_xml_filename(source, xmls, files):\n\t\"\"\"\n\tGroups files by xmls and returns data in dict format.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef _group_files_by_xml_filename(source, xmls, files):\n    grouped_files = {}\n    \n    for xml in xmls:\n        xml_filename = xml.split('/')[-1]\n        grouped_files[xml_filename] = {\n           'source': source,\n            'xml': xml,\n            'files': [file for file in files if file.startswith(xml_filename)]\n        }\n    \n    return grouped_files\n```"}}}
{"dataset": "coderEval", "task_id": "62b463153879012d1948149b", "original_prompt": "def match_file_by_prefix(prefix, file_path):\n\t\"\"\"\n\tGiven a filepath, return true if the basename of the filepath is startswith the given prefix plus \"-\" or the given prefix plus \".\"\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\n\ndef match_file_by_prefix(prefix, file_path):\n    basename = os.path.basename(file_path)\n    return basename.startswith(f\"{prefix}-\") or basename.startswith(f\"{prefix}.\")\n\n# Example usage:\n# print(match_file_by_prefix(\"data\", \"data-2023.csv\"))  # True\n# print(match_file_by_prefix(\"data\", \"data_v1.csv\"))    # False\n# print(match_file_by_prefix(\"report\", \"report.2023.txt\"))  # True\n```"}}}
{"dataset": "coderEval", "task_id": "62b463153879012d1948149c", "original_prompt": "def select_filenames_by_prefix(prefix, files):\n\t\"\"\"\n\tFor each file in files, return all files taht match the given prefix\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef select_filenames_by_prefix(prefix, files):\n    return [file for file in files if file.startswith(prefix)]\n```"}}}
{"dataset": "coderEval", "task_id": "62b463153879012d1948149d", "original_prompt": "def _explore_folder(folder):\n\t\"\"\"\n\tGroups files in the given group by using _group_files_by_xml_filename.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\nfrom collections import defaultdict\n\ndef _group_files_by_xml_filename(files):\n    grouped = defaultdict(list)\n    for file in files:\n        if file.endswith('.xml'):\n            base_name = os.path.splitext(file)[0]\n            grouped[base_name].append(file)\n    return grouped\n\ndef _explore_folder(folder):\n    if not os.path.isdir(folder):\n        return {}\n\n    all_files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n    return _group_files_by_xml_filename(all_files)\n```"}}}
{"dataset": "coderEval", "task_id": "62b463153879012d1948149f", "original_prompt": "def _eval_file(prefix, file_path):\n\t\"\"\"\n\tIdentify the type of the given file. Return None if the file do not match the given prefix or the type of the file is xml. Return dict with the key of component_id, file_path if the type of the file is \"pdf\", return dict with the key of component_id, file_path, ftype, file_path if the type of the file is not \"pdf\".\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\n\ndef _eval_file(prefix, file_path):\n    if not file_path.startswith(prefix) or file_path.endswith('.xml'):\n        return None\n\n    component_id = os.path.splitext(os.path.basename(file_path))[0]\n    file_type = 'pdf' if file_path.endswith('.pdf') else 'other'\n\n    if file_type == 'pdf':\n        return {component_id: file_path}\n    else:\n        return {component_id: file_path, 'ftype': file_type, 'file_path': file_path}\n```"}}}
{"dataset": "coderEval", "task_id": "62b463153879012d194814a1", "original_prompt": "def add_rendition(self, lang, file_path):\n\t\"\"\"\n\tAssign the filepath invoke by filepath() in the class to \"lang\" in _renditions in the class.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass ExampleClass:\n    def __init__(self):\n        self._renditions = {}\n\n    def filepath(self):\n        # This method should return the intended file path\n        return \"example/path/to/file\"\n\n    def add_rendition(self, lang, file_path=None):\n        if file_path is None:\n            file_path = self.filepath()\n        self._renditions[lang] = file_path\n```"}}}
{"dataset": "coderEval", "task_id": "62b463163879012d194814a2", "original_prompt": "def add_asset(self, basename, file_path):\n\t\"\"\"\n\tAssign the filepath invoke by filepath() in the class to \"basename\" in _assets in the class.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean Python implementation for the described task:\n\n```python\nclass AssetManager:\n    def __init__(self):\n        self._assets = {}\n\n    def filepath(self, file_path):\n        # Assume this method processes the file_path in some manner\n        return file_path\n\n    def add_asset(self, basename, file_path):\n        processed_path = self.filepath(file_path)\n        self._assets[basename] = processed_path\n```\n\nThis implementation defines a simple `AssetManager` class with an `_assets` dictionary to store assets. The `add_asset` method assigns a processed file path to a given basename within the `_assets` dictionary. The processing of the file path is done through a `filepath` method, which is assumed to be defined elsewhere in the class."}}}
{"dataset": "coderEval", "task_id": "62b463163879012d194814a4", "original_prompt": "def _explore_zipfile(zip_path):\n\t\"\"\"\n\tGroups the given zip path by using _group_files_by_xml_filename.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\nfrom collections import defaultdict\nfrom zipfile import ZipFile\n\ndef _group_files_by_xml_filename(file_names):\n    grouped_files = defaultdict(list)\n    for file_name in file_names:\n        base_name = os.path.splitext(file_name)[0]\n        grouped_files[base_name].append(file_name)\n    return grouped_files\n\ndef _explore_zipfile(zip_path):\n    with ZipFile(zip_path, 'r') as zip_file:\n        file_names = zip_file.namelist()\n        return _group_files_by_xml_filename(file_names)\n```"}}}
{"dataset": "coderEval", "task_id": "62b463163879012d194814a6", "original_prompt": "def files_list_from_zipfile(zip_path):\n\t\"\"\"\n\tReturn the files in the given zip path.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean and concise Python code for the task without docstrings or comments:\n\n```python\nimport zipfile\n\ndef files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path, 'r') as z:\n        return z.namelist()\n```\n\nThis function opens the specified zip file and returns a list of the file names contained within it."}}}
{"dataset": "coderEval", "task_id": "62b4631b3879012d194814dd", "original_prompt": "def fix_namespace_prefix_w(content):\n\t\"\"\"\n\tReplace \"w:st=\" in content with \"w-st=\".\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean Python function to replace occurrences of \"w:st=\" with \"w-st=\" in the given content:\n\n```python\ndef fix_namespace_prefix_w(content):\n    return content.replace(\"w:st=\", \"w-st=\")\n```\n\nThis function uses the `replace` method to substitute all instances of \"w:st=\" with \"w-st=\" in the input string `content` and returns the modified string."}}}
{"dataset": "coderEval", "task_id": "62b463283879012d1948153d", "original_prompt": "def match_pubdate(node, pubdate_xpaths):\n\t\"\"\"\n\tFor the given node, returns the first match in the pubdate_xpaths list.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean implementation of the `match_pubdate` function in Python:\n\n```python\nfrom lxml import etree\n\ndef match_pubdate(node, pubdate_xpaths):\n    for xpath in pubdate_xpaths:\n        result = node.xpath(xpath)\n        if result:\n            return result[0]\n    return None\n```\n\nThis function iterates over the `pubdate_xpaths` list, attempting to find a match using each XPath expression on the given `node`. It returns the first non-empty result or `None` if no matches are found."}}}
{"dataset": "coderEval", "task_id": "62b463303879012d19481579", "original_prompt": "def _extract_number_and_supplment_from_issue_element(issue):\n\t\"\"\"\n\tReturn the possible values of number and sup from the contents of issue.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef _extract_number_and_supplement_from_issue_element(issue):\n    import re\n\n    # Define regex pattern to extract number and supplement\n    pattern = r'(\\d+)(?:\\s*Supplement\\s*(\\d+)?)?'\n\n    # Search for pattern in the issue content\n    match = re.search(pattern, issue)\n\n    # Extract number and supplement if match is found\n    number = int(match.group(1)) if match else None\n    supplement = int(match.group(2)) if match and match.group(2) else None\n\n    return number, supplement\n\n# Example usage:\n# issue_content = \"123 Supplement 2\"\n# print(_extract_number_and_supplement_from_issue_element(issue_content))\n```\n\nThis code defines a function that uses a regular expression to extract a number and an optional supplement from a given string. It returns these values as a tuple."}}}
{"dataset": "coderEval", "task_id": "62b46740d2f69a53b466171a", "original_prompt": "def pretty(self, indent=0, debug=False):\n\t\"\"\"\n\tReturn a pretty formatted representation of self. obj = f\"'{self.obj}'\" if isinstance(self.obj, str) else repr(self.obj) return (\" \" * indent) + f\"{self.__class__.__name__}({debug_details}{obj})\"\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Below is the Python code for the `pretty` method, ensuring it's clean and avoids code smells:\n\n```python\ndef pretty(self, indent=0, debug=False):\n    debug_details = f\"debug=True, \" if debug else \"\"\n    obj = f\"'{self.obj}'\" if isinstance(self.obj, str) else repr(self.obj)\n    return (\" \" * indent) + f\"{self.__class__.__name__}({debug_details}{obj})\"\n```\n\nThis code maintains clarity and simplicity while adhering to the requirements."}}}
{"dataset": "coderEval", "task_id": "62b46746d2f69a53b4661722", "original_prompt": "def absorb(self, args):\n\t\"\"\"\n\tGiven an `args` sequence of expressions, return a new list of expression applying absorption.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass ExpressionTransformer:\n    def absorb(self, args):\n        def absorb_pair(a, b):\n            # Assuming expressions are tuples of the form (operator, operand1, operand2)\n            if a[0] == b[0] and a[1] == b[1]:\n                return a\n            return (a[0], a[1], b)\n        \n        result = []\n        i = 0\n        while i < len(args):\n            if i + 1 < len(args) and args[i][0] == args[i + 1][0] and args[i][1] == args[i + 1][1]:\n                result.append(absorb_pair(args[i], args[i + 1]))\n                i += 2\n            else:\n                result.append(args[i])\n                i += 1\n        return result\n```\n\nThis code defines a class `ExpressionTransformer` with a method `absorb` that processes a sequence of expressions to apply absorption. The expressions are assumed to be tuples, and the absorption logic is implemented in the `absorb_pair` function."}}}
{"dataset": "coderEval", "task_id": "62b86707b4d922cb0e688c2a", "original_prompt": "def on(self, hook):\n\t\"\"\"\n\tReturn a decorator function to add a new handler to the \"hook\" in the registry in the class.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Certainly! Below is a Python implementation for the `on` method, which returns a decorator for adding a new handler to a specified hook in a registry:\n\n```python\nclass HookRegistry:\n    def __init__(self):\n        self.registry = {}\n\n    def on(self, hook):\n        def decorator(func):\n            if hook not in self.registry:\n                self.registry[hook] = []\n            self.registry[hook].append(func)\n            return func\n        return decorator\n\n# Usage example:\nclass ExampleClass(HookRegistry):\n    pass\n\nexample = ExampleClass()\n\n@example.on('example_hook')\ndef example_handler():\n    print(\"Example handler executed.\")\n\nexample_registry = example.registry\nprint(example_registry)\n```\n\n### Explanation:\n- **Class `HookRegistry`**: Contains a registry (a dictionary) to store hooks and their corresponding handlers.\n- **Method `on`**: Takes a `hook` name and returns a `decorator` function.\n- **Decorator Function**: Adds the decorated function to the list of handlers for the specified hook in the registry.\n- **Usage Example**: Demonstrates how to use the `on` method to register a handler for a specific hook."}}}
{"dataset": "coderEval", "task_id": "62b86729b4d922cb0e688c2f", "original_prompt": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n\t\"\"\"\n\tCreates a configuration with some simple parameters, the key parameters contains \"tls\", \"authentication\", \"authorization\", \"etcd\", \"docs\", and \"log\".\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    tls = {\n        \"enabled\": False,\n        \"cert_file\": \"/etc/ssl/certs/tls.crt\",\n        \"key_file\": \"/etc/ssl/private/tls.key\"\n    }\n    \n    authentication = {\n        \"type\": \"simple\",\n        \"htpasswd\": \"/etc/auth/htpasswd\"\n    }\n    \n    authorization = {\n        \"enabled\": True,\n        \"policies\": \"/etc/authorization/policies.json\"\n    }\n    \n    etcd = {\n        \"host\": etcd_host,\n        \"port\": etcd_port\n    }\n    \n    docs = {\n        \"url\": \"https://docs.example.com\"\n    }\n    \n    log = {\n        \"level\": \"info\",\n        \"output\": \"/var/log/app.log\"\n    }\n    \n    config = {\n        \"user\": user,\n        \"tls\": tls,\n        \"authentication\": authentication,\n        \"authorization\": authorization,\n        \"etcd\": etcd,\n        \"docs\": docs,\n        \"log\": log\n    }\n    \n    return config\n```"}}}
{"dataset": "coderEval", "task_id": "62b8a4a4755ee91dce50a3d2", "original_prompt": "def _fromutc(self, dt):\n\t\"\"\"\n\tGiven a timezone datetime in a given timezone, calculates a timezone datetime in a new timezone.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom datetime import datetime, timedelta, timezone\n\nclass TimezoneConverter:\n    def __init__(self, offset_hours, name):\n        self.offset = timedelta(hours=offset_hours)\n        self.name = name\n\n    def _fromutc(self, dt):\n        if dt.tzinfo is None or dt.tzinfo.utcoffset(dt) is None:\n            raise ValueError(\"The input datetime must be timezone-aware\")\n\n        utc_time = dt.astimezone(timezone.utc)\n        local_time = utc_time + self.offset\n        return local_time.replace(tzinfo=timezone(self.offset)).astimezone(self.offset)\n\n# Example usage:\n# converter = TimezoneConverter(-5, 'EST')\n# dt_utc = datetime(2023, 10, 10, 15, 0, tzinfo=timezone.utc)\n# dt_converted = converter._fromutc(dt_utc)\n# print(dt_converted)\n```\n\nThis code defines a `TimezoneConverter` class with a `_fromutc` method that converts a timezone-aware datetime from UTC to a specified timezone. The class is initialized with an offset in hours and a name for the timezone. The `_fromutc` method ensures the input datetime is timezone-aware and performs the conversion."}}}
{"dataset": "coderEval", "task_id": "62b8982f755ee91dce50a241", "original_prompt": "def normalized(self):\n\t\"\"\"\n\tNormalize all units of time to integers.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a Python class with a `normalized` method that demonstrates how to normalize time units to integers. This example assumes you have hours, minutes, and seconds as attributes of a class.\n\n```python\nclass TimeNormalizer:\n    def __init__(self, hours, minutes, seconds):\n        self.hours = hours\n        self.minutes = minutes\n        self.seconds = seconds\n\n    def normalized(self):\n        total_seconds = self.hours * 3600 + self.minutes * 60 + self.seconds\n\n        normalized_hours = total_seconds // 3600\n        remaining_seconds = total_seconds % 3600\n        normalized_minutes = remaining_seconds // 60\n        normalized_seconds = remaining_seconds % 60\n\n        return {\n            'hours': normalized_hours,\n           'minutes': normalized_minutes,\n           'seconds': normalized_seconds\n        }\n\n# Example usage:\n# time_instance = TimeNormalizer(1, 75, 120)\n# normalized_time = time_instance.normalized()\n# print(normalized_time)  # Output: {'hours': 3,'minutes': 5,'seconds': 0}\n```\n\nThis code defines a `TimeNormalizer` class with a method `normalized` that converts the time attributes into total seconds, then recalculates the hours, minutes, and seconds to ensure they are all integers."}}}
{"dataset": "coderEval", "task_id": "62b89640755ee91dce50a114", "original_prompt": "def tzname_in_python2(namefunc):\n\t\"\"\"\n\tChange unicode output into bytestrings in Python 2\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport sys\n\ndef tzname_in_python2(namefunc):\n    result = namefunc()\n    if isinstance(result, str) and not isinstance(result, bytes) and sys.version_info[0] == 2:\n        return result.encode('utf-8')\n    return result\n```"}}}
{"dataset": "coderEval", "task_id": "62b87d24d292efb640a55670", "original_prompt": "def get_versions():\n\t\"\"\"\n\tObtains the version information. If the version information cannot be obtained, the default value is returned.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean Python function that achieves the described task, assuming the version information is obtained from a dictionary. If accessing the version information fails, it returns a default value.\n\n```python\ndef get_versions():\n    version_info = {\n        \"major\": 1,\n        \"minor\": 0,\n        \"patch\": 0\n    }\n\n    default_version = {\n        \"major\": 0,\n        \"minor\": 0,\n        \"patch\": 0\n    }\n\n    try:\n        return {\n            \"version\": f\"{version_info['major']}.{version_info['minor']}.{version_info['patch']}\"\n        }\n    except KeyError:\n        return {\n            \"version\": f\"{default_version['major']}.{default_version['minor']}.{default_version['patch']}\"\n        }\n```\n\nThis function attempts to retrieve the version information from a dictionary and constructs a version string. If the required keys are not found, it returns a default version string."}}}
{"dataset": "coderEval", "task_id": "62b87d24d292efb640a5566f", "original_prompt": "def render(pieces, style):\n\t\"\"\"\n\tInput pieces and a style, render the pieces to the corresponding style.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef render(pieces, style):\n    if style == 'uppercase':\n        return [piece.upper() for piece in pieces]\n    elif style == 'lowercase':\n        return [piece.lower() for piece in pieces]\n    elif style == 'titlecase':\n        return [piece.title() for piece in pieces]\n    elif style =='reverse':\n        return [piece[::-1] for piece in pieces]\n    else:\n        return pieces\n```"}}}
{"dataset": "coderEval", "task_id": "62b87d24d292efb640a5566d", "original_prompt": "def plus_or_dot(pieces):\n\t\"\"\"\n\tReturn \".\" If the closet-tag of the pieces contains \"+\", otherwise, return \"+\".\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef plus_or_dot(pieces):\n    closest_tag = pieces[-1].split('/')[-1]\n    return '.' if '+' in closest_tag else '+'\n```"}}}
{"dataset": "coderEval", "task_id": "62b87d23d292efb640a5566b", "original_prompt": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n\t\"\"\"\n\tCall the given command(s).\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean implementation of the `run_command` function in Python:\n\n```python\nimport subprocess\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    full_command = [commands] + args\n    stderr_option = subprocess.STDOUT if hide_stderr else subprocess.PIPE\n\n    process = subprocess.Popen(\n        full_command,\n        cwd=cwd,\n        stdout=subprocess.PIPE,\n        stderr=stderr_option,\n        env=env\n    )\n\n    stdout, stderr = process.communicate()\n\n    if verbose:\n        print(f\"Command: {' '.join(full_command)}\")\n        if stdout:\n            print(f\"Output:\\n{stdout.decode()}\")\n        if stderr and not hide_stderr:\n            print(f\"Error:\\n{stderr.decode()}\")\n\n    return process.returncode, stdout.decode(), stderr.decode() if stderr else ''\n```\n\nThis code defines the `run_command` function, which uses the `subprocess` module to execute a command with optional arguments, working directory, environment variables, and verbosity settings. The function captures the standard output and error, returning the process's return code along with the captured output."}}}
{"dataset": "coderEval", "task_id": "62b87d23d292efb640a55668", "original_prompt": "def get_config():\n\t\"\"\"\n\tReturn a new VersioneerConfig() and set various attribute of it.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass VersioneerConfig:\n    def __init__(self):\n        self.version_file = None\n        self.tag_prefix = None\n        self.parent_dir = None\n        self.verbose = False\n\ndef get_config():\n    config = VersioneerConfig()\n    config.version_file = \"VERSION\"\n    config.tag_prefix = \"v\"\n    config.parent_dir = \".\"\n    config.verbose = True\n    return config\n```"}}}
{"dataset": "coderEval", "task_id": "62b87d23d292efb640a55667", "original_prompt": "def register_vcs_handler(vcs, method):\n\t\"\"\"\n\tCreate decorator to mark a method as the handler of a object\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass VCSHandlerRegistry:\n    def __init__(self):\n        self.handlers = {}\n\n    def register_vcs_handler(self, vcs):\n        def decorator(method):\n            self.handlers[vcs] = method\n            return method\n        return decorator\n\n    def get_handler(self, vcs):\n        return self.handlers.get(vcs)\n\n\n# Usage example:\n\nregistry = VCSHandlerRegistry()\n\n@registry.register_vcs_handler('git')\ndef git_handler():\n    print(\"Handling Git operations\")\n\n@registry.register_vcs_handler('hg')\ndef hg_handler():\n    print(\"Handling Mercurial operations\")\n\n# Retrieving and using the handlers\ngit_handler = registry.get_handler('git')\nif git_handler:\n    git_handler()\n\nhg_handler = registry.get_handler('hg')\nif hg_handler:\n    hg_handler()\n```\n\nThis code defines a `VCSHandlerRegistry` class that allows registering and retrieving handlers for different version control systems (VCS). The `register_vcs_handler` method is used as a decorator to associate a method with a specific VCS. The `get_handler` method retrieves the registered handler for a given VCS."}}}
{"dataset": "coderEval", "task_id": "62b45e945108cfac7f210a4a", "original_prompt": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n\t\"\"\"\n\tValidate storage root hierarchy.\n\nReturns:\n    num_objects - number of objects checked\n    good_objects - number of objects checked that were found to be valid\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean Python implementation for the `validate_hierarchy` method without docstrings and comments:\n\n```python\nclass StorageRootValidator:\n    def __init__(self):\n        self.objects = []  # Assume this holds objects to validate\n\n    def validate_object(self, obj, check_digests):\n        # Placeholder logic for object validation\n        if check_digests:\n            return obj.get('digest') is not None\n        return True\n\n    def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n        num_objects = 0\n        good_objects = 0\n\n        for obj in self.objects:\n            num_objects += 1\n            if validate_objects and self.validate_object(obj, check_digests):\n                good_objects += 1\n            elif show_warnings:\n                print(f\"Warning: Object {obj.get('id')} is invalid.\")\n\n        return num_objects, good_objects\n```\n\nThis code assumes the presence of a list of objects within the class and a placeholder method for object validation. Adjust the `validate_object` method as needed for your specific validation logic."}}}
{"dataset": "coderEval", "task_id": "62b45e515108cfac7f210a3c", "original_prompt": "def initialize(self):\n\t\"\"\"\n\tCreate and initialize a new OCFL storage root.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\nimport shutil\nimport json\n\nclass OCFLStorageRoot:\n\n    def __init__(self, root_directory):\n        self.root_directory = root_directory\n        self.manifest_filename ='manifest.json'\n        self.inventory_filename = 'inventory.json'\n        self.version_directory_name = 'v1'\n\n    def initialize(self):\n        os.makedirs(self.root_directory, exist_ok=True)\n\n        manifest_path = os.path.join(self.root_directory, self.manifest_filename)\n        inventory_path = os.path.join(self.root_directory, self.inventory_filename)\n        version_directory_path = os.path.join(self.root_directory, self.version_directory_name)\n\n        os.makedirs(version_directory_path, exist_ok=True)\n\n        manifest = {\n            \"0\": {\n                \"created\": \"2023-10-01T00:00:00Z\",\n                \"state\": \"active\",\n                \"message\": \"Initial version\"\n            }\n        }\n\n        inventory = {\n            \"0\": {\n                \"id\": \"sha256-abcdef1234567890\",\n                \"digestAlgorithm\": \"sha256\",\n                \"contentDirectory\": self.version_directory_name,\n                \"manifest\": manifest_path,\n                \"signature\": None,\n                \"message\": \"Initial inventory\"\n            }\n        }\n\n        with open(manifest_path, 'w') as manifest_file:\n            json.dump(manifest, manifest_file, indent=2)\n\n        with open(inventory_path, 'w') as inventory_file:\n            json.dump(inventory, inventory_file, indent=2)\n```\n\nThis code defines a class `OCFLStorageRoot` with an `initialize` method that creates and initializes a new OCFL storage root. It sets up directories and JSON files for the manifest and inventory, ensuring a clean and straightforward implementation."}}}
{"dataset": "coderEval", "task_id": "62b45e2eb89c9fd354170232", "original_prompt": "def next_version(version):\n\t\"\"\"\n\tGiven next version identifier following existing pattern\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef next_version(version):\n    major, minor, patch = map(int, version.split('.'))\n    patch += 1\n    if patch == 10:\n        patch = 0\n        minor += 1\n        if minor == 10:\n            minor = 0\n            major += 1\n    return f\"{major}.{minor}.{patch}\"\n```"}}}
{"dataset": "coderEval", "task_id": "62b45e23e0d4551b0392c90a", "original_prompt": "def validate_version_inventories(self, version_dirs):\n\t\"\"\"\n\tEach version SHOULD have an inventory up to that point.\n\nAlso keep a record of any content digests different from those in the root inventory\nso that we can also check them when validating the content.\n\nversion_dirs is an array of version directory names and is assumed to be in\nversion sequence (1, 2, 3...).\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean Python function for the described task:\n\n```python\nimport os\nimport hashlib\n\nclass VersionValidator:\n    def __init__(self):\n        self.digest_mismatches = []\n\n    def calculate_digest(self, file_path):\n        hash_md5 = hashlib.md5()\n        with open(file_path, \"rb\") as f:\n            for chunk in iter(lambda: f.read(4096), b\"\"):\n                hash_md5.update(chunk)\n        return hash_md5.hexdigest()\n\n    def validate_version_inventories(self, version_dirs):\n        root_inventory_path = 'root_inventory.txt'\n        root_digests = self._read_inventory(root_inventory_path)\n\n        for version_dir in version_dirs:\n            version_inventory_path = os.path.join(version_dir, 'inventory.txt')\n            if not os.path.exists(version_inventory_path):\n                print(f\"Missing inventory for version {version_dir}\")\n                continue\n\n            version_digests = self._read_inventory(version_inventory_path)\n            self._compare_digests(root_digests, version_digests, version_dir)\n\n    def _read_inventory(self, inventory_path):\n        digests = {}\n        if os.path.exists(inventory_path):\n            with open(inventory_path, 'r') as f:\n                for line in f:\n                    parts = line.strip().split()\n                    if len(parts) == 2:\n                        file_path, digest = parts\n                        digests[file_path] = digest\n        return digests\n\n    def _compare_digests(self, root_digests, version_digests, version_dir):\n        for file_path, root_digest in root_digests.items():\n            version_digest = version_digests.get(file_path)\n            if version_digest and version_digest!= root_digest:\n                self.digest_mismatches.append((version_dir, file_path, root_digest, version_digest))\n                print(f\"Digest mismatch in {version_dir} for {file_path}: {root_digest}!= {version_digest}\")\n```\n\n### Key Points:\n- **Class Structure:** Encapsulated in a class `VersionValidator` to maintain state (e.g., `digest_mismatches`).\n- **Helper Methods:** Used `_read_inventory` to read inventory files and `_compare_digests` to compare digests.\n- **Digest Calculation:** Placeholder `calculate_digest` method for calculating file digests if needed.\n- **Error Handling:** Checks for missing inventory files and reports digest mismatches.\n- **Output:** Prints messages for missing inventories and digest mismatches."}}}
{"dataset": "coderEval", "task_id": "62b45e21e0d4551b0392c8ed", "original_prompt": "def find_path_type(path):\n\t\"\"\"\n\tReturn a string indicating the type of thing at the given path\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\n\ndef find_path_type(path):\n    if not os.path.exists(path):\n        return \"Does Not Exist\"\n    \n    if os.path.isfile(path):\n        return \"File\"\n    \n    if os.path.isdir(path):\n        return \"Directory\"\n    \n    if os.path.islink(path):\n        return \"Symbolic Link\"\n    \n    return \"Unknown\"\n```"}}}
{"dataset": "coderEval", "task_id": "62b45b396decaeff903e1001", "original_prompt": "def amend_bzparams(self, params, bug_ids):\n\t\"\"\"\n\tAmend the Bugzilla params\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass BugzillaHandler:\n    def amend_bzparams(self, params, bug_ids):\n        if not isinstance(params, dict):\n            raise ValueError(\"params must be a dictionary\")\n        \n        if not isinstance(bug_ids, list):\n            raise ValueError(\"bug_ids must be a list\")\n        \n        if 'ids' in params:\n            raise ValueError(\"params already contains 'ids' key\")\n\n        params['ids'] = ','.join(map(str, bug_ids))\n```\n\nThis code ensures that `params` is a dictionary and `bug_ids` is a list, raises errors if conditions are not met, and updates the `params` dictionary with a comma-separated string of `bug_ids`."}}}
{"dataset": "coderEval", "task_id": "62b4567ed7d32e5b55cc83d9", "original_prompt": "def deep_merge_nodes(nodes):\n\t\"\"\"\n\tMerge any node values corresponding to duplicate keys and return the result. If there are colliding keys with non-MappingNode values, the last of the values remains.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom collections.abc import Mapping\n\ndef deep_merge_nodes(nodes):\n    result = {}\n    \n    for node in nodes:\n        for key, value in node.items():\n            if key in result:\n                if isinstance(result[key], Mapping) and isinstance(value, Mapping):\n                    result[key] = deep_merge_nodes([result[key], value])\n                else:\n                    result[key] = value\n            else:\n                result[key] = value\n                \n    return result\n```"}}}
{"dataset": "coderEval", "task_id": "62b4567ad7d32e5b55cc83af", "original_prompt": "def parse_arguments(*arguments):\n\t\"\"\"\n\tGiven command-line arguments with which this script was invoked, parse the arguments and return  them as an ArgumentParser instance\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport argparse\n\ndef parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for arg in arguments:\n        if \"=\" in arg:\n            key, value = arg.split(\"=\", 1)\n            parser.add_argument(f\"--{key}\", default=value)\n        else:\n            parser.add_argument(f\"--{arg}\", action=\"store_true\")\n    return parser.parse_args()\n```"}}}
{"dataset": "coderEval", "task_id": "62b45679d7d32e5b55cc83a9", "original_prompt": "def parser_flags(parser):\n\t\"\"\"\n\tGiven an argparse.ArgumentParser instance, return its argument flags in a space-separated\nstring.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport argparse\n\ndef parser_flags(parser):\n    return''.join(action.option_strings for action in parser._actions if action.option_strings)\n\n# Example usage:\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-f', '--foo', help='foo help')\n    parser.add_argument('-b', '--bar', help='bar help')\n    print(parser_flags(parser))  # Output: -f --foo -b --bar\n```"}}}
{"dataset": "coderEval", "task_id": "62b45665d7d32e5b55cc8365", "original_prompt": "def parse_arguments(*unparsed_arguments):\n\t\"\"\"\n\tParses parameters and returns them as dict maps\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport argparse\n\ndef parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--name', type=str, help='Name of the user')\n    parser.add_argument('--age', type=int, help='Age of the user')\n    parser.add_argument('--email', type=str, help='Email address of the user')\n    \n    args = parser.parse_args(unparsed_arguments)\n    return vars(args)\n```\n\nThis code uses the `argparse` module to parse command-line arguments into a dictionary. Adjust the arguments as needed for your specific use case."}}}
{"dataset": "coderEval", "task_id": "62b45665d7d32e5b55cc8364", "original_prompt": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n\t\"\"\"\n\tGiven a sequence of arguments and a dict from subparser name to argparse.ArgumentParser\ninstance, give each requested action's subparser a shot at parsing all arguments. This allows\ncommon arguments like \"--repository\" to be shared across multiple subparsers.\n\nReturn the result as a tuple of (a dict mapping from subparser name to a parsed namespace of\narguments, a list of remaining arguments not claimed by any subparser).\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a Python function that accomplishes the task described, without using docstrings or comments:\n\n```python\nimport argparse\n\ndef parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_args = {}\n    remaining_args = unparsed_arguments[:]\n    \n    for subparser_name, subparser in subparsers.items():\n        try:\n            # Attempt to parse arguments for this subparser\n            args, remaining = subparser.parse_known_args(remaining_args)\n            parsed_args[subparser_name] = args\n            remaining_args = remaining\n        except SystemExit:\n            # If parsing fails, continue to the next subparser\n            continue\n    \n    return parsed_args, remaining_args\n\n# Example usage:\n# subparsers = {'subcmd1': argparse.ArgumentParser(prog='subcmd1'),\n#              'subcmd2': argparse.ArgumentParser(prog='subcmd2')}\n# unparsed_arguments = ['subcmd1', '--repository','repo1','subcmd2', '--repository','repo2']\n# result = parse_subparser_arguments(unparsed_arguments, subparsers)\n```\n\nThis function iterates over each subparser, attempting to parse the provided arguments. If a subparser successfully parses the arguments, it updates the `parsed_args` dictionary and modifies `remaining_args` to exclude the parsed arguments. If parsing fails (e.g., due to incorrect arguments for that subparser), it catches the `SystemExit` exception and continues to the next subparser."}}}
{"dataset": "coderEval", "task_id": "62b45665d7d32e5b55cc8363", "original_prompt": "def make_parsers():\n\t\"\"\"\n\tBuild a parser and its subparsers and return them as a tuple.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport argparse\n\ndef make_parsers():\n    parser = argparse.ArgumentParser(description=\"Main parser\")\n    subparsers = parser.add_subparsers(dest=\"command\", required=True)\n\n    parser_a = subparsers.add_parser(\"command_a\", help=\"Sub-command A\")\n    parser_a.add_argument(\"--option-a\", type=int, help=\"Option for command A\")\n\n    parser_b = subparsers.add_parser(\"command_b\", help=\"Sub-command B\")\n    parser_b.add_argument(\"--option-b\", type=str, help=\"Option for command B\")\n\n    return parser, subparsers\n```"}}}
{"dataset": "coderEval", "task_id": "62b438ba66fea644fe22cca2", "original_prompt": "def deep_merge_nodes(nodes):\n\t\"\"\"\n\tmerge any node values corresponding to duplicate keys and return the result. If there are colliding keys with non-MappingNode values, the last of the values remains.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef deep_merge_nodes(nodes):\n    def merge(dict1, dict2):\n        for key, value in dict2.items():\n            if key in dict1:\n                if isinstance(dict1[key], dict) and isinstance(value, dict):\n                    merge(dict1[key], value)\n                elif isinstance(dict1[key], list) and isinstance(value, list):\n                    dict1[key].extend(value)\n                else:\n                    dict1[key] = value\n            else:\n                dict1[key] = value\n\n    result = {}\n    for node in nodes:\n        merge(result, node)\n    return result\n```"}}}
{"dataset": "coderEval", "task_id": "62b438b666fea644fe22cc78", "original_prompt": "def parse_arguments(*arguments):\n\t\"\"\"\n\tGiven command-line arguments with which this script was invoked, parse the arguments and return  them as an ArgumentParser instance\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "To create a function that parses command-line arguments without using docstrings or comments, you can utilize the `argparse` module in Python. Here's a clean implementation:\n\n```python\nimport argparse\n\ndef parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n\n    # Define arguments\n    parser.add_argument('--example', type=str, help='Example argument')\n    parser.add_argument('--number', type=int, help='Example integer argument')\n    parser.add_argument('--flag', action='store_true', help='Example boolean flag')\n\n    # Parse the provided arguments\n    parsed_args = parser.parse_args(arguments)\n    \n    return parsed_args\n\n# Example usage:\n# args = parse_arguments('--example', 'test', '--number', '42', '--flag')\n# print(args.example)  # Output: test\n# print(args.number)   # Output: 42\n# print(args.flag)     # Output: True\n```\n\n### Explanation:\n- **argparse.ArgumentParser()**: Initializes the argument parser.\n- **parser.add_argument()**: Adds arguments that the script can accept. You can define the type, help text, and other properties.\n- **parser.parse_args(arguments)**: Parses the arguments provided to the function and returns them as an object where each argument is an attribute.\n\nThis code defines a basic structure for parsing command-line arguments. You can expand it by adding more arguments as needed for your specific use case."}}}
{"dataset": "coderEval", "task_id": "62b438b666fea644fe22cc72", "original_prompt": "def parser_flags(parser):\n\t\"\"\"\n\tGiven an argparse.ArgumentParser instance, return its argument flags in a space-separated\nstring.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport argparse\n\ndef parser_flags(parser):\n    flags = []\n    for action in parser._actions:\n        for option_string in action.option_strings:\n            flags.append(option_string)\n    return''.join(sorted(flags))\n\n# Example usage\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-a', '--alpha')\n    parser.add_argument('-b', '--beta')\n    parser.add_argument('--gamma')\n    print(parser_flags(parser))\n```\n\nThis code defines a function `parser_flags` that extracts and returns the argument flags from an `argparse.ArgumentParser` instance as a sorted, space-separated string. The example usage demonstrates how to use the function."}}}
{"dataset": "coderEval", "task_id": "62b438b566fea644fe22cc70", "original_prompt": "def bash_completion():\n\t\"\"\"\n\tProduce the borgmatic command by introspecting borgmatic's command-line argument parsers.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "To achieve the task of generating bash completion for the `borgmatic` command by introspecting its command-line argument parsers, you can use the `argparse` module in Python to extract the arguments and generate the necessary bash completion script. Below is a Python function that accomplishes this:\n\n```python\nimport argparse\nimport sys\n\ndef bash_completion():\n    parser = argparse.ArgumentParser(prog='borgmatic', add_help=False)\n    subparsers = parser.add_subparsers(dest='command')\n\n    # Example subcommands and arguments for demonstration purposes\n    # In a real scenario, these would be dynamically loaded or introspected\n    subparser_a = subparsers.add_parser('backup', add_help=False)\n    subparser_a.add_argument('--host')\n    subparser_a.add_argument('--remote-path')\n\n    subparser_b = subparsers.add_parser('restore', add_help=False)\n    subparser_b.add_argument('--archive')\n    subparser_b.add_argument('--destination')\n\n    # Simulate parsing to introspect arguments\n    parser.parse_args(['--help'])\n\n    commands = {p.name: p for p in subparsers.choices.values()}\n    completions = ['_borgmatic']\n\n    for command, subparser in commands.items():\n        completions.append(f'{{%s}} () {{' % command)\n        completions.append('    local cur prev opts')\n        completions.append('    COMPREPLY=()')\n        completions.append('    cur=\"${COMP_WORDS[COMP_CWORD]}\"')\n        completions.append('    prev=\"${COMP_WORDS[COMP_CWORD-1]}\"')\n\n        options = subparser._option_string_actions.keys()\n        completions.append('    opts=\"' + \" \".join(sorted(options)) + '\"')\n\n        completions.append('    COMPREPLY=( $(compgen -W \"${opts}\" -- ${cur}) )')\n        completions.append('    return 0')\n        completions.append('}')\n    \n    completions_script = \"\\n\".join(completions)\n    print(completions_script)\n\nif __name__ == '__main__':\n    bash_completion()\n```\n\n### Explanation:\n- **Argument Parsing Setup**: The script sets up an `argparse.ArgumentParser` with subparsers to mimic the structure of `borgmatic` commands.\n- **Introspection**: It parses `--help` to introspect the arguments without actually executing any command.\n- **Completion Script Generation**: For each command, it generates a bash function that uses `compgen` to provide command-line completions.\n- **Output**:"}}}
{"dataset": "coderEval", "task_id": "62b438a266fea644fe22cc2e", "original_prompt": "def parse_arguments(*unparsed_arguments):\n\t\"\"\"\n\tGiven command-line arguments with which this script was invoked, parse the arguments and return\nthem as a dict mapping from subparser name (or \"global\") to an argparse.Namespace instance.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport argparse\n\ndef parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser(description=\"Parse command-line arguments.\")\n    subparsers = parser.add_subparsers(dest='command', required=True)\n\n    # Example subparser\n    example_parser = subparsers.add_parser('example')\n    example_parser.add_argument('--option', type=str, help='An example option.')\n\n    # Parse the arguments\n    args = parser.parse_args(unparsed_arguments)\n\n    # Organize the parsed arguments into a dictionary\n    parsed_args = {'global': vars(args)}\n    \n    if args.command:\n        parsed_args[args.command] = vars(args)\n\n    return parsed_args\n```\n\nThis code defines a function `parse_arguments` that uses `argparse` to parse command-line arguments and returns them as a dictionary. It includes a global namespace and any subparser-specific arguments."}}}
{"dataset": "coderEval", "task_id": "62b438a266fea644fe22cc2d", "original_prompt": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n\t\"\"\"\n\tGiven a sequence of arguments and a dict from subparser name to argparse.ArgumentParser\ninstance, give each requested action's subparser a shot at parsing all arguments. This allows\ncommon arguments like \"--repository\" to be shared across multiple subparsers.\n\nReturn the result as a tuple of (a dict mapping from subparser name to a parsed namespace of\narguments, a list of remaining arguments not claimed by any subparser).\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport argparse\n\ndef parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = unparsed_arguments.copy()\n\n    for name, subparser in subparsers.items():\n        try:\n            # Attempt to parse the arguments for this subparser\n            parsed_namespace = subparser.parse_known_args(remaining_arguments)[0]\n            parsed_arguments[name] = parsed_namespace\n            # Remove the arguments that were successfully parsed\n            remaining_arguments = [arg for arg in remaining_arguments if arg not in parsed_namespace._get_kwargs()]\n        except SystemExit:\n            continue  # If parsing fails, just continue to the next subparser\n\n    return parsed_arguments, remaining_arguments\n\n# Example usage:\nif __name__ == \"__main__\":\n    # Create a top-level parser and subparsers\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='command')\n\n    # Define subparsers\n    parser_a = subparsers.add_parser('subcommand_a')\n    parser_a.add_argument('--repository', type=str)\n\n    parser_b = subparsers.add_parser('subcommand_b')\n    parser_b.add_argument('--repository', type=str)\n\n    # Example unparsed arguments\n    unparsed_args = ['subcommand_a', '--repository','repo1','subcommand_b', '--repository','repo2', 'extra_arg']\n\n    # Call the function\n    parsed_args, remaining_args = parse_subparser_arguments(unparsed_args, {'subcommand_a': parser_a,'subcommand_b': parser_b})\n\n    print(\"Parsed Arguments:\", parsed_args)\n    print(\"Remaining Arguments:\", remaining_args)\n```\n\nThis code defines the `parse_subparser_arguments` function that attempts to parse arguments for each subparser. It returns a dictionary of parsed arguments and a list of arguments not claimed by any subparser."}}}
{"dataset": "coderEval", "task_id": "62b438a266fea644fe22cc2c", "original_prompt": "def make_parsers():\n\t\"\"\"\n\tBuild a top-level parser and its subparsers and return them as a tuple.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport argparse\n\ndef make_parsers():\n    parser = argparse.ArgumentParser(description=\"Top-level parser\")\n    subparsers = parser.add_subparsers(dest=\"command\", help=\"Subcommands\")\n\n    # Example subparser 1\n    parser_a = subparsers.add_parser(\"command_a\", help=\"Description for command_a\")\n    parser_a.add_argument(\"arg1\", type=int, help=\"An integer argument\")\n\n    # Example subparser 2\n    parser_b = subparsers.add_parser(\"command_b\", help=\"Description for command_b\")\n    parser_b.add_argument(\"--flag\", action=\"store_true\", help=\"A flag for command_b\")\n\n    return parser, subparsers\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd5f", "original_prompt": "def paging(response, max_results):\n\t\"\"\"\n\tReturn every response with the length of max_results\n    Args:\n    response (list): WAPI response.\n    max_results (int): Maximum number of objects to be returned in one page.\n    Returns:\n        Generator object with WAPI response split page by page.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef paging(response, max_results):\n    for i in range(0, len(response), max_results):\n        yield response[i:i + max_results]\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd60", "original_prompt": "def size_to_bytes(size: str) -> int:\n\t\"\"\"\n\tConvert human readable file size to bytes\n\n    Args:\n            size: str, a string representing a human readable file size (eg: '500K')\n    Returns:\n            int: file size in bytes\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef size_to_bytes(size: str) -> int:\n    units = {\"B\": 1, \"K\": 1024, \"M\": 1024**2, \"G\": 1024**3, \"T\": 1024**4}\n    for unit in units:\n        if size.endswith(unit):\n            return int(float(size.rstrip(unit)) * units[unit])\n    return int(size)\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd61", "original_prompt": "def _dictsum(dicts):\n\t\"\"\"\n\tSum values with the same key in the dictionaries. And return a new dictionary.\n    Example:\n        given two dictionaries: dict1: {'a': 1, 'b': 2}, dict2: {'a': 5, 'b': 0}\n        return a dictionary: dic:{'a': 6, 'b': 2}\n    Returns: dict\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom collections import defaultdict\n\ndef _dictsum(dicts):\n    result = defaultdict(int)\n    for d in dicts:\n        for key, value in d.items():\n            result[key] += value\n    return dict(result)\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd62", "original_prompt": "def _replace_url_args(url, url_args):\n\t\"\"\"\n\tReplace the value in url with the value in url_args\n    If url_args has a value, iterate over the keys and values from url_args.\n    Then replace the keys of the first parameter with values.\n    Returns: the modified url.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef _replace_url_args(url, url_args):\n    for key, value in url_args.items():\n        url = url.replace(f\"{{{key}}}\", str(value))\n    return url\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd63", "original_prompt": "def is_none_string(val: any) -> bool:\n\t\"\"\"\n\tCheck if a string represents a None value.\n    Returns:\n        Return True if the type of val is string and the lowercase of val is equal to 'none', otherwise return False\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef is_none_string(val: any) -> bool:\n    return isinstance(val, str) and val.lower() == 'none'\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd64", "original_prompt": "def strip_root(path, root):\n\t\"\"\"\n\tRemove root from path. If fails, throw exception\n\n    Returns:\n        A path without root\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\n\ndef strip_root(path, root):\n    if not path.startswith(root):\n        raise ValueError(\"Path does not start with the specified root\")\n    stripped_path = os.path.relpath(path, root)\n    return stripped_path\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd65", "original_prompt": "def parser_flags(parser):\n\t\"\"\"\n\tGiven an argparse.ArgumentParser instance, return its argument flags in a space-separated string.\n    Args:\n        script: argparse.ArgumentParser instance\n\n    Returns:\n        argument flags in a space-separated string\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport argparse\n\ndef parser_flags(parser):\n    flags = [f'--{arg.dest}' for arg in parser._actions if arg.option_strings]\n    return''.join(flags)\n\n# Example usage:\n# parser = argparse.ArgumentParser()\n# parser.add_argument('--example', help='An example flag')\n# parser.add_argument('--another', help='Another example flag')\n# print(parser_flags(parser))\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd66", "original_prompt": "def was_processed(processed, path_name, verbose):\n\t\"\"\"\n\tCheck if a file or directory has already been processed.\n\n    To prevent recursion, expand the path name to an absolution path\n    call this function with a set that will store all the entries and\n    the entry to test. If the entry is already in the set, report the issue\n    and return ``True``. Otherwise, add the entry to the set and return\n    ``False`` to allow the path to be processed.\n\n    Args:\n        processed: Set to store processed pathnames\n        path_name: Path to a directory or file\n        verbose: True if verbose output is requested\n\n    Returns:\n        True if it's already in the set. False if not.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\n\ndef was_processed(processed, path_name, verbose):\n    abs_path = os.path.abspath(path_name)\n    if abs_path in processed:\n        if verbose:\n            print(f\"Already processed: {abs_path}\")\n        return True\n    processed.add(abs_path)\n    return False\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd67", "original_prompt": "def vertex3tuple(vertices):\n\t\"\"\"\n\tGet 3 points for each vertex of the polygon.\n    This will include the vertex and the 2 points on both sides of the vertex\n    If the subscript is out of bounds, take the value of index as 0\n    Args:\n        vertices: vertices to be converted\n\n    Returns:\n        A list where the elements of vertices represented by tuple\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef vertex3tuple(vertices):\n    n = len(vertices)\n    result = []\n    \n    for i in range(n):\n        prev_index = (i - 1) % n\n        next_index = (i + 1) % n\n        triplet = (vertices[prev_index], vertices[i], vertices[next_index])\n        result.append(triplet)\n    \n    return result\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd68", "original_prompt": "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n\t\"\"\"\n\tConvert a number to a string, using the given alphabet.\n    The number represents a short uuid.\n    The output has the most significant digit first.\n    @param number: Int value\n    @param alphabet : List with letters\n    @param padding : Optional with int value\n    @return  string value corresponded to int\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom typing import List, Optional\n\ndef int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    if number == 0:\n        return alphabet[0] * (padding or 1)\n    \n    base = len(alphabet)\n    result = []\n    \n    while number > 0:\n        number, remainder = divmod(number, base)\n        result.append(alphabet[remainder])\n    \n    result.reverse()\n    \n    if padding and len(result) < padding:\n        result = [alphabet[0]] * (padding - len(result)) + result\n    \n    return ''.join(result)\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd69", "original_prompt": "def _replace_register(flow_params, register_number, register_value):\n\t\"\"\"\n\tReplace the value of flow_params[register_number] with flow_params[register_value] and delete flow_params[register_value]\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean implementation of the `_replace_register` function in Python:\n\n```python\ndef _replace_register(flow_params, register_number, register_value):\n    flow_params[register_number] = flow_params.pop(register_value, None)\n```\n\nThis function replaces the value at `register_number` with the value at `register_value` and removes the entry at `register_value` using `pop`, which also handles the case where `register_value` might not exist by returning `None`."}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd6a", "original_prompt": "def replace_dots(value, arg):\n\t\"\"\"\n\tReplaces all values of '.' to arg from the given string\n    Args:\n        value: old string\n        arg: new string to replace '.'\n    Returns:\n        str, the replaced string\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef replace_dots(value, arg):\n    return value.replace('.', arg)\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd6b", "original_prompt": "def subclasses(cls):\n\t\"\"\"\n\tReturn all subclasses of a class, recursively\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef subclasses(cls):\n    result = []\n    for subclass in cls.__subclasses__():\n        result.append(subclass)\n        result.extend(subclasses(subclass))\n    return result\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd6d", "original_prompt": "def string_to_int(string: str, alphabet: List[str]) -> int:\n\t\"\"\"\n\tConvert a string to a number, using the given alphabet.\n    :param string: a string consist of the letters in alphabet\n    :param alphabet: list of letters\n    :return: int, the corresponding number of the given string using the given transition rule.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom typing import List\n\ndef string_to_int(string: str, alphabet: List[str]) -> int:\n    base = len(alphabet)\n    num = 0\n    for char in string:\n        num = num * base + alphabet.index(char)\n    return num\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd6f", "original_prompt": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n\t\"\"\"\n\tGiven an url and a destination path, retrieve and extract .tar.gz archive which contains 'desc' file for each package\n\n        Args:\n            url: url of the .tar.gz archive to download\n            destination_path: the path on disk where to extract archive\n        Returns:\n                path where the archive is extracted to\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport requests\nfrom pathlib import Path\nimport tarfile\n\ndef get_repo_archive(url: str, destination_path: Path) -> Path:\n    response = requests.get(url, stream=True)\n    response.raise_for_status()\n\n    temp_file_path = destination_path / 'archive.tar.gz'\n    with open(temp_file_path, 'wb') as file:\n        for chunk in response.iter_content(chunk_size=8192):\n            file.write(chunk)\n\n    with tarfile.open(temp_file_path, 'r:gz') as tar:\n        tar.extractall(path=destination_path)\n\n    temp_file_path.unlink()\n    return destination_path\n```\n\nThis code handles downloading a `.tar.gz` file from a given URL, extracting its contents to a specified destination path, and then deleting the temporary downloaded archive file."}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd70", "original_prompt": "def os_is_mac():\n\t\"\"\"\n\tChecks if the os is macOS\n\n    :return: bool, True is macOS, otherwise False.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport platform\n\ndef os_is_mac():\n    return platform.system() == 'Darwin'\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd71", "original_prompt": "def regex_dict(item):\n\t\"\"\"\n\tConvert *.cpp keys to regex keys.\nGiven a dict where the keys are all filenames with wildcards,\nconvert only the keys into equivalent regexes and leave the values intact.\n\nArgs:\n    item: dict to convert\nReturns:\n    dict with keys converted to regexes\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport re\n\ndef regex_dict(item):\n    regex_item = {}\n    for key, value in item.items():\n        regex_key = re.escape(key).replace(r'\\*', '.*').replace(r'\\?', '.')\n        regex_item[re.compile(f\"^{regex_key}$\")] = value\n    return regex_item\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd72", "original_prompt": "def unquote(name):\n\t\"\"\"\n\tRemove quote from the given name with regular expression.\n    Args:\n        name: input name\n    Returns:\n        name after removal\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport re\n\ndef unquote(name):\n    return re.sub(r'^[\"\\']|[\"\\']$', '', name)\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd73", "original_prompt": "def split(s, platform='this'):\n\t\"\"\"\n\tSplit the input str under given platform, return the splitting result\n    If platform equals 'this', auto-detect current platform.\n    If platform equals 1, use POSIX style.\n    If platform equals 0, use Windows/CMD style.\n    Args:\n        s: input str\n        platform: 'this' = auto from current platform; 1 = POSIX; 0 = Windows/CMD\n    Returns:\n        a list of splitting str\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\nimport platform\n\ndef split(s, platform='this'):\n    if platform == 'this':\n        current_platform = platform.system().lower()\n        if 'win' in current_platform:\n            platform = 0\n        else:\n            platform = 1\n    if platform == 1:\n        return s.split(':')\n    elif platform == 0:\n        return s.split(';')\n    return s.split(os.pathsep)\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd74", "original_prompt": "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n\t\"\"\"\n\tGiven an existing archive_path, uncompress it.\n    Returns a file repo url which can be used as origin url.\n\n    This does not deal with the case where the archive passed along does not exist.\n    @param archive_path : archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\nfrom pathlib import Path\nfrom typing import Optional, Union\nimport shutil\nimport subprocess\nimport tempfile\n\ndef prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    tmp_path = Path(tmp_path) if isinstance(tmp_path, str) else tmp_path\n    tmp_repo_path = tempfile.mkdtemp(dir=tmp_path)\n    \n    if os.path.exists(archive_path):\n        command = ['tar', '-xzf', archive_path, '-C', tmp_repo_path]\n        if filename:\n            command.extend(['--strip-components=1', f'{filename}/'])\n        subprocess.run(command, check=True)\n\n    repo_url = f'file://{tmp_repo_path}'\n    return repo_url\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd75", "original_prompt": "def addignored(ignored):\n\t\"\"\"\n\tUse the git command to obtain the file names\u3002\n    Turn the file names into a list, sort the list for only ignored files\n    return those files as a single string with each filename separated by a comma.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean Python function to achieve the task described:\n\n```python\nimport subprocess\n\ndef addignored(ignored):\n    command = ['git', 'ls-files', '--others', '--ignored', '--exclude-standard']\n    result = subprocess.run(command, capture_output=True, text=True)\n    files = result.stdout.splitlines()\n\n    ignored_files = [file for file in files if file in ignored]\n    ignored_files.sort()\n\n    return ','.join(ignored_files)\n```\n\nThis function uses the `subprocess` module to run the `git ls-files` command, filters the files based on the `ignored` list, sorts them, and returns them as a comma-separated string."}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd76", "original_prompt": "def match(filename):\n\t\"\"\"\n\tCheck if the type of the given filename is 'doxyfile'\n\n    Args:\n        filename: filename to be check\n    Returns:\n        Return True if the type of the given filename in lower case is 'doxyfile'\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef match(filename):\n    return filename.lower() == 'doxyfile'\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4982e6aefcf4aabbd77", "original_prompt": "def parse_frequency(frequency):\n\t\"\"\"\n\tGiven a frequency string with a number and a unit of time, return a corresponding\n     datetime.timedelta instance.\n     If the frequency is None or \"always\", return None.\n     Raise ValueError if the given frequency cannot be parsed.\n     For instance, given \"3 timeunit\", return datetime.timedelta(timeunit=3)\n\n     @param frequency :  A frequency string \"number timeunit\"\n\n    @return str, the corresponding datetime\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom datetime import timedelta\nimport re\n\ndef parse_frequency(frequency):\n    if frequency is None or frequency == \"always\":\n        return None\n    \n    match = re.match(r\"(\\d+)\\s*(\\w+)\", frequency)\n    if not match:\n        raise ValueError(\"Invalid frequency format\")\n    \n    number, unit = match.groups()\n    number = int(number)\n    \n    unit_map = {\n        \"second\": \"seconds\",\n        \"minute\": \"minutes\",\n        \"hour\": \"hours\",\n        \"day\": \"days\",\n        \"week\": \"weeks\",\n        \"month\": \"days\",\n        \"year\": \"days\"\n    }\n    \n    if unit not in unit_map:\n        raise ValueError(\"Unsupported time unit\")\n    \n    if unit in [\"month\", \"year\"]:\n        if unit == \"month\":\n            number *= 30  # Approximate month as 30 days\n        else:\n            number *= 365  # Approximate year as 365 days\n    \n    return timedelta(**{unit_map[unit]: number})\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd78", "original_prompt": "def is_local(host):\n\t\"\"\"\n\tChecks if the host is the localhost,\n    the localhost include local IP, user name, local domain name, `localhost` and `127.0.0.1`\n\n    Args:\n        host: The hostname or ip\n\n    Returns:\n        True if the host is the localhost else False\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport socket\n\ndef is_local(host):\n    try:\n        host_ip = socket.gethostbyname(host)\n    except socket.gaierror:\n        return False\n\n    return (host_ip in (\"127.0.0.1\", \"localhost\") or\n            host_ip.startswith(\"127.\") or\n            host == \"localhost\" or\n            host in socket.gethostbyname_ex(socket.gethostname())[2])\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd79", "original_prompt": "def make_find_paths(find_paths):\n\t\"\"\"\n\tGiven a sequence of path, transform all path into glob patterns. Pass through existing patterns untouched.\n\n    Args:\n        find_paths: sequence of path\n    Returns:\n        tuple of transformed path\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean implementation of the `make_find_paths` function in Python:\n\n```python\nimport fnmatch\n\ndef make_find_paths(find_paths):\n    transformed_paths = tuple(\n        pattern if '*' in pattern or '?' in pattern else f\"*{pattern}*\" \n        for pattern in find_paths\n    )\n    return transformed_paths\n```\n\nThis function checks each path in the `find_paths` sequence. If a path already contains a glob pattern (indicated by `*` or `?`), it leaves it unchanged. Otherwise, it transforms it into a glob pattern by surrounding it with `*`."}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd7a", "original_prompt": "def is_gitbash():\n\t\"\"\"\n\tCheck whether the current program is run in a Windows gitbash terminal\n\n    Returns:\n            boolean, True if gitbash else False\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef is_gitbash():\n    import os\n    return 'MINGW64' in os.environ.get('MSYSTEM', '') or 'MINGW32' in os.environ.get('MSYSTEM', '')\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd7b", "original_prompt": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n\t\"\"\"\n\tGiven a rendered config YAML, write it out to target file.\n    But if the file already exists and overwrite is False,\n    abort before writing anything.\n    If the file does not exist, create it.\n    Write to the file otherwise.\n\n    Returns: None\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\nimport yaml\n\ndef write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if os.path.exists(config_filename) and not overwrite:\n        raise FileExistsError(f\"File '{config_filename}' already exists and overwrite is False.\")\n    \n    with open(config_filename, 'w') as config_file:\n        yaml.dump(rendered_config, config_file)\n        os.chmod(config_file.name, mode)\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd7c", "original_prompt": "def oneline(script, seperator=\" && \"):\n\t\"\"\"\n\tConvert a script to one line command with the given seperator.\n\n        Args:\n                script: str\n                separator: str\n        Returns:\n                str, the one-line command.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef oneline(script, separator=\" && \"):\n    return separator.join(line.strip() for line in script.splitlines() if line.strip())\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd7d", "original_prompt": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n\t\"\"\"\n\tRun a function in a sub-process\n\n    Args:\n            func: function, the function to be run. It must be in a module that is importable.\n            *args: str. Any additional command line arguments to be passed in\n                        the first argument to ``subprocess.run``.\n            extra_env: dict[str, str]. Any additional environment variables to be set for the subprocess.\n    Returns:\n            CompletedProcess instance\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport subprocess\nimport multiprocessing\nimport os\nimport importlib.util\nimport sys\n\ndef subprocess_run_helper(func_module_name, func_name, *args, timeout, extra_env=None):\n    def worker(q, module_name, function_name, func_args):\n        try:\n            spec = importlib.util.find_spec(module_name)\n            if spec is None:\n                raise ImportError(f\"Module {module_name} not found\")\n            module = importlib.util.module_from_spec(spec)\n            sys.modules[module_name] = module\n            spec.loader.exec_module(module)\n            func = getattr(module, function_name)\n            result = func(*func_args)\n            q.put(subprocess.CompletedProcess(args=func_args, returncode=0, stdout=result, stderr=None))\n        except Exception as e:\n            q.put(subprocess.CompletedProcess(args=func_args, returncode=1, stdout=None, stderr=str(e)))\n\n    if extra_env is None:\n        extra_env = {}\n\n    q = multiprocessing.Queue()\n    p = multiprocessing.Process(target=worker, args=(q, func_module_name, func_name, args))\n    p.start()\n    p.join(timeout)\n\n    if p.is_alive():\n        p.terminate()\n        p.join()\n        return subprocess.CompletedProcess(args=args, returncode=-1, stdout=None, stderr=\"Timeout\")\n\n    return q.get()\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd7e", "original_prompt": "def _resolve_string(matcher):\n\t\"\"\"\n\tGet the value from environment given a matcher containing a name and an optional default value in its group dict.\n    If the variable is not defined in environment and no default value is provided, an Error is raised.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\n\ndef _resolve_string(matcher):\n    name = matcher.group('name')\n    default = matcher.group('default')\n\n    value = os.getenv(name)\n    if value is None:\n        if default is not None:\n            return default\n        raise ValueError(f\"Environment variable '{name}' not found and no default value provided.\")\n    \n    return value\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd7f", "original_prompt": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n\t\"\"\"\n\tParse an image href into composite parts import urllib.\n\n    :param image_href: href of an image\n    :returns: a tuple of the form (image_id, netloc, use_ssl)\n    :raises ValueError:\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom typing import Tuple\nfrom urllib.parse import urlparse\n\ndef _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    parsed_url = urlparse(image_href)\n    image_id = parsed_url.path.strip('/')\n    netloc = parsed_url.netloc\n    use_ssl = parsed_url.scheme == 'https'\n    return image_id, netloc, use_ssl\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd80", "original_prompt": "def remove_ending_os_sep(input_list):\n\t\"\"\"\n\tIf input list is None, return []\n    Iterate over a string list and remove trailing os seperator characters.\n    Each string is tested if its length is greater than one and if the last\n    character is the pathname seperator.\n    Returns:\n    A list after removing trailing os seperator characters.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\n\ndef remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    return [s[:-1] if len(s) > 1 and s[-1] == os.sep else s for s in input_list]\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd82", "original_prompt": "def get_pattern(pattern, strip=True):\n\t\"\"\"\n\tConvert a string to a regex pattern object\n\n    Args:\n            pattern: str or regex pattern object\n            strip: boolean, whether the spaces in the start/end will be stripped\n    Returns:\n            regex pattern object\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport re\n\ndef get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        if strip:\n            pattern = pattern.strip()\n        pattern = re.escape(pattern)\n        pattern = re.sub(r'\\\\ ', '[\\\\s]*', pattern)\n        pattern = re.sub(r'\\\\A', '^', pattern)\n        pattern = re.sub(r'\\\\Z', '$', pattern)\n        pattern = re.compile(pattern)\n    elif not pattern.flags & re.RegexFlag.A:\n        pattern = re.compile(pattern.pattern, pattern.flags)\n    return pattern\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd83", "original_prompt": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n\t\"\"\"\n\tA list of command is given. Run the given command(s) with the given arguments use a subprocess. Return the running result (stdout and returncode)\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport subprocess\nimport os\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    for command in commands:\n        full_command = [command] + args\n        process_env = os.environ.copy()\n        if env:\n            process_env.update(env)\n\n        stderr = subprocess.PIPE if hide_stderr else None\n\n        if verbose:\n            print(f\"Running: {' '.join(full_command)}\")\n\n        result = subprocess.run(\n            full_command,\n            cwd=cwd,\n            env=process_env,\n            stdout=subprocess.PIPE,\n            stderr=stderr,\n            text=True\n        )\n\n        if verbose:\n            print(f\"Output:\\n{result.stdout}\")\n\n        return result.stdout, result.returncode\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd84", "original_prompt": "def is_ipv4(target):\n\t\"\"\"\n\tTest if IPv4 address or not.\n\n   Returns: Boolean, True if target is IPv4 address, else False.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef is_ipv4(target):\n    parts = target.split('.')\n    if len(parts)!= 4:\n        return False\n    for part in parts:\n        if not part.isdigit() or not 0 <= int(part) <= 255:\n            return False\n        if part[0] == '0' and len(part) > 1:\n            return False\n    return True\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd85", "original_prompt": "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n\t\"\"\"\n\t Find the roots in some sort of transitive hierarchy.\n\n    find_roots(graph, rdflib.RDFS.subClassOf)\n    will return a set of all roots of the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of\n    RDFS.subClassOf or SKOS.broader\n\n    Args:\n        graph: Graph Class Object\n        prop: URIRef Class Object\n        roots: Optional list with set type\n    Return:\n        roots: a set with nodes\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom typing import Optional, Set\nfrom rdflib import Graph, URIRef, Node\n\ndef find_roots(graph: Graph, prop: URIRef, roots: Optional[Set[Node]] = None) -> Set[Node]:\n    if roots is None:\n        roots = set()\n\n    subjects = set(graph.subjects(predicate=prop))\n    objects = set(graph.objects(subject=None, predicate=prop))\n\n    all_children = subjects - objects\n\n    for child in all_children:\n        roots.add(child)\n        find_roots(graph, prop, roots)\n\n    return roots\n```\n\nThis code recursively identifies root nodes in a transitive hierarchy by checking for nodes that are children (subjects) but not parents (objects) in the given graph."}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd86", "original_prompt": "def _dump_string(obj, dumper=None):\n\t\"\"\"\n\tGiven a python object and serialize it into a YAML stream\n\n    Args:\n        obj: python object\n\n    Returns:\n        YAML stream\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean Python function that serializes a Python object into a YAML stream using the PyYAML library:\n\n```python\nimport yaml\n\ndef _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = yaml.Dumper\n    return yaml.dump(obj, Dumper=dumper)\n```\n\nMake sure you have the PyYAML library installed. You can install it using pip if needed:\n\n```bash\npip install pyyaml\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd87", "original_prompt": "def build_app_logger(name='app', logfile='app.log', debug=True):\n\t\"\"\"\n\tGeneral purpose application logger. Useful mainly for debugging\n    Args:\n        name: The name of logger\n        logfile: The log file need to save\n        debug: is need to debug\n\n    Returns:\n        Returns an instantiated logger object\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport logging\n\ndef build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.DEBUG if debug else logging.INFO)\n\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n    file_handler = logging.FileHandler(logfile)\n    file_handler.setLevel(logging.DEBUG if debug else logging.INFO)\n    file_handler.setFormatter(formatter)\n    logger.addHandler(file_handler)\n\n    stream_handler = logging.StreamHandler()\n    stream_handler.setLevel(logging.DEBUG if debug else logging.INFO)\n    stream_handler.setFormatter(formatter)\n    logger.addHandler(stream_handler)\n\n    return logger\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd88", "original_prompt": "def make_array(shape, dtype=np.dtype(\"float32\")):\n\t\"\"\"\n\tReturns a 0-filled array of the given shape and type.\n\n        Args:\n                shape : tuple\n                    shape of the array to create\n                dtype : `numpy.dtype`\n                    data-type of the array to create\n        Return: array\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport numpy as np\n\ndef make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype=dtype)\n```\n\nThis code defines a function `make_array` that creates and returns a NumPy array filled with zeros. The array's shape and data type are specified by the function's parameters. The default data type is `np.dtype(\"float32\")`."}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd89", "original_prompt": "def gaussian(x):\n\t\"\"\"\n\tCalculate Gaussian centered with u is 0.2 and sigma is 0.1.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport math\n\ndef gaussian(x):\n    u = 0.2\n    sigma = 0.1\n    exponent = -((x - u) ** 2) / (2 * sigma ** 2)\n    return (1 / (sigma * math.sqrt(2 * math.pi))) * math.exp(exponent)\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd8a", "original_prompt": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n\t\"\"\"\n\tGiven a sequence of configuration filenames, load and validate each configuration file. If the configuration file\ncannot be read due to insufficient permissions or error parsing configuration file, the error log will\nbe recorded. Otherwise, return the results as a tuple of: dict of configuration filename to corresponding parsed configuration,\nand sequence of logging.LogRecord instances containing any parse errors.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\nimport logging\nimport yaml\nfrom typing import Tuple, Dict, List, Optional\n\ndef load_configurations(config_filenames, overrides=None, resolve_env=True) -> Tuple[Dict[str, dict], List[logging.LogRecord]]:\n    if overrides is None:\n        overrides = {}\n\n    parsed_configurations = {}\n    error_records = []\n\n    for filename in config_filenames:\n        try:\n            with open(filename, 'r') as file:\n                config_data = yaml.safe_load(file)\n\n            if resolve_env:\n                config_data = {\n                    k: os.path.expandvars(v) if isinstance(v, str) else v\n                    for k, v in config_data.items()\n                }\n\n            parsed_configurations[filename] = {**config_data, **overrides}\n\n        except (IOError, yaml.YAMLError) as e:\n            logging.error(f\"Error reading configuration from {filename}: {e}\")\n            error_records.append(logging.makeLogRecord({\n                'levelname': 'ERROR',\n               'msg': f\"Error reading configuration from {filename}: {e}\",\n                'exc_info': e,\n            }))\n\n    return parsed_configurations, error_records\n```"}}}
{"dataset": "coderEval", "task_id": "62ece4992e6aefcf4aabbd8b", "original_prompt": "def force_string(obj):\n\t\"\"\"\n\tForce decoding obj with 'utf-8' if it is a numpy.bytes or bytes\n\n    Args:\n        obj: consistency config\n\n    Returns:\n        returns the bytes object corresponding to `obj` in case it is a string using UTF-8 else return `obj`\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport numpy as np\n\ndef force_string(obj):\n    if isinstance(obj, (bytes, np.bytes_)):\n        return obj.decode('utf-8')\n    return obj\n```"}}}
{"dataset": "coderEval", "task_id": "62e60723d76274f8a4026b76", "original_prompt": "def from_ticks(cls, ticks, tz=None):\n\t\"\"\"\n\tCreate a time from ticks (nanoseconds since midnight).\n\n:param ticks: nanoseconds since midnight\n:type ticks: int\n:param tz: optional timezone\n:type tz: datetime.tzinfo\n\n:rtype: Time\n\n:raises ValueError: if ticks is out of bounds\n    (0 <= ticks < 86400000000000)\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom datetime import timedelta, datetime\n\nclass Time:\n    @classmethod\n    def from_ticks(cls, ticks, tz=None):\n        if not (0 <= ticks < 86400000000000):\n            raise ValueError(\"ticks is out of bounds (0 <= ticks < 86400000000000)\")\n        \n        seconds, nanoseconds = divmod(ticks, 1_000_000_000)\n        time_of_day = timedelta(seconds=seconds, microseconds=nanoseconds // 1000)\n\n        naive_time = datetime.combine(datetime.today(), datetime.min.time()) + time_of_day\n        if tz:\n            return naive_time.replace(tzinfo=tz)\n        return naive_time.time()\n```"}}}
{"dataset": "coderEval", "task_id": "62e60873d76274f8a4026bd8", "original_prompt": "def protocol_handlers(cls, protocol_version=None):\n\t\"\"\"\n\tReturn a dictionary of available Bolt protocol handlers,\nkeyed by version tuple. If an explicit protocol version is\nprovided, the dictionary will contain either zero or one items,\ndepending on whether that version is supported. If no protocol\nversion is provided, all available versions will be returned.\n\n:param protocol_version: tuple identifying a specific protocol\n    version (e.g. (3, 5)) or None\n:return: dictionary of version tuple to handler class for all\n    relevant and supported protocol versions\n:raise TypeError: if protocol version is not passed in a tuple\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef protocol_handlers(cls, protocol_version=None):\n    def is_supported(version):\n        # Define supported versions for illustration purposes\n        supported_versions = [(3, 5), (4, 0), (4, 1)]\n        return version in supported_versions\n\n    if protocol_version is not None and not isinstance(protocol_version, tuple):\n        raise TypeError(\"protocol version must be a tuple\")\n\n    handlers = {\n        (3, 5): cls.HandlerV35,\n        (4, 0): cls.HandlerV40,\n        (4, 1): cls.HandlerV41,\n    }\n\n    if protocol_version is None:\n        return {version: handler for version, handler in handlers.items() if is_supported(version)}\n    else:\n        return {protocol_version: handlers[protocol_version]} if is_supported(protocol_version) else {}\n```\n\nThis code defines a function that returns a dictionary of Bolt protocol handlers based on the specified protocol version. It checks if the provided version is supported and handles the case where no version is specified by returning all supported versions."}}}
{"dataset": "coderEval", "task_id": "62e60e3bd76274f8a4026d1a", "original_prompt": "def from_raw_values(cls, values):\n\t\"\"\"\n\tCreate a Bookmarks object from a list of raw bookmark string values.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Certainly! Here's a Python class with a class method `from_raw_values` that creates a `Bookmarks` object from a list of raw bookmark string values. I've ensured the code is clean and avoids code smells:\n\n```python\nclass Bookmark:\n    def __init__(self, url):\n        self.url = url\n\nclass Bookmarks:\n    def __init__(self, bookmarks):\n        self.bookmarks = bookmarks\n\n    @classmethod\n    def from_raw_values(cls, values):\n        bookmarks = [Bookmark(url.strip()) for url in values if url.strip()]\n        return cls(bookmarks)\n```\n\nIn this code:\n\n- The `Bookmark` class represents individual bookmarks with a URL.\n- The `Bookmarks` class holds a list of `Bookmark` objects.\n- The `from_raw_values` class method processes a list of raw string values, trims whitespace, and filters out empty strings, then creates `Bookmark` objects and returns a `Bookmarks` instance."}}}
{"dataset": "coderEval", "task_id": "62b87b199a0c4fa8b80b354c", "original_prompt": "def _get_seq_with_type(seq, bufsize=None):\n\t\"\"\"\n\tReturn a (sequence, type) pair.\nSequence is derived from *seq*\n(or is *seq*, if that is of a sequence type).\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a Python function that implements the task you described, with a focus on clean and readable code:\n\n```python\ndef _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, (list, tuple, str)):\n        seq_type = type(seq)\n        result_seq = seq if bufsize is None else seq[:bufsize]\n    else:\n        seq_type = type(seq)\n        result_seq = list(seq) if bufsize is None else list(seq)[:bufsize]\n\n    return result_seq, seq_type\n```\n\n### Explanation:\n- **Type Checking**: The function first checks if `seq` is of a sequence type (list, tuple, or string). If so, it uses the type as is or slices it according to `bufsize`.\n- **Non-sequence Handling**: If `seq` is not a sequence type, it converts it to a list and applies the `bufsize` slice.\n- **Return**: It returns a tuple containing the possibly sliced sequence and its type."}}}
{"dataset": "coderEval", "task_id": "62b87b4f9a0c4fa8b80b3581", "original_prompt": "def scale(self, other=None, recompute=False):\n\t\"\"\"\n\tCompute or set scale (integral of the histogram).\n\nIf *other* is ``None``, return scale of this histogram.\nIf its scale was not computed before,\nit is computed and stored for subsequent use\n(unless explicitly asked to *recompute*).\nNote that after changing (filling) the histogram\none must explicitly recompute the scale\nif it was computed before.\n\nIf a float *other* is provided, rescale self to *other*.\n\nHistograms with scale equal to zero can't be rescaled.\n:exc:`.LenaValueError` is raised if one tries to do that.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass LenaValueError(Exception):\n    pass\n\nclass Histogram:\n    def __init__(self, data):\n        self.data = data\n        self._scale = None\n\n    def _compute_scale(self):\n        return sum(self.data)\n\n    def scale(self, other=None, recompute=False):\n        if other is None:\n            if self._scale is None or recompute:\n                self._scale = self._compute_scale()\n            return self._scale\n\n        if not isinstance(other, (float, int)):\n            raise LenaValueError(\"Provided scale must be a float or int.\")\n        \n        current_scale = self.scale(recompute=recompute)\n        if current_scale == 0:\n            raise LenaValueError(\"Cannot rescale histogram with scale equal to zero.\")\n        \n        factor = other / current_scale\n        self.data = [x * factor for x in self.data]\n        self._scale = other\n```"}}}
{"dataset": "coderEval", "task_id": "62b87b519a0c4fa8b80b3583", "original_prompt": "def scale(self, other=None):\n\t\"\"\"\n\tGet or set the scale of the graph.\n\nIf *other* is ``None``, return the scale of this graph.\n\nIf a numeric *other* is provided, rescale to that value.\nIf the graph has unknown or zero scale,\nrescaling that will raise :exc:`~.LenaValueError`.\n\nTo get meaningful results, graph's fields are used.\nOnly the last coordinate is rescaled.\nFor example, if the graph has *x* and *y* coordinates,\nthen *y* will be rescaled, and for a 3-dimensional graph\n*z* will be rescaled.\nAll errors are rescaled together with their coordinate.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass LenaValueError(Exception):\n    pass\n\nclass Graph:\n    def __init__(self, scale=None, fields=None):\n        self._scale = scale\n        self._fields = fields if fields else {}\n\n    def scale(self, other=None):\n        if other is None:\n            return self._scale\n\n        if self._scale is None or self._scale == 0:\n            raise LenaValueError(\"Cannot rescale a graph with unknown or zero scale.\")\n\n        last_field = next(reversed(self._fields), None)\n        if last_field is None:\n            raise LenaValueError(\"Graph has no fields to rescale.\")\n\n        scale_factor = other / self._scale\n        for field, coordinates in self._fields.items():\n            for i, coord in enumerate(coordinates):\n                if field == last_field:\n                    coordinates[i] = coord * scale_factor\n\n        self._scale = other\n\n```\n\nThis code defines a `Graph` class with a `scale` method that either returns the current scale or rescales the graph if a numeric value is provided. It handles cases where the scale is unknown or zero by raising a custom `LenaValueError`. The method rescales only the last coordinate field in the graph."}}}
{"dataset": "coderEval", "task_id": "62b87b869a0c4fa8b80b35e1", "original_prompt": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n\t\"\"\"\n\tConvert a :class:`.histogram` to a :class:`.graph`.\n\n*make_value* is a function to set the value of a graph's point.\nBy default it is bin content.\n*make_value* accepts a single value (bin content) without context.\n\nThis option could be used to create graph's error bars.\nFor example, to create a graph with errors\nfrom a histogram where bins contain\na named tuple with fields *mean*, *mean_error* and a context\none could use\n\n>>> make_value = lambda bin_: (bin_.mean, bin_.mean_error)\n\n*get_coordinate* defines what the coordinate\nof a graph point created from a histogram bin will be.\nIt can be \"left\" (default), \"right\" and \"middle\".\n\n*field_names* set field names of the graph. Their number\nmust be the same as the dimension of the result.\nFor a *make_value* above they would be\n*(\"x\", \"y_mean\", \"y_mean_error\")*.\n\n*scale* becomes the graph's scale (unknown by default).\nIf it is ``True``, it uses the histogram scale.\n\n*hist* must contain only numeric bins (without context)\nor *make_value* must remove context when creating a numeric graph.\n\nReturn the resulting graph.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom collections import namedtuple\n\nclass Histogram:\n    def __init__(self, bins):\n        self.bins = bins\n\nclass Graph:\n    def __init__(self, points, field_names, scale=None):\n        self.points = points\n        self.field_names = field_names\n        self.scale = scale\n\ndef hist_to_graph(hist, make_value=None, get_coordinate=\"left\", field_names=(\"x\", \"y\"), scale=None):\n    if make_value is None:\n        make_value = lambda bin_: bin_\n\n    points = []\n    for i, bin_ in enumerate(hist.bins):\n        content = make_value(bin_)\n        if get_coordinate == \"left\":\n            x = i\n        elif get_coordinate == \"right\":\n            x = i + 1\n        elif get_coordinate == \"middle\":\n            x = i + 0.5\n        else:\n            raise ValueError(\"Invalid get_coordinate value\")\n        \n        if isinstance(content, tuple):\n            y_values = content\n        else:\n            y_values = (content,)\n\n        point = [x] + list(y_values)\n        points.append(point)\n\n    if scale is True:\n        scale = \"auto\"  # Assuming histogram has a scale attribute or method\n\n    return Graph(points, field_names, scale)\n\n# Example usage\nBin = namedtuple(\"Bin\", [\"mean\", \"mean_error\"])\nhist = Histogram([Bin(1.0, 0.1), Bin(2.0, 0.2)])\nmake_value = lambda bin_: (bin_.mean, bin_.mean_error)\ngraph = hist_to_graph(hist, make_value=make_value, field_names=(\"x\", \"y_mean\", \"y_mean_error\"))\n```"}}}
{"dataset": "coderEval", "task_id": "62b8b4baeb7e40a82d2d1136", "original_prompt": "def _verify(iface, candidate, tentative=False, vtype=None):\n\t\"\"\"\n\tVerify that *candidate* might correctly provide *iface*.\n\nThis involves:\n\n- Making sure the candidate claims that it provides the\n  interface using ``iface.providedBy`` (unless *tentative* is `True`,\n  in which case this step is skipped). This means that the candidate's class\n  declares that it `implements <zope.interface.implementer>` the interface,\n  or the candidate itself declares that it `provides <zope.interface.provider>`\n  the interface\n\n- Making sure the candidate defines all the necessary methods\n\n- Making sure the methods have the correct signature (to the\n  extent possible)\n\n- Making sure the candidate defines all the necessary attributes\n\n:return bool: Returns a true value if everything that could be\n   checked passed.\n:raises zope.interface.Invalid: If any of the previous\n   conditions does not hold.\n\n.. versionchanged:: 5.0\n    If multiple methods or attributes are invalid, all such errors\n    are collected and reported. Previously, only the first error was reported.\n    As a special case, if only one such error is present, it is raised\n    alone, like before.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom zope.interface import Interface, implementer, providedBy, Invalid\n\ndef _verify(iface, candidate, tentative=False, vtype=None):\n    errors = []\n\n    def check_provided_by():\n        if not tentative and not iface.providedBy(candidate):\n            errors.append(\n                f\"{candidate} does not provide {iface}\"\n            )\n\n    def check_methods():\n        missing_methods = [method for method in iface.names() if not hasattr(candidate, method)]\n        if missing_methods:\n            errors.append(\n                f\"Missing methods: {', '.join(missing_methods)}\"\n            )\n\n    def check_method_signatures():\n        for method_name in iface.names():\n            if hasattr(candidate, method_name):\n                candidate_method = getattr(candidate, method_name)\n                iface_method = getattr(iface, method_name, None)\n                if iface_method and callable(iface_method):\n                    if getattr(candidate_method, '__code__', None)!= getattr(iface_method, '__code__', None):\n                        errors.append(\n                            f\"Method {method_name} signature mismatch in {candidate}\"\n                        )\n\n    def check_attributes():\n        missing_attributes = [attr for attr in iface.names() if not hasattr(candidate, attr)]\n        if missing_attributes:\n            errors.append(\n                f\"Missing attributes: {', '.join(missing_attributes)}\"\n            )\n\n    check_provided_by()\n    check_methods()\n    check_method_signatures()\n    check_attributes()\n\n    if errors:\n        if len(errors) == 1:\n            raise Invalid(errors[0])\n        raise Invalid(\"\\n\".join(errors))\n\n    return True\n```"}}}
{"dataset": "coderEval", "task_id": "62b8b4baeb7e40a82d2d1137", "original_prompt": "def verifyObject(iface, candidate, tentative=False):\n\t\"\"\"\n\tVerify that *candidate* might correctly provide *iface*.\n\nThis involves:\n\n- Making sure the candidate claims that it provides the\n  interface using ``iface.providedBy`` (unless *tentative* is `True`,\n  in which case this step is skipped). This means that the candidate's class\n  declares that it `implements <zope.interface.implementer>` the interface,\n  or the candidate itself declares that it `provides <zope.interface.provider>`\n  the interface\n\n- Making sure the candidate defines all the necessary methods\n\n- Making sure the methods have the correct signature (to the\n  extent possible)\n\n- Making sure the candidate defines all the necessary attributes\n\n:return bool: Returns a true value if everything that could be\n   checked passed.\n:raises zope.interface.Invalid: If any of the previous\n   conditions does not hold.\n\n.. versionchanged:: 5.0\n    If multiple methods or attributes are invalid, all such errors\n    are collected and reported. Previously, only the first error was reported.\n    As a special case, if only one such error is present, it is raised\n    alone, like before.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom zope.interface import Interface, implementer, Invalid, providedBy\nfrom inspect import signature, Signature, Parameter\n\ndef verifyObject(iface, candidate, tentative=False):\n    if not tentative and not iface.providedBy(candidate):\n        raise Invalid(f\"{candidate} does not provide {iface}\")\n\n    errors = []\n\n    # Check methods\n    for method_name, method in iface.namesAndDescriptions(1):\n        if method_name not in candidate.__dict__:\n            errors.append(f\"Missing method: {method_name}\")\n            continue\n\n        candidate_method = getattr(candidate, method_name)\n        expected_signature = signature(method)\n        actual_signature = signature(candidate_method)\n\n        if expected_signature!= actual_signature:\n            errors.append(\n                f\"Method {method_name} signature mismatch: \"\n                f\"expected {expected_signature}, got {actual_signature}\"\n            )\n\n    # Check attributes\n    for attr_name, _ in iface.namesAndDescriptions(2):\n        if not hasattr(candidate, attr_name):\n            errors.append(f\"Missing attribute: {attr_name}\")\n\n    if errors:\n        if len(errors) == 1:\n            raise Invalid(errors[0])\n        else:\n            raise Invalid(\"Errors:\\n\" + \"\\n\".join(errors))\n\n    return True\n```"}}}
{"dataset": "coderEval", "task_id": "62b8b4c1eb7e40a82d2d1139", "original_prompt": "def verifyClass(iface, candidate, tentative=False):\n\t\"\"\"\n\tVerify that the *candidate* might correctly provide *iface*.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean implementation of the `verifyClass` function in Python:\n\n```python\ndef verifyClass(iface, candidate, tentative=False):\n    for method in iface:\n        if not hasattr(candidate, method):\n            return False\n        if not callable(getattr(candidate, method)):\n            return False\n    return True\n\n    if tentative:\n        # Additional checks for tentative verification can be added here\n        pass\n```\n\nThis function checks if the `candidate` class or instance has all the methods defined in the `iface` and ensures they are callable. The `tentative` parameter is included for potential future checks."}}}
{"dataset": "coderEval", "task_id": "62b8b559eb7e40a82d2d11f6", "original_prompt": "def determineMetaclass(bases, explicit_mc=None):\n\t\"\"\"\n\tDetermine metaclass from 1+ bases and optional explicit __metaclass__\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is not None:\n        return explicit_mc\n    \n    metaclasses = set()\n    for base in bases:\n        if hasattr(base, '__metaclass__'):\n            metaclasses.add(base.__metaclass__)\n        else:\n            metaclasses.update(getattr(base, '__mro__', ()))\n    \n    if len(metaclasses) == 1:\n        return metaclasses.pop()\n    \n    if len(metaclasses) > 1:\n        metaclasses.discard(type)\n        if len(metaclasses) == 1:\n            return metaclasses.pop()\n        raise TypeError(\"Cannot create a consistent method resolution \"\n                        \"order (MRO) for bases {}.\".format(bases))\n    \n    return type\n```"}}}
{"dataset": "coderEval", "task_id": "62b8d22a48ba5a41d1c3f47d", "original_prompt": "def pop(self, key, default=__marker):\n\t\"\"\"\n\tD.pop(k[,d]) -> v, remove specified key and return the corresponding value.\nIf key is not found, d is returned if given, otherwise KeyError is raised.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean implementation of the `pop` method for a dictionary-like class, avoiding code smells and excluding docstrings and comments:\n\n```python\nclass D:\n    def __init__(self):\n        self._data = {}\n        self.__marker = object()\n\n    def pop(self, key, default=__marker):\n        if key in self._data:\n            return self._data.pop(key)\n        if default is self.__marker:\n            raise KeyError(key)\n        return default\n```\n\nThis code defines a class `D` with a `pop` method that behaves similarly to the `pop` method of a standard dictionary. It uses a special marker object to distinguish between a default value being provided and the absence of a default."}}}
{"dataset": "coderEval", "task_id": "62b8d23748ba5a41d1c3f497", "original_prompt": "def popitem(self):\n\t\"\"\"\n\tRemove and return the `(key, value)` pair least frequently used.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass LFUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.min_freq = 0\n        self.key_to_val = {}\n        self.key_to_freq = {}\n        self.freq_to_keys = {}\n\n    def popitem(self):\n        if not self.key_to_val:\n            return None\n        \n        # Get the keys with the least frequency\n        keys = self.freq_to_keys.get(self.min_freq, [])\n        if not keys:\n            return None\n        \n        # Pop the least frequently used key\n        key_to_remove = keys.pop(0)\n        \n        # If no keys left for this frequency, clean up the frequency list\n        if not keys:\n            del self.freq_to_keys[self.min_freq]\n        \n        # Remove the key from other structures\n        value = self.key_to_val.pop(key_to_remove)\n        freq = self.key_to_freq.pop(key_to_remove)\n        \n        # Update the frequency list\n        self.freq_to_keys[freq].remove(key_to_remove)\n        \n        # Update the minimum frequency if needed\n        if not self.freq_to_keys.get(self.min_freq):\n            self.min_freq += 1\n        \n        return (key_to_remove, value)\n\n    def get(self, key: int):\n        if key not in self.key_to_val:\n            return -1\n        self._update_freq(key)\n        return self.key_to_val[key]\n\n    def put(self, key: int, value: int):\n        if self.capacity <= 0:\n            return\n        \n        if key in self.key_to_val:\n            self.key_to_val[key] = value\n            self._update_freq(key)\n        else:\n            if len(self.key_to_val) >= self.capacity:\n                self.popitem()\n            self.key_to_val[key] = value\n            self.key_to_freq[key] = 1\n            self.freq_to_keys.setdefault(1, []).append(key)\n            self.min_freq = 1\n\n    def _update_freq(self, key: int):\n        freq = self.key_to_freq[key]\n        keys = self.freq_to_keys[freq]\n        keys.remove(key)\n        \n        if not keys:\n            del self.freq_to_keys[freq]\n            if self.min_freq == freq:\n                self.min_freq += 1\n        \n        self.key_to_freq[key] += 1\n        new_freq = self.key_to_freq[key]\n        self.freq_to_keys.setdefault(new_freq, []).append(key)\n```"}}}
{"dataset": "coderEval", "task_id": "62b8d23a48ba5a41d1c3f499", "original_prompt": "def popitem(self):\n\t\"\"\"\n\tRemove and return the `(key, value)` pair least recently used.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.cache = OrderedDict()\n        self.capacity = capacity\n\n    def popitem(self):\n        if not self.cache:\n            raise KeyError(\"Cache is empty\")\n        return self.cache.popitem(last=False)\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        value = self.cache.pop(key)\n        self.cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.cache.pop(key)\n        elif len(self.cache) >= self.capacity:\n            self.cache.popitem(last=False)\n        self.cache[key] = value\n```\n\nThis code defines an `LRUCache` class using `OrderedDict` to maintain the order of elements, allowing efficient removal of the least recently used item. The `popitem` method removes and returns the least recently used `(key, value)` pair."}}}
{"dataset": "coderEval", "task_id": "62b8d23c48ba5a41d1c3f49b", "original_prompt": "def popitem(self):\n\t\"\"\"\n\t\"Remove and return the (key, value) pair most recently used.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean implementation of the `popitem` method for a class that functions like an LRU (Least Recently Used) cache. This example assumes the class is using an `OrderedDict` from the `collections` module to maintain the order of items based on usage:\n\n```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.cache = OrderedDict()\n        self.capacity = capacity\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self.cache.move_to_end(key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.cache.move_to_end(key)\n        self.cache[key] = value\n        if len(self.cache) > self.capacity:\n            self.cache.popitem(last=False)\n\n    def popitem(self):\n        return self.cache.popitem(last=True)\n\n# Example usage:\n# cache = LRUCache(2)\n# cache.put(1, 1)\n# cache.put(2, 2)\n# print(cache.popitem())  # Output: (2, 2)\n# cache.put(3, 3)\n# print(cache.get(1))     # Output: -1\n# print(cache.popitem())  # Output: (1, 1)\n```\n\n### Key Points:\n- **OrderedDict**: Maintains the order of insertion and allows easy movement of items to the end to denote recent use.\n- **get**: Retrieves an item and moves it to the end to mark it as recently used.\n- **put**: Adds or updates an item, moves it to the end, and removes the least recently used item if the capacity is exceeded.\n- **popitem**: Removes and returns the most recently used item by using `popitem(last=True)`."}}}
{"dataset": "coderEval", "task_id": "62b8d23e48ba5a41d1c3f49e", "original_prompt": "def popitem(self):\n\t\"\"\"\n\tFind, remove and return a random `(key, value)` pair via __choice in the class\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Certainly! Below is a clean implementation of the `popitem` method in Python. This method finds, removes, and returns a random `(key, value)` pair from a dictionary-like class.\n\n```python\nimport random\n\nclass CustomDict:\n    def __init__(self):\n        self._data = {}\n\n    def __choice(self):\n        return random.choice(list(self._data.items()))\n\n    def popitem(self):\n        key, value = self.__choice()\n        del self._data[key]\n        return key, value\n\n    def __setitem__(self, key, value):\n        self._data[key] = value\n\n    def __getitem__(self, key):\n        return self._data[key]\n\n    def __delitem__(self, key):\n        del self._data[key]\n\n    def __len__(self):\n        return len(self._data)\n\n    def __iter__(self):\n        return iter(self._data)\n```\n\nThis code defines a `CustomDict` class with a `popitem` method that uses a private method `__choice` to select a random item. The class also includes basic dictionary-like methods for completeness."}}}
{"dataset": "coderEval", "task_id": "62b43425903eeb48555d3ea1", "original_prompt": "def _create_in_regex(self) -> Pattern:\n\t\"\"\"\n\tCreate the in-style parameter regular expression.\n\nReturns the in-style parameter regular expression (:class:`re.Pattern`).\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport re\nfrom typing import Pattern\n\nclass RegexCreator:\n    def _create_in_regex(self) -> Pattern:\n        # Define a regular expression pattern for matching 'in-style' parameters\n        # Example: Assume the format is \"param=value1,value2,...\"\n        pattern = r\"(\\w+)=(\\w+(?:,\\w+)*)\"\n        \n        # Compile the pattern to return a re.Pattern object\n        return re.compile(pattern)\n```\n\nThis code defines a method `_create_in_regex` within a class `RegexCreator`. It creates and compiles a regular expression pattern to match parameters in the format `param=value1,value2,...` and returns a compiled `re.Pattern` object."}}}
{"dataset": "coderEval", "task_id": "62b43426903eeb48555d3ea2", "original_prompt": "def _create_converter(self) -> _converting._Converter:\n\t\"\"\"\n\tCreate the parameter style converter.\n\nReturns the parameter style converter (:class:`._converting._Converter`).\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Below is the Python code for the task, following best practices to ensure it is clean and avoids code smells:\n\n```python\nclass ConverterFactory:\n    def __init__(self):\n        # Initialize any required attributes if necessary\n        pass\n\n    def _create_converter(self):\n        # Import the required module or class\n        import _converting\n\n        # Create and return an instance of _converting._Converter\n        return _converting._Converter()\n```\n\n### Key Points:\n- **Class Initialization**: The `ConverterFactory` class is defined with an `__init__` method to allow for future extensions, such as initializing attributes if needed.\n- **Import Statement**: The import statement for `_converting` is placed inside the method to ensure that it is only executed when the method is called. This is a common practice to avoid unnecessary imports if the method might not always be used.\n- **Return Statement**: The method `_create_converter` directly returns an instance of `_converting._Converter`."}}}
{"dataset": "coderEval", "task_id": "62b8966c755ee91dce50a154", "original_prompt": "def isoparse(self, dt_str):\n\t\"\"\"\n\tParse an ISO-8601 datetime string into a :class:`datetime.datetime`.\n\nAn ISO-8601 datetime string consists of a date portion, followed\noptionally by a time portion - the date and time portions are separated\nby a single character separator, which is ``T`` in the official\nstandard. Incomplete date formats (such as ``YYYY-MM``) may *not* be\ncombined with a time portion.\n\nSupported date formats are:\n\nCommon:\n\n- ``YYYY``\n- ``YYYY-MM`` or ``YYYYMM``\n- ``YYYY-MM-DD`` or ``YYYYMMDD``\n\nUncommon:\n\n- ``YYYY-Www`` or ``YYYYWww`` - ISO week (day defaults to 0)\n- ``YYYY-Www-D`` or ``YYYYWwwD`` - ISO week and day\n\nThe ISO week and day numbering follows the same logic as\n:func:`datetime.date.isocalendar`.\n\nSupported time formats are:\n\n- ``hh``\n- ``hh:mm`` or ``hhmm``\n- ``hh:mm:ss`` or ``hhmmss``\n- ``hh:mm:ss.ssssss`` (Up to 6 sub-second digits)\n\nMidnight is a special case for `hh`, as the standard supports both\n00:00 and 24:00 as a representation. The decimal separator can be\neither a dot or a comma.\n\n\n.. caution::\n\n    Support for fractional components other than seconds is part of the\n    ISO-8601 standard, but is not currently implemented in this parser.\n\nSupported time zone offset formats are:\n\n- `Z` (UTC)\n- `\u00b1HH:MM`\n- `\u00b1HHMM`\n- `\u00b1HH`\n\nOffsets will be represented as :class:`dateutil.tz.tzoffset` objects,\nwith the exception of UTC, which will be represented as\n:class:`dateutil.tz.tzutc`. Time zone offsets equivalent to UTC (such\nas `+00:00`) will also be represented as :class:`dateutil.tz.tzutc`.\n\n:param dt_str:\n    A string or stream containing only an ISO-8601 datetime string\n\n:return:\n    Returns a :class:`datetime.datetime` representing the string.\n    Unspecified components default to their lowest value.\n\n.. warning::\n\n    As of version 2.7.0, the strictness of the parser should not be\n    considered a stable part of the contract. Any valid ISO-8601 string\n    that parses correctly with the default settings will continue to\n    parse correctly in future versions, but invalid strings that\n    currently fail (e.g. ``2017-01-01T00:00+00:00:00``) are not\n    guaranteed to continue failing in future versions if they encode\n    a valid date.\n\n.. versionadded:: 2.7.0\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a Python implementation of the `isoparse` method that parses an ISO-8601 datetime string into a `datetime.datetime` object. This implementation focuses on handling various date, time, and timezone formats as described, while avoiding code smells:\n\n```python\nfrom datetime import datetime, timedelta\nfrom dateutil import parser, tz\n\nclass ISO8601Parser:\n    def isoparse(self, dt_str):\n        # Replace comma with dot for decimal separator\n        dt_str = dt_str.replace(',', '.')\n\n        # Handle special case for 24:00 to convert it to 00:00 of the next day\n        if '24:' in dt_str:\n            dt_str = dt_str.replace('24:', '00:')\n            dt = datetime.fromisoformat(dt_str)\n            return dt + timedelta(days=1)\n        \n        # Use dateutil's parser for ISO-8601 parsing\n        try:\n            dt = parser.isoparse(dt_str)\n        except ValueError:\n            raise ValueError(f\"Invalid ISO-8601 datetime string: {dt_str}\")\n\n        return dt\n\n# Example usage:\n# iso_parser = ISO8601Parser()\n# result = iso_parser.isoparse(\"2023-10-05T14:48:00Z\")\n# print(result)\n```\n\n### Key Points:\n- **Decimal Separator**: Replaces commas with dots to handle fractional seconds.\n- **24:00 Handling**: Converts `24:00` to `00:00` of the next day, as per ISO-8601.\n- **Dateutil Parser**: Utilizes `dateutil.parser.isoparse` for robust parsing of ISO-8601 strings.\n- **Error Handling**: Raises a `ValueError` if the input string is not a valid ISO-8601 datetime.\n\nThis implementation leverages the `dateutil` library, which is well-suited for parsing ISO-8601 strings and handles many edge cases internally."}}}
{"dataset": "coderEval", "task_id": "62b896de755ee91dce50a183", "original_prompt": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n\t\"\"\"\n\tParse the date/time string into a :class:`datetime.datetime` object.\n\n:param timestr:\n    Any date/time string using the supported formats.\n\n:param default:\n    The default datetime object, if this is a datetime object and not\n    ``None``, elements specified in ``timestr`` replace elements in the\n    default object.\n\n:param ignoretz:\n    If set ``True``, time zones in parsed strings are ignored and a\n    naive :class:`datetime.datetime` object is returned.\n\n:param tzinfos:\n    Additional time zone names / aliases which may be present in the\n    string. This argument maps time zone names (and optionally offsets\n    from those time zones) to time zones. This parameter can be a\n    dictionary with timezone aliases mapping time zone names to time\n    zones or a function taking two parameters (``tzname`` and\n    ``tzoffset``) and returning a time zone.\n\n    The timezones to which the names are mapped can be an integer\n    offset from UTC in seconds or a :class:`tzinfo` object.\n\n    .. doctest::\n       :options: +NORMALIZE_WHITESPACE\n\n        >>> from dateutil.parser import parse\n        >>> from dateutil.tz import gettz\n        >>> tzinfos = {\"BRST\": -7200, \"CST\": gettz(\"America/Chicago\")}\n        >>> parse(\"2012-01-19 17:21:00 BRST\", tzinfos=tzinfos)\n        datetime.datetime(2012, 1, 19, 17, 21, tzinfo=tzoffset(u'BRST', -7200))\n        >>> parse(\"2012-01-19 17:21:00 CST\", tzinfos=tzinfos)\n        datetime.datetime(2012, 1, 19, 17, 21,\n                          tzinfo=tzfile('/usr/share/zoneinfo/America/Chicago'))\n\n    This parameter is ignored if ``ignoretz`` is set.\n\n:param \\*\\*kwargs:\n    Keyword arguments as passed to ``_parse()``.\n\n:return:\n    Returns a :class:`datetime.datetime` object or, if the\n    ``fuzzy_with_tokens`` option is ``True``, returns a tuple, the\n    first element being a :class:`datetime.datetime` object, the second\n    a tuple containing the fuzzy tokens.\n\n:raises ParserError:\n    Raised for invalid or unknown string format, if the provided\n    :class:`tzinfo` is not in a valid format, or if an invalid date\n    would be created.\n\n:raises TypeError:\n    Raised for non-string or character stream input.\n\n:raises OverflowError:\n    Raised if the parsed date exceeds the largest valid C integer on\n    your system.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a Python class with a `parse` method that follows your specifications:\n\n```python\nfrom datetime import datetime\nfrom dateutil.parser import parse as du_parse\nfrom dateutil.tz import tzoffset, tzfile\n\nclass Parser:\n    def parse(self, timestr, default=None, ignoretz=False, tzinfos=None, **kwargs):\n        if not isinstance(timestr, str):\n            raise TypeError(\"Input must be a string.\")\n\n        if tzinfos and ignoretz:\n            raise ValueError(\"tzinfos parameter is ignored if ignoretz is set.\")\n\n        if isinstance(tzinfos, dict):\n            tzinfos = {k: (tzoffset(None, v) if isinstance(v, int) else v) for k, v in tzinfos.items()}\n\n        try:\n            dt = du_parse(timestr, default=default, ignoretz=ignoretz, tzinfos=tzinfos, **kwargs)\n        except Exception as e:\n            raise ValueError(f\"Failed to parse date/time: {e}\")\n\n        return dt\n```\n\n### Key Points:\n- **Type Checking**: Ensures `timestr` is a string.\n- **Conflict Handling**: Raises an error if `ignoretz` is `True` but `tzinfos` is provided.\n- **Time Zone Handling**: Converts integer offsets to `tzoffset` objects.\n- **Exception Handling**: Catches parsing errors and raises a `ValueError` with a descriptive message.\n- **Dateutil Use**: Leverages `dateutil.parser.parse` for parsing flexibility."}}}
{"dataset": "coderEval", "task_id": "62b8a4a4755ee91dce50a3d3", "original_prompt": "def fromutc(self, dt):\n\t\"\"\"\n\tGiven a timezone-aware datetime in a given timezone, calculates a\ntimezone-aware datetime in a new timezone.\n\nSince this is the one time that we *know* we have an unambiguous\ndatetime object, we take this opportunity to determine whether the\ndatetime is ambiguous and in a \"fold\" state (e.g. if it's the first\noccurrence, chronologically, of the ambiguous datetime).\n\n:param dt:\n    A timezone-aware :class:`datetime.datetime` object.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a Python class implementing the `fromutc` method. The method converts a timezone-aware datetime from one timezone to another while checking for ambiguous times (fold state).\n\n```python\nfrom datetime import datetime, timezone, timedelta\nimport pytz\n\nclass TimezoneConverter:\n    def __init__(self, target_tz):\n        self.target_tz = pytz.timezone(target_tz)\n\n    def fromutc(self, dt):\n        if dt.tzinfo is None or dt.tzinfo.utcoffset(dt) is None:\n            raise ValueError(\"The datetime must be timezone-aware\")\n\n        # Convert the given datetime to the target timezone\n        target_dt = dt.astimezone(self.target_tz)\n\n        # Check if the datetime is ambiguous\n        ambiguous = target_dt.tzinfo._utc_transition_times and (\n            target_dt.tzinfo.utcoffset(target_dt, is_dst=None) is None\n        )\n\n        # Determine fold state (using fold attribute)\n        fold = target_dt.fold\n\n        return target_dt, ambiguous, fold\n\n# Example usage\nconverter = TimezoneConverter('America/New_York')\ndt_utc = datetime(2023, 11, 5, 1, 30, tzinfo=timezone.utc)\nconverted_dt, is_ambiguous, is_fold = converter.fromutc(dt_utc)\n\nprint(f\"Converted Datetime: {converted_dt}\")\nprint(f\"Ambiguous: {is_ambiguous}\")\nprint(f\"Fold: {is_fold}\")\n```\n\n### Key Points:\n\n- **Timezone Conversion**: The `astimezone` method is used to convert the datetime to the target timezone.\n- **Ambiguity Check**: The code checks if the datetime is ambiguous by examining if the offset is `None` during a transition period.\n- **Fold State**: The `fold` attribute of the datetime object indicates if it is in a \"fold\" state, which is relevant during ambiguous times like daylight saving time transitions."}}}
{"dataset": "coderEval", "task_id": "62b8a7b2755ee91dce50a4a7", "original_prompt": "def default_tzinfo(dt, tzinfo):\n\t\"\"\"\n\tSets the ``tzinfo`` parameter on naive datetimes only\n\nThis is useful for example when you are provided a datetime that may have\neither an implicit or explicit time zone, such as when parsing a time zone\nstring.\n\n.. doctest::\n\n    >>> from dateutil.tz import tzoffset\n    >>> from dateutil.parser import parse\n    >>> from dateutil.utils import default_tzinfo\n    >>> dflt_tz = tzoffset(\"EST\", -18000)\n    >>> print(default_tzinfo(parse('2014-01-01 12:30 UTC'), dflt_tz))\n    2014-01-01 12:30:00+00:00\n    >>> print(default_tzinfo(parse('2014-01-01 12:30'), dflt_tz))\n    2014-01-01 12:30:00-05:00\n\n:param dt:\n    The datetime on which to replace the time zone\n\n:param tzinfo:\n    The :py:class:`datetime.tzinfo` subclass instance to assign to\n    ``dt`` if (and only if) it is naive.\n\n:return:\n    Returns an aware :py:class:`datetime.datetime`.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom datetime import datetime\n\ndef default_tzinfo(dt, tzinfo):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n    return dt\n```"}}}
{"dataset": "coderEval", "task_id": "6305f9991d275c6667163c50", "original_prompt": "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n\t\"\"\"\n\tSet the bytes used to delimit slice points.\n\nArgs:\n    before: Split file before these delimiters.\n    after: Split file after these delimiters.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass FileSplitter:\n    def __init__(self):\n        self.before_delimiter = b''\n        self.after_delimiter = b''\n\n    def set_cut_chars(self, before: bytes, after: bytes) -> None:\n        self.before_delimiter = before\n        self.after_delimiter = after\n```"}}}
{"dataset": "coderEval", "task_id": "6306292052e177c0ba469f09", "original_prompt": "def identify_request(request: RequestType):\n\t\"\"\"\n\tCheck whether the request body loaded using JSON contains events. If yes, True is returned, otherwise, check whether the tag of the XML loaded from the request body is Magic_ENV_TAG, if yes, return True. If neither of the preceding conditions is met, return False.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport json\nimport xml.etree.ElementTree as ET\n\nclass RequestType:\n    def __init__(self, body: str):\n        self.body = body\n\ndef identify_request(request: RequestType) -> bool:\n    try:\n        json_data = json.loads(request.body)\n        if 'events' in json_data:\n            return True\n    except json.JSONDecodeError:\n        pass\n\n    try:\n        xml_root = ET.fromstring(request.body)\n        if xml_root.tag == 'Magic_ENV_TAG':\n            return True\n    except ET.ParseError:\n        pass\n\n    return False\n```"}}}
{"dataset": "coderEval", "task_id": "6306292152e177c0ba469f0d", "original_prompt": "def identify_request(request: RequestType) -> bool:\n\t\"\"\"\n\tCheck whether the request body loaded using JSON contains events. If yes, True is returned. Otherwise, False is returned.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean version of the Python code for the specified task:\n\n```python\nimport json\nfrom typing import Any\n\nclass RequestType:\n    def __init__(self, body: str):\n        self.body = body\n\ndef identify_request(request: RequestType) -> bool:\n    try:\n        data = json.loads(request.body)\n        return 'events' in data\n    except json.JSONDecodeError:\n        return False\n```\n\nThis code defines a `RequestType` class to represent the request with a JSON body and a function `identify_request` to check for the presence of an \"events\" key in the JSON data."}}}
{"dataset": "coderEval", "task_id": "6306292252e177c0ba469f11", "original_prompt": "def format_dt(dt):\n\t\"\"\"\n\tUse the ensure_timezone function to format the time of dt and return the time.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom datetime import datetime\nfrom pytz import timezone\n\ndef ensure_timezone(dt, tz_name='UTC'):\n    tz = timezone(tz_name)\n    return dt.astimezone(tz) if dt.tzinfo else tz.localize(dt)\n\ndef format_dt(dt):\n    dt = ensure_timezone(dt)\n    return dt.strftime('%Y-%m-%d %H:%M:%S %Z%z')\n```"}}}
{"dataset": "coderEval", "task_id": "6306292352e177c0ba469f1d", "original_prompt": "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n\t\"\"\"\n\tFind tags in text.\n\nTries to ignore tags inside code blocks.\n\nOptionally, if passed a \"replacer\", will also replace the tag word with the result\nof the replacer function called with the tag word.\n\nReturns a set of tags and the original or replaced text.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom typing import Callable, Set, Tuple\n\ndef find_tags(text: str, replacer: Callable[[str], str] = None) -> Tuple[Set[str], str]:\n    in_code_block = False\n    tags = set()\n    result_text = []\n    word = \"\"\n    \n    for char in text:\n        if char == '`':\n            in_code_block = not in_code_block\n            if word:\n                result_text.append(word)\n                word = \"\"\n            result_text.append(char)\n        elif char.isspace() or char in {',', '.', '!', '?', ';', ':', '-', '(', ')', '[', ']', '{', '}', '\"', '\\''}:\n            if not in_code_block and word.isalpha():\n                tags.add(word)\n                if replacer:\n                    word = replacer(word)\n            result_text.append(word)\n            result_text.append(char)\n            word = \"\"\n        else:\n            word += char\n\n    if word:\n        result_text.append(word)\n\n    return tags, ''.join(result_text)\n```"}}}
{"dataset": "coderEval", "task_id": "6306292352e177c0ba469f1e", "original_prompt": "def process_text_links(text):\n\t\"\"\"\n\tProcess links in text, adding some attributes and linkifying textual links.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport re\nfrom urllib.parse import urlparse\n\ndef process_text_links(text):\n    def is_valid_url(url):\n        try:\n            result = urlparse(url)\n            return all([result.scheme, result.netloc])\n        except ValueError:\n            return False\n\n    def linkify(match):\n        url = match.group(0)\n        if is_valid_url(url):\n            return f'<a href=\"{url}\" target=\"_blank\" rel=\"noopener noreferrer\">{url}</a>'\n        return url\n\n    url_pattern = r'https?://[^\\s]+'\n    processed_text = re.sub(url_pattern, linkify, text)\n    \n    return processed_text\n```"}}}
{"dataset": "coderEval", "task_id": "6306292652e177c0ba469f34", "original_prompt": "def fetch_content_type(url: str) -> Optional[str]:\n\t\"\"\"\n\tSet the head of the request through the URL and USER_AGENT.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nfrom typing import Optional\nimport requests\n\ndef fetch_content_type(url: str) -> Optional[str]:\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n    }\n    try:\n        response = requests.head(url, headers=headers)\n        response.raise_for_status()\n        return response.headers.get('Content-Type')\n    except requests.RequestException:\n        return None\n```"}}}
{"dataset": "coderEval", "task_id": "6306292a52e177c0ba469f41", "original_prompt": "def test_tag(tag: str) -> bool:\n\t\"\"\"\n\tChecks whether each character in the LEEGAL_TAG_CHARS belongs to a tag. If any character belongs to a tag, the value False is returned. Otherwise, the value True is returned.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean version of the Python function that follows the requirements:\n\n```python\ndef test_tag(tag: str) -> bool:\n    LEGAL_TAG_CHARS = set(\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_.\")  # Define valid characters\n\n    for char in tag:\n        if char not in LEGAL_TAG_CHARS:\n            return False\n    return True\n```\n\nThis function checks if each character in the `tag` string belongs to the set of legal characters, returning `True` if all characters are valid and `False` otherwise."}}}
{"dataset": "coderEval", "task_id": "6306298b52e177c0ba469fdc", "original_prompt": "def xml_children_as_dict(node):\n\t\"\"\"\n\tTurn the children of node <xml> into a dict, keyed by tag name.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef xml_children_as_dict(node):\n    children_dict = {}\n    for child in node:\n        tag = child.tag\n        if tag in children_dict:\n            if isinstance(children_dict[tag], list):\n                children_dict[tag].append(child)\n            else:\n                children_dict[tag] = [children_dict[tag], child]\n        else:\n            children_dict[tag] = child\n    return children_dict\n```"}}}
{"dataset": "coderEval", "task_id": "6306299052e177c0ba469fe8", "original_prompt": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n\t\"\"\"\n\tCheck whether sender_handle is the same as entity_handle. If yes, return True. Otherwise, return False.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    return sender_handle == entity_handle\n```"}}}
{"dataset": "coderEval", "task_id": "630629b952e177c0ba46a043", "original_prompt": "def get_nodeinfo_well_known_document(url, document_path=None):\n\t\"\"\"\n\tReturns a formatted dictionary, including information such as url and document_path.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport requests\n\ndef get_nodeinfo_well_known_document(url, document_path=None):\n    if not document_path:\n        document_path = '/.well-known/nodeinfo'\n    try:\n        response = requests.get(f\"{url}{document_path}\")\n        response.raise_for_status()\n        return {\n            'url': url,\n            'document_path': document_path,\n           'status_code': response.status_code,\n            'content': response.json() if response.headers.get('Content-Type') == 'application/json' else response.text\n        }\n    except requests.RequestException:\n        return {\n            'url': url,\n            'document_path': document_path,\n           'status_code': None,\n            'content': None\n        }\n```"}}}
{"dataset": "coderEval", "task_id": "630629d052e177c0ba46a0a1", "original_prompt": "def verify_relayable_signature(public_key, doc, signature):\n\t\"\"\"\n\tVerify the signed XML elements to have confidence that the claimed\nauthor did actually generate this message.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Certainly! Below is a Python function to verify a relayable signature using a public key. This function assumes you have access to libraries such as `lxml` for XML parsing and `cryptography` for signature verification. Make sure to install these libraries if you haven't already.\n\n```python\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives.serialization import load_pem_public_key\nfrom lxml import etree\n\ndef verify_relayable_signature(public_key_pem, doc, signature):\n    public_key = load_pem_public_key(public_key_pem)\n    doc_root = etree.fromstring(doc)\n    \n    # Assuming the signature is in an XML element like <Signature>...</Signature>\n    signature_element = doc_root.find('.//Signature')\n    if signature_element is None:\n        return False\n    \n    # Extract the signed data, which is everything before the <Signature> element\n    signed_data = etree.tostring(doc_root, method='c14n', exclusive=True, with_comments=False)\n    \n    # Verify the signature\n    try:\n        public_key.verify(\n            signature,\n            signed_data,\n            padding.PKCS1v15(),\n            hashes.SHA256()\n        )\n        return True\n    except Exception:\n        return False\n```\n\n### Key Points:\n- **XML Parsing**: Uses `lxml` to parse the XML document.\n- **Signature Extraction**: Assumes the signature is within a `<Signature>` XML element.\n- **Canonicalization**: Uses exclusive XML Canonicalization (c14n) to ensure the data is in a consistent format for verification.\n- **Signature Verification**: Utilizes the `cryptography` library to verify the signature with PKCS1v15 padding and SHA256 hashing.\n\nEnsure that the `signature` is in bytes and `public_key_pem` is the PEM-encoded public key. Adjust the XML path or canonicalization method as needed for your specific XML structure."}}}
{"dataset": "coderEval", "task_id": "630629e052e177c0ba46a0c4", "original_prompt": "def parse_diaspora_webfinger(document: str) -> Dict:\n\t\"\"\"\n\tThe webfinger is obtained by reading the document in JSON format, the value of hcard_url in the webfinger is the value of href in links in the document.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport json\nfrom typing import Dict\n\ndef parse_diaspora_webfinger(document: str) -> Dict:\n    data = json.loads(document)\n    links = data.get(\"links\", [])\n    hcard_url = next((link[\"href\"] for link in links if link[\"rel\"] == \"http://microformats.org/profile/hcard\"), None)\n    return {\"hcard_url\": hcard_url}\n```"}}}
{"dataset": "coderEval", "task_id": "630629e152e177c0ba46a0d1", "original_prompt": "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n\t\"\"\"\n\tTry to retrieve an RFC7033 webfinger document. Does not raise if it fails.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport requests\nfrom typing import Optional\n\ndef try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n    base_url = 'https://example.com/.well-known/webfinger'\n    params = {'resource': f'acct:{handle}'}\n    \n    try:\n        response = requests.get(base_url, params=params)\n        response.raise_for_status()\n        return response.text\n    except requests.RequestException:\n        return None\n``` \n\nThis code attempts to retrieve a WebFinger document for a given handle without raising an exception if it fails. The `requests` library is used to make the HTTP GET request. If the request is successful, the response text is returned; otherwise, `None` is returned."}}}
{"dataset": "coderEval", "task_id": "630629e152e177c0ba46a0d2", "original_prompt": "def retrieve_and_parse_diaspora_webfinger(handle):\n\t\"\"\"\n\tRetrieve a and parse a remote Diaspora webfinger document.\n\n:arg handle: Remote handle to retrieve\n:returns: dict\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport requests\nfrom xml.etree import ElementTree\n\ndef retrieve_and_parse_diaspora_webfinger(handle):\n    webfinger_url = f\"https://{handle}.well-known/webfinger?resource=acct:{handle}\"\n    response = requests.get(webfinger_url)\n    response.raise_for_status()\n    \n    root = ElementTree.fromstring(response.content)\n    links = {}\n    \n    for link in root.findall('{http://www.w3.org/2005/Atom}link'):\n        rel = link.get('rel')\n        href = link.get('href')\n        if rel and href:\n            links[rel] = href\n            \n    return links\n```"}}}
{"dataset": "coderEval", "task_id": "630629e252e177c0ba46a0d6", "original_prompt": "def retrieve_diaspora_host_meta(host):\n\t\"\"\"\n\tRetrieve a remote Diaspora host-meta document.\n\n:arg host: Host to retrieve from\n:returns: ``XRD`` instance\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport requests\nfrom xml.etree import ElementTree as ET\n\nclass XRD:\n    def __init__(self, root):\n        self.root = root\n\n    def __repr__(self):\n        return ET.tostring(self.root, encoding='unicode')\n\ndef retrieve_diaspora_host_meta(host):\n    url = f\"https://{host}/.well-known/host-meta\"\n    response = requests.get(url)\n    response.raise_for_status()\n    root = ET.fromstring(response.content)\n    return XRD(root)\n```"}}}
{"dataset": "coderEval", "task_id": "630629e752e177c0ba46a0fb", "original_prompt": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n\t\"\"\"\n\tSend a response containing data through the POST method.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean implementation of the `send_document` function in Python, using the `requests` library to handle HTTP requests:\n\n```python\nimport requests\n\ndef send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    headers = kwargs.pop('headers', {})\n    files = kwargs.pop('files', None)\n    \n    if method.lower() == \"post\":\n        response = requests.post(url, data=data, timeout=timeout, headers=headers, files=files, *args, **kwargs)\n    elif method.lower() == \"get\":\n        response = requests.get(url, params=data, timeout=timeout, headers=headers, *args, **kwargs)\n    else:\n        raise ValueError(f\"Unsupported method: {method}\")\n    \n    return response\n```\n\nThis code allows you to send data using either the POST or GET method, handling additional arguments and keyword arguments flexibly."}}}
{"dataset": "coderEval", "task_id": "6306091073426c38ae68acac", "original_prompt": "def dict_insert(dic, val, key, *keys):\n\t\"\"\"\n\tinsert a value of a nested key into a dictionary\n\nto insert value for a nested key, all ancestor keys should be given as\nmethod's arguments\n\nexample:\n  dict_insert({}, 'val', 'key1.key2'.split('.'))\n\n:param dic: a dictionary object to insert the nested key value into\n:param val: a value to insert to the given dictionary\n:param key: first key in a chain of key that will store the value\n:param keys: sub keys in the keys chain\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here is the Python code for the `dict_insert` function that inserts a value into a nested dictionary structure based on a chain of keys:\n\n```python\ndef dict_insert(dic, val, key, *keys):\n    current = dic\n    for k in keys[:len(keys) - 1]:\n        current = current.setdefault(k, {})\n    current[key] = val\n``` \n\nThis code iteratively navigates through the dictionary using the provided keys, creating nested dictionaries as needed, and finally assigns the value to the last key in the sequence."}}}
{"dataset": "coderEval", "task_id": "6306091a73426c38ae68acc8", "original_prompt": "def list_of_file_names(settings_dirs, spec_option):\n\t\"\"\"\n\tCreate and return a new IniType complex type via cli.ListOfFileNames()\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Below is a Python function that meets your requirements. It creates and returns a new `IniType` complex type using `cli.ListOfFileNames()`. The code is designed to be clean and free of code smells:\n\n```python\nfrom some_module import IniType, cli\n\ndef list_of_file_names(settings_dirs, spec_option):\n    list_of_files = cli.ListOfFileNames(settings_dirs, spec_option)\n    ini_type_instance = IniType(files=list_of_files)\n    return ini_type_instance\n```\n\nIn this code:\n\n- `some_module` is a placeholder for the actual module where `IniType` and `cli.ListOfFileNames` are defined. Replace it with the correct module name.\n- The function `list_of_file_names` takes `settings_dirs` and `spec_option` as arguments, creates a list of file names using `cli.ListOfFileNames`, and then uses this list to create an instance of `IniType`.\n- The instance of `IniType` is returned."}}}
{"dataset": "coderEval", "task_id": "6306091b73426c38ae68acd7", "original_prompt": "def ansible_config_manager(cls):\n\t\"\"\"\n\tGets the ansible config manager via ServiceName.ANSIBLE_CONFIG_MANAGER in cls._get_service()\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a Python implementation of the `ansible_config_manager` method, adhering to clean code principles:\n\n```python\nclass ConfigurationService:\n    def _get_service(self):\n        # Simulate fetching service details\n        return {\n            'ServiceName.ANSIBLE_CONFIG_MANAGER': 'ansible_config_manager_value'\n        }\n\n    @classmethod\n    def ansible_config_manager(cls):\n        service_details = cls()._get_service()\n        return service_details.get('ServiceName.ANSIBLE_CONFIG_MANAGER')\n```\n\nThis code defines a class `ConfigurationService` with a method `_get_service` simulating the retrieval of service details. The `ansible_config_manager` class method fetches the Ansible config manager value from the service details."}}}
{"dataset": "coderEval", "task_id": "6306091b73426c38ae68acd9", "original_prompt": "def workspace_manager(cls):\n\t\"\"\"\n\tGets the workspace manager via ServiceName.WORKSPACE_MANAGER in cls._get_service()\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass WorkspaceManager:\n    def __init__(self):\n        self.service_map = {\n            'SERVICE_NAME': {\n                'WORKSPACE_MANAGER': self._workspace_manager\n            }\n        }\n\n    def _get_service(self, service_name):\n        return self.service_map.get(service_name, {})\n\n    def _workspace_manager(self):\n        # Placeholder for workspace manager logic\n        return \"Workspace Manager Logic\"\n\n    def workspace_manager(self, cls):\n        service_name = 'SERVICE_NAME'\n        service = cls._get_service(service_name)\n        return service.get('WORKSPACE_MANAGER', lambda: None)()\n```\n\nThis code defines a `WorkspaceManager` class with a method `workspace_manager` that retrieves a specific service using `_get_service`. The service logic is encapsulated within `_workspace_manager`."}}}
{"dataset": "coderEval", "task_id": "6306091b73426c38ae68acda", "original_prompt": "def plugins_manager(cls):\n\t\"\"\"\n\tGets the plugin manager via ServiceName.PLUGINS_MANAGER in cls._get_service()\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Certainly! Below is a Python function that implements the `plugins_manager` method without using docstrings or comments. The function assumes that `cls._get_service()` returns a dictionary-like object with a key `ServiceName.PLUGINS_MANAGER`.\n\n```python\nclass ServiceName:\n    PLUGINS_MANAGER = 'plugins_manager'\n\ndef plugins_manager(cls):\n    services = cls._get_service()\n    return services[ServiceName.PLUGINS_MANAGER]\n```\n\nThis function retrieves the plugin manager by accessing the `ServiceName.PLUGINS_MANAGER` key from the result of `cls._get_service()`. Ensure that `cls._get_service()` is defined elsewhere in your code to return the appropriate dictionary-like object."}}}
{"dataset": "coderEval", "task_id": "6306091c73426c38ae68acdc", "original_prompt": "def validate_from_content(cls, spec_content=None):\n\t\"\"\"\n\tvalidates that spec (YAML) content has all required fields\n\n:param spec_content: content of spec file\n:raise IRValidatorException: when mandatory data\nis missing in spec file\n:return: Dictionary with data loaded from a spec (YAML) file\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport yaml\n\nclass IRValidatorException(Exception):\n    pass\n\nclass SpecValidator:\n    REQUIRED_FIELDS = ['field1', 'field2', 'field3']  # Example required fields\n\n    @classmethod\n    def validate_from_content(cls, spec_content=None):\n        if spec_content is None:\n            raise IRValidatorException(\"Spec content is missing.\")\n        \n        try:\n            data = yaml.safe_load(spec_content)\n        except yaml.YAMLError:\n            raise IRValidatorException(\"Invalid YAML format.\")\n        \n        if not isinstance(data, dict):\n            raise IRValidatorException(\"Spec content must be a dictionary.\")\n        \n        missing_fields = [field for field in cls.REQUIRED_FIELDS if field not in data]\n        \n        if missing_fields:\n            raise IRValidatorException(f\"Missing mandatory fields: {', '.join(missing_fields)}\")\n        \n        return data\n```\n\nThis code defines a class `SpecValidator` with a class method `validate_from_content` that checks if the provided YAML content contains all required fields. It raises an `IRValidatorException` if any required field is missing or if the content is not in the expected format."}}}
{"dataset": "coderEval", "task_id": "6306091c73426c38ae68acdd", "original_prompt": "def validate_from_file(cls, yaml_file=None):\n\t\"\"\"\n\tLoads & validates that a YAML file has all required fields\n\n:param yaml_file: Path to YAML file\n:raise IRValidatorException: when mandatory data is missing in file\n:return: Dictionary with data loaded from a YAML file\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport yaml\n\nclass IRValidatorException(Exception):\n    pass\n\nclass Validator:\n    REQUIRED_FIELDS = [\"field1\", \"field2\", \"field3\"]\n\n    @classmethod\n    def validate_from_file(cls, yaml_file=None):\n        if yaml_file is None:\n            raise IRValidatorException(\"YAML file path is required\")\n\n        with open(yaml_file, \"r\") as file:\n            data = yaml.safe_load(file)\n\n        if not isinstance(data, dict):\n            raise IRValidatorException(\"YAML content is not a dictionary\")\n\n        for field in cls.REQUIRED_FIELDS:\n            if field not in data:\n                raise IRValidatorException(f\"Mandatory field '{field}' is missing\")\n\n        return data\n```\n\nThis code defines a `Validator` class with a class method `validate_from_file` that loads a YAML file, checks for required fields, and raises an exception if any are missing. The method returns the data as a dictionary if all checks pass."}}}
{"dataset": "coderEval", "task_id": "6306091d73426c38ae68ace5", "original_prompt": "def _include_groups(self, parser_dict):\n\t\"\"\"\n\tResolves the include dict directive in the spec files.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef _include_groups(self, parser_dict):\n    included_groups = []\n    for key, value in parser_dict.items():\n        if key == 'include':\n            for group in value:\n                if group in self.spec_files:\n                    included_groups.append(self.spec_files[group])\n    return included_groups\n```"}}}
{"dataset": "coderEval", "task_id": "6306092373426c38ae68acfa", "original_prompt": "def get_spec_defaults(self):\n\t\"\"\"\n\tResolve arguments' values from spec and other sources with self._get_defaults()\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "To achieve the task described in your request, we need to create a Python method called `get_spec_defaults` within a class context. This method will use another method called `_get_defaults` to resolve argument values from a specification (spec) and other potential sources. Here's a possible implementation:\n\n```python\nclass SpecificationHandler:\n    def __init__(self, spec):\n        self.spec = spec\n\n    def _get_defaults(self, key):\n        # Placeholder for actual default retrieval logic\n        # This could involve checking environment variables, config files, etc.\n        defaults = {\n            'timeout': 30,\n           'retries': 3,\n           'verbose': False\n        }\n        return defaults.get(key)\n\n    def get_spec_defaults(self):\n        resolved_defaults = {}\n        for key in self.spec:\n            if key not in resolved_defaults:\n                # Attempt to resolve the value from the spec first\n                resolved_defaults[key] = self.spec[key]\n\n            # If the spec does not provide a value, use the _get_defaults method\n            if resolved_defaults[key] is None:\n                resolved_defaults[key] = self._get_defaults(key)\n\n        return resolved_defaults\n\n# Example usage:\nspec = {\n    'timeout': None,\n   'retries': None,\n   'verbose': True,\n    'batch_size': None\n}\n\nhandler = SpecificationHandler(spec)\ndefaults = handler.get_spec_defaults()\nprint(defaults)\n```\n\n### Explanation:\n\n1. **Class Initialization**: The `SpecificationHandler` class is initialized with a `spec` dictionary that contains the initial configuration or specification.\n\n2. **_get_defaults Method**: This method is a placeholder for retrieving default values. It returns a default value for a given key if available. In a real-world scenario, this method could be more complex, involving fetching values from environment variables, configuration files, or other sources.\n\n3. **get_spec_defaults Method**: This method iterates over the keys in the `spec`. It first tries to use the value from the `spec`. If the value is `None` (indicating that it's not provided in the spec), it falls back to the `_get_defaults` method to get a default value.\n\n4. **Example Usage**: An example usage is provided to demonstrate how the class and methods work together. The `spec` dictionary has some `None` values, which are resolved using the `_get_defaults` method.\n\nThis implementation avoids code smells by keeping the logic straightforward and modular, with clear separation of concerns between resolving spec"}}}
{"dataset": "coderEval", "task_id": "6306092973426c38ae68ad01", "original_prompt": "def get_deprecated_args(self):\n\t\"\"\"\n\tReturning dict with options which deprecate others. options from self.spec_helper.iterate_option_specs()\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean implementation of the `get_deprecated_args` function in Python, following best practices and avoiding code smells:\n\n```python\nclass SpecHelper:\n    def iterate_option_specs(self):\n        # Placeholder for the actual implementation\n        return []\n\nclass MyClass:\n    def __init__(self):\n        self.spec_helper = SpecHelper()\n\n    def get_deprecated_args(self):\n        deprecated_options = {}\n        for option in self.spec_helper.iterate_option_specs():\n            if option.get('deprecated'):\n                deprecated = option.get('deprecated')\n                if isinstance(deprecated, list):\n                    deprecated_options[option['name']] = deprecated\n        return deprecated_options\n```\n\n### Key Points:\n- **Encapsulation**: The `SpecHelper` class is assumed to handle the iteration of option specifications.\n- **Iterate and Filter**: The function iterates over the options and checks for a `'deprecated'` key.\n- **Data Structure**: Uses a dictionary to map deprecated options to their replacements.\n- **Type Checking**: Ensures the deprecated field is a list before adding to the dictionary."}}}
{"dataset": "coderEval", "task_id": "6306092c73426c38ae68ad02", "original_prompt": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n\t\"\"\"\n\tValidates and prints the deprecated arguments.\n\n:param cli_args: the dict of arguments from cli\n:param answer_file_args:  the dict of arguments from files\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass ArgumentValidator:\n    def __init__(self, deprecated_args):\n        self.deprecated_args = deprecated_args\n\n    def validate_arg_deprecation(self, cli_args, answer_file_args):\n        all_args = {**cli_args, **answer_file_args}\n        deprecated_found = [\n            arg for arg in all_args if arg in self.deprecated_args\n        ]\n\n        if deprecated_found:\n            print(\"Deprecated arguments found:\")\n            for arg in deprecated_found:\n                print(f\"  - {arg}\")\n```\n\n### Usage Example\n\n```python\n# Assuming these are the deprecated arguments\ndeprecated_args = [\"--old-option\", \"--legacy-flag\"]\n\n# Create an instance of the ArgumentValidator\nvalidator = ArgumentValidator(deprecated_args)\n\n# Example CLI and answer file arguments\ncli_args = {\"--new-option\": \"value1\", \"--old-option\": \"value2\"}\nanswer_file_args = {\"--some-option\": \"value3\", \"--legacy-flag\": \"value4\"}\n\n# Validate deprecated arguments\nvalidator.validate_arg_deprecation(cli_args, answer_file_args)\n```\n\nThis code defines a class `ArgumentValidator` with a method `validate_arg_deprecation` that checks for deprecated arguments in the combined dictionary of CLI and file arguments. It prints out any deprecated arguments found."}}}
{"dataset": "coderEval", "task_id": "6306092d73426c38ae68ad04", "original_prompt": "def get_parser_option_specs(self, command_name):\n\t\"\"\"\n\tGets all the options for the specified command\n\n:param command_name: the command name (main, virsh, ospd, etc...)\n:return: the list of all command options\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass CommandParser:\n    def __init__(self):\n        self.commands = {\n           'main': ['--help', '--version'],\n            'virsh': ['--domain', '--name', '--state'],\n            'ospd': ['--config', '--debug', '--log-level'],\n            # Add more command options as needed\n        }\n\n    def get_parser_option_specs(self, command_name):\n        return self.commands.get(command_name, [])\n```\n\nThis code defines a `CommandParser` class with an `__init__` method to initialize a dictionary of command options. The `get_parser_option_specs` method retrieves the options for a given command, defaulting to an empty list if the command is not found."}}}
{"dataset": "coderEval", "task_id": "6306092d73426c38ae68ad05", "original_prompt": "def get_option_spec(self, command_name, argument_name):\n\t\"\"\"\n\tGets the specification for the specified option name. Get options of the given command_name with self.get_parser_option_specs()\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nclass CommandHandler:\n    def get_parser_option_specs(self, command_name):\n        # This method should be implemented to return the options for a given command\n        pass\n\n    def get_option_spec(self, command_name, argument_name):\n        options = self.get_parser_option_specs(command_name)\n        return next((option for option in options if option['name'] == argument_name), None)\n```\n\nThis code defines a `CommandHandler` class with the `get_option_spec` method, which retrieves the specification for a specified option name. The `get_parser_option_specs` method is assumed to be implemented elsewhere in the class to return the options for a given command. The `get_option_spec` method uses a generator expression with `next` to find and return the option with the matching `argument_name`. If no match is found, it returns `None`."}}}
{"dataset": "coderEval", "task_id": "6306092d73426c38ae68ad06", "original_prompt": "def get_silent_args(self, args):\n\t\"\"\"\n\tlist of silenced argument\n\n:param args: The received arguments.\n:return: list, slienced argument names\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef get_silent_args(self, args):\n    silent_args = []\n    for arg in args:\n        if arg.startswith('--silent-'):\n            silent_args.append(arg[9:])\n    return silent_args\n```"}}}
{"dataset": "coderEval", "task_id": "6306092d73426c38ae68ad07", "original_prompt": "def validate_requires_args(self, args):\n\t\"\"\"\n\tCheck if all the required arguments have been provided.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef validate_requires_args(self, args):\n    required_args = {'arg1', 'arg2', 'arg3'}  # Replace with actual required arguments\n    missing_args = required_args - args.keys()\n\n    if missing_args:\n        raise ValueError(f\"Missing required arguments: {', '.join(missing_args)}\")\n```\n\nThis code assumes `args` is a dictionary and `required_args` is a set of keys that must be present in `args`. Adjust `required_args` to fit your specific use case."}}}
{"dataset": "coderEval", "task_id": "6306092d73426c38ae68ad08", "original_prompt": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n\t\"\"\"\n\tList arguments with ``required_when`` condition matched.\n\n:param command_name: the command name.\n:param options_spec:  the list of command spec options.\n:param args: the received input arguments\n:return: list, list of argument names with matched ``required_when``\n    condition\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef _get_conditionally_required_args(self, command_name, options_spec, args):\n    required_args = []\n    for option in options_spec:\n        required_when = option.get('required_when')\n        if required_when:\n            condition, arg_name = required_when.split(':')\n            if condition in args and args[condition] == 'true':\n                required_args.append(arg_name)\n    return required_args\n```\n\nThis code iterates through the `options_spec`, checking for `required_when` conditions. If a condition is met (i.e., the specified argument is `'true'`), it adds the corresponding argument name to the `required_args` list."}}}
{"dataset": "coderEval", "task_id": "6306092e73426c38ae68ad09", "original_prompt": "def validate_length_args(self, args):\n\t\"\"\"\n\tCheck if value of the given args is not longer than length specified. \\n:param args: The received arguments.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef validate_length_args(self, args, max_lengths):\n    for arg_name, arg_value in args.items():\n        if arg_name in max_lengths and isinstance(arg_value, str):\n            if len(arg_value) > max_lengths[arg_name]:\n                raise ValueError(f\"Argument '{arg_name}' exceeds maximum length of {max_lengths[arg_name]}\")\n```"}}}
{"dataset": "coderEval", "task_id": "6306092e73426c38ae68ad0a", "original_prompt": "def validate_choices_args(self, args):\n\t\"\"\"\n\tCheck if value of the given args is one of the available choices. \\n:param args: The received arguments.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef validate_choices_args(self, args):\n    choices = {\n        'option1': ['value1', 'value2', 'value3'],\n        'option2': ['value4', 'value5'],\n        'option3': ['value6', 'value7', 'value8', 'value9'],\n    }\n\n    for key, value in args.items():\n        if key in choices:\n            if value not in choices[key]:\n                raise ValueError(f\"Invalid value '{value}' for argument '{key}'. Expected one of {choices[key]}.\")\n\n```\n\nThis function checks if the values in `args` are within the predefined choices. It raises a `ValueError` if an invalid value is found."}}}
{"dataset": "coderEval", "task_id": "6306092e73426c38ae68ad0b", "original_prompt": "def validate_min_max_args(self, args):\n\t\"\"\"\n\tCheck if value of the given args is between minimum and maximum values\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean implementation of the `validate_min_max_args` function:\n\n```python\nclass Validator:\n    def __init__(self, min_values, max_values):\n        self.min_values = min_values\n        self.max_values = max_values\n\n    def validate_min_max_args(self, args):\n        if len(args)!= len(self.min_values) or len(args)!= len(self.max_values):\n            raise ValueError(\"Argument count does not match min or max values count.\")\n\n        for i, value in enumerate(args):\n            if not (self.min_values[i] <= value <= self.max_values[i]):\n                raise ValueError(f\"Argument at index {i} is out of bounds: {value}\")\n\n# Example usage:\n# validator = Validator([0, 10], [10, 20])\n# validator.validate_min_max_args([5, 15])\n```\n\nThis code defines a `Validator` class that checks if each value in `args` is within the corresponding minimum and maximum range."}}}
{"dataset": "coderEval", "task_id": "6306092e73426c38ae68ad0d", "original_prompt": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n\t\"\"\"\n\tReturns the corresponding function in COMPLEX_TYPES based on type_name and returns the result obtained by complex_action after option_name,(self.vars, self.defaults, self.plugin_path), subcommand, spec_option) is input.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here is the Python code for the given task. I've structured it to be clean and avoid code smells:\n\n```python\nclass CommandHandler:\n    COMPLEX_TYPES = {\n        # Assuming this is a dictionary mapping type names to functions\n        'example_type': lambda *args: f\"Example processing with {args}\",\n        # Add other type mappings as necessary\n    }\n\n    def complex_action(self, option_name, vars, defaults, plugin_path, subcommand, spec_option):\n        # Placeholder for the actual processing logic\n        return f\"Processed {option_name} with vars={vars}, defaults={defaults}, plugin_path={plugin_path}, subcommand={subcommand}, spec_option={spec_option}\"\n\n    def create_complex_argument_type(self, subcommand, type_name, option_name, spec_option):\n        complex_type_function = self.COMPLEX_TYPES.get(type_name)\n        if not complex_type_function:\n            raise ValueError(f\"Unknown type_name: {type_name}\")\n\n        result = self.complex_action(option_name, self.vars, self.defaults, self.plugin_path, subcommand, spec_option)\n        return complex_type_function(result)\n\n    def __init__(self, vars, defaults, plugin_path):\n        self.vars = vars\n        self.defaults = defaults\n        self.plugin_path = plugin_path\n\n# Example usage\nhandler = CommandHandler(vars='vars_value', defaults='defaults_value', plugin_path='plugin_path_value')\nresult = handler.create_complex_argument_type('subcommand_example', 'example_type', 'option_example','spec_option_example')\nprint(result)\n```\n\n### Key Points:\n- **Class Structure**: The logic is encapsulated within a class `CommandHandler`.\n- **Dictionary Mapping**: `COMPLEX_TYPES` is a dictionary mapping type names to functions.\n- **Error Handling**: Raises a `ValueError` if `type_name` is not found in `COMPLEX_TYPES`.\n- **Initialization**: The class is initialized with `vars`, `defaults`, and `plugin_path` to be used in `complex_action`.\n- **Functionality**: `create_complex_argument_type` retrieves the function from `COMPLEX_TYPES` and processes the result using `complex_action`."}}}
{"dataset": "coderEval", "task_id": "6306092e73426c38ae68ad0f", "original_prompt": "def get_nested_custom_and_control_args(self, args):\n\t\"\"\"\n\tSplit input arguments to control nested and custom.\n\nControls arguments: control the IR behavior. These arguments\n    will not be put into the spec yml file\nNested arguments: are used by the Ansible playbooks and will be put\n    into the spec yml file.\nCustom arguments: Custom ansible variables to be used instead of the\n    normal nested usage.\n\n:param args: the collected list of args.\n:return: (dict, dict): flat dicts (control_args, nested_args)\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    \n    for arg in args:\n        key, value = arg.split('=', 1)\n        \n        if key.startswith('--control-'):\n            control_args[key[10:]] = value\n        elif key.startswith('--nested-'):\n            nested_args[key[9:]] = value\n        elif key.startswith('--custom-'):\n            nested_args[key[9:]] = value\n    \n    return control_args, nested_args\n```"}}}
{"dataset": "coderEval", "task_id": "6306092e73426c38ae68ad11", "original_prompt": "def merge_extra_vars(vars_dict, extra_vars=None):\n\t\"\"\"\n\tExtend ``vars_dict`` with ``extra-vars``\n\n:param vars_dict: Dictionary to merge extra-vars into\n:param extra_vars: List of extra-vars\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = {}\n    \n    for key, value in extra_vars.items():\n        if key in vars_dict and isinstance(vars_dict[key], dict) and isinstance(value, dict):\n            merge_extra_vars(vars_dict[key], value)\n        else:\n            vars_dict[key] = value\n```"}}}
{"dataset": "coderEval", "task_id": "6306092f73426c38ae68ad13", "original_prompt": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n\t\"\"\"\n\tWraps the 'ansible-playbook' CLI.\n\n:param ir_workspace: An Infrared Workspace object represents the active\nworkspace\n:param ir_plugin: An InfraredPlugin object of the current plugin\n:param playbook_path: the playbook to invoke\n:param verbose: Ansible verbosity level\n:param extra_vars: dict. Passed to Ansible as extra-vars\n:param ansible_args: dict of ansible-playbook arguments to plumb down\n    directly to Ansible.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport subprocess\nimport shlex\n\ndef ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    cmd = [\"ansible-playbook\", playbook_path]\n\n    if verbose is not None:\n        cmd.extend([\"-v\"] * verbose)\n\n    if extra_vars:\n        extra_vars_str = \" \".join(f\"{key}={value}\" for key, value in extra_vars.items())\n        cmd.extend([\"-e\", extra_vars_str])\n\n    if ansible_args:\n        for arg, value in ansible_args.items():\n            if isinstance(value, bool):\n                if value:\n                    cmd.append(f\"--{arg}\")\n            else:\n                cmd.extend([f\"--{arg}\", str(value)])\n\n    result = subprocess.run(cmd, capture_output=True, text=True)\n    return result.stdout, result.stderr\n```"}}}
{"dataset": "coderEval", "task_id": "6306093273426c38ae68ad15", "original_prompt": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n\t\"\"\"\n\tRuns ansible cli with vars dict\n\n:param vars_dict: dict, Will be passed as Ansible extra-vars\n:param cli_args: the list  of command line arguments\n:param ir_workspace: An Infrared Workspace object represents the active\n workspace\n:param ir_plugin: An InfraredPlugin object of the current plugin\n:return: ansible results\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "Here's a clean implementation of the `_run_playbook` function without docstrings or comments:\n\n```python\nimport subprocess\nimport json\n\ndef _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    extra_vars = json.dumps(vars_dict)\n    command = ['ansible-playbook'] + cli_args + ['--extra-vars', extra_vars]\n\n    process = subprocess.Popen(\n        command,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        text=True\n    )\n\n    stdout, stderr = process.communicate()\n\n    if process.returncode!= 0:\n        raise RuntimeError(f\"Playbook execution failed: {stderr}\")\n\n    return {\n        \"returncode\": process.returncode,\n        \"stdout\": stdout,\n        \"stderr\": stderr\n    }\n```\n\n### Key Points:\n- **Subprocess**: Uses `subprocess.Popen` to run the playbook command.\n- **Extra-vars**: Converts `vars_dict` to a JSON string for `--extra-vars`.\n- **Error Handling**: Raises an exception if the playbook execution fails.\n- **Return Value**: Returns a dictionary containing the return code, stdout, and stderr."}}}
{"dataset": "coderEval", "task_id": "63060ada73426c38ae68ad31", "original_prompt": "def _convert_non_cli_args(self, parser_name, values_dict):\n\t\"\"\"\n\tCasts arguments to correct types by modifying values_dict param.\n\nBy default all the values are strings.\n\n:param parser_name: The command name, e.g. main, virsh, ospd, etc\n:param values_dict: The dict of with arguments\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef _convert_non_cli_args(self, parser_name, values_dict):\n    conversion_map = {\n       'main': {\n            'timeout': int,\n           'verbose': bool,\n        },\n        'virsh': {\n           'memory': int,\n            'cpu': int,\n        },\n        'ospd': {\n            'port': int,\n            'debug': bool,\n        }\n    }\n\n    if parser_name in conversion_map:\n        for key, conversion_func in conversion_map[parser_name].items():\n            if key in values_dict:\n                try:\n                    values_dict[key] = conversion_func(values_dict[key])\n                except (ValueError, TypeError):\n                    pass\n```\n\nThis code snippet defines a method `_convert_non_cli_args` that converts specific arguments in `values_dict` to their appropriate types based on the `parser_name`. It uses a dictionary `conversion_map` to map parser names to their respective argument conversion functions. The method iterates over these mappings and attempts to convert each specified argument, handling any conversion errors gracefully."}}}
{"dataset": "coderEval", "task_id": "63060b1a73426c38ae68ad3e", "original_prompt": "def get_plugin_spec_flatten_dict(plugin_dir):\n\t\"\"\"\n\tUse YAML to read various information in plugin_dir and return the information in dictionary form.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\nimport yaml\n\ndef get_plugin_spec_flatten_dict(plugin_dir):\n    def load_yaml_file(file_path):\n        with open(file_path, 'r') as file:\n            return yaml.safe_load(file) or {}\n\n    def flatten_dict(d, parent_key='', sep='_'):\n        items = []\n        for k, v in d.items():\n            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n            if isinstance(v, dict):\n                items.extend(flatten_dict(v, new_key, sep=sep).items())\n            else:\n                items.append((new_key, v))\n        return dict(items)\n\n    plugin_spec = {}\n    for root, _, files in os.walk(plugin_dir):\n        for file in files:\n            if file.endswith('.yaml') or file.endswith('.yml'):\n                file_path = os.path.join(root, file)\n                yaml_data = load_yaml_file(file_path)\n                flattened_data = flatten_dict(yaml_data)\n                plugin_spec.update(flattened_data)\n    \n    return plugin_spec\n```"}}}
{"dataset": "coderEval", "task_id": "63060b1b73426c38ae68ad42", "original_prompt": "def inject_config(self):\n\t\"\"\"\n\tIf the ANSIBLE_CONFIG property does not exist in os.environ, set it to self.ansible_config_path.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\nimport os\n\nclass ConfigInjector:\n    def __init__(self, ansible_config_path):\n        self.ansible_config_path = ansible_config_path\n\n    def inject_config(self):\n        if 'ANSIBLE_CONFIG' not in os.environ:\n            os.environ['ANSIBLE_CONFIG'] = self.ansible_config_path\n```\n\nThis code defines a `ConfigInjector` class with an `inject_config` method that sets the `ANSIBLE_CONFIG` environment variable if it is not already set. The constructor initializes the class with the path to the Ansible configuration file."}}}
{"dataset": "coderEval", "task_id": "63060b1b73426c38ae68ad43", "original_prompt": "def extend_cli(self, root_subparsers):\n\t\"\"\"\n\tAdds the spec cli options to to the main entry point.\n\n:param subparser: the subparser object to extend.\n\t\"\"\"\n\t", "generations": {"microsoft/phi-4": {"quality_focused": "```python\ndef extend_cli(self, root_subparsers):\n    parent_parser = root_subparsers.add_parser('parent', help='Parent command')\n    parent_parser.set_defaults(func=self.parent_command)\n    \n    subparser = parent_parser.add_subparsers(dest='command')\n\n    spec_parser = subparser.add_parser('spec', help='Spec command')\n    spec_parser.add_argument('--option1', type=str, help='Option 1')\n    spec_parser.add_argument('--option2', type=int, help='Option 2')\n    spec_parser.set_defaults(func=self.spec_command)\n\ndef parent_command(self, args):\n    print(\"Executing parent command\")\n\ndef spec_command(self, args):\n    print(f\"Executing spec command with options: {args.option1}, {args.option2}\")\n```\n\nThis code defines a method to extend a CLI with a subcommand structure using `argparse`. It sets up a parent command with a `spec` subcommand, including options for `option1` and `option2`. The `set_defaults` method links the commands to their respective handler functions."}}}
